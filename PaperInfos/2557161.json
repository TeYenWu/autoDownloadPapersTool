{"paperId":2557161,"citation":[{"content":"Jan Schneider , Dirk BÃ¶rner , Peter van Rosmalen , Marcus Specht, Presentation Trainer, your Public Speaking Multimodal Coach, Proceedings of the 2015 ACM on International Conference on Multimodal Interaction, November 09-13, 2015, Seattle, Washington, USA","paperID":"2830603"}],"reference":[{"content":"openframeworks. http://www.openframeworks.cc/.","paperID":"None"},{"content":"ofxFaceTracker. http://github.com/kylemcdonald/ofxFaceTracker/","paperID":"None"},{"content":"Dirac3L. http://dirac.dspdimension.com/","paperID":"None"},{"content":"Lyons. M. J., Haehnel. M, and Tetsutani. N. The Mouthesizer: A Facial Gesture Musical Interface. In Conference Abstracts, SIGGRAPH 2001, ACM (LA, 2001), 230.","paperID":"None"},{"content":"Michael J. Lyons , Nobuji Tetsutani, Facing the music: a facial action controlled musical interface, CHI '01 Extended Abstracts on Human Factors in Computing Systems, March 31-April 05, 2001, Seattle, Washington","paperID":"634250"},{"content":"Thibaut Weise , Sofien Bouaziz , Hao Li , Mark Pauly, Realtime performance-based facial animation, ACM Transactions on Graphics (TOG), v.30 n.4, July 2011","paperID":"1964972"}],"abstract":"In most cases, speeches or presentations at an international event are required to be given in a common language (e.g. English). However, for people who are not proficient in that common language, delivering presentations fluently is very difficult. Simultaneous translation seems to be a solution, but besides its high cost, simultaneous translation undermines the nature of the presentation by substituting the real voice of the lecturer as well as his/her emotions. In this paper, we propose \"SmartVoice\", a presentation support system, which aims to overcome language barriers. By tracking the lip motion of the lecturer, SmartVoice controls the playback of the narration, which is a sound data prepared in advance or created automatically using a voice synthesizer. SmartVoice also controls the intonation of the sound based on the position and shape of the lecturer's mouth. As the lecturer can talk at his/her own pace with the voice automatically following, it appears as if he/she talks in his/her own voice. In our user evaluation, we confirmed that audiences find it difficult to distinguish between the narration generated by SmartVoice and that by a real voice. We also discuss the possibility of applying SmartVoice to fields other than multi-language presentation support, such as Automated Dialogue Replacement and language study.","video":"http://www.youtube.com/embed/vuytIP0bHLE?rel=0","title":"SmartVoice: a presentation support system for overcoming the language barrier","filename":"CHI14/p1563","authors":["Xiang Li","Jun Rekimoto"],"conference":"CHI '14"}