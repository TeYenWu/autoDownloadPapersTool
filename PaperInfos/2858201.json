{"paperId":2858201,"citation":[],"reference":[{"content":"1. Martha Abednego, Joong-Ho Lee, Won Moon, and Ji-Hyung Park. 2009. I-Grabber: Expanding Physical Reach in a Large-display Tabletop Environment Through the Use of a Virtual Grabber. In Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces (ITS '09). ACM, NY, NY, USA, 61--64. DOI: http://dx.doi.org/10.1145/1731903.1731917","paperID":"None"},{"content":"2. Jeff Avery, Mark Choi, Daniel Vogel, and Edward Lank. 2014. Pinch-to-zoom-plus: An Enhanced Pinch-to-zoom That Reduces Clutching and Panning. In Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology (UIST '14). ACM, NY, NY, USA, 595--604. DOI: http://dx.doi.org/10.1145/2642918.2647352","paperID":"None"},{"content":"3. Ravin Balakrishnan and Ken Hinckley. 2000. Symmetric Bimanual Interaction. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '00). ACM, NY, NY, USA, 33--40. DOI:http://dx.doi.org/10.1145/332040.332404","paperID":"None"},{"content":"4. Hrvoje Benko, Andrew D. Wilson, and Patrick Baudisch. 2006. Precise Selection Techniques for Multi-touch Screens. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '06). ACM, NY, NY, USA, 1263--1272. DOI:http://dx.doi.org/10.1145/1124772.1124963","paperID":"None"},{"content":"5. Anastasia Bezerianos and Ravin Balakrishnan. 2005. The Vacuum: Facilitating the Manipulation of Distant Objects. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '05). ACM, NY, NY, USA, 361--370. DOI: http://dx.doi.org/10.1145/1054972.1055023","paperID":"None"},{"content":"6. Peter Brandl, Clifton Forlines, Daniel Wigdor, Michael Haller, and Chia Shen. 2008. Combining and Measuring the Benefits of Bimanual Pen and Direct-touch Interaction on Horizontal Interfaces. In Proceedings of the Working Conference on Advanced Visual Interfaces (AVI '08). ACM, NY, NY, USA, 154--161. DOI: http://dx.doi.org/10.1145/1385569.1385595","paperID":"None"},{"content":"7. W. Buxton and B. Myers. 1986. A Study in Two-handed Input. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '86). ACM, NY, NY, USA, 321--326. DOI: http://dx.doi.org/10.1145/22627.22390","paperID":"None"},{"content":"8. Yves Guiard. 1987. Asymmetric Division of Labor in Human Skilled Bimanual Action: The Kinematic Chain as a Model. In Journal of Motor Behavior, Vol. 19. 486--517.","paperID":"None"},{"content":"9. Yves Guiard and Michel Beaudouin-Lafon. 2004. Target Acquisition in Multiscale Electronic Worlds. Int. J. Hum.-Comput. Stud. 61, 6 (Dec. 2004), 875--905. DOI: http://dx.doi.org/10.1016/j.ijhcs.2004.09.005","paperID":"None"},{"content":"10. Ken Hinckley, Xiaojun Bi, Michel Pahud, and Bill Buxton. 2012. Informal Information Gathering Techniques for Active Reading. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '12). ACM, NY, NY, USA, 1893--1896. DOI: http://dx.doi.org/10.1145/2207676.2208327","paperID":"None"},{"content":"11. Ken Hinckley, Michel Pahud, Hrvoje Benko, Pourang Irani, François Guimbreti'ere, Marcel Gavriliu, Xiang 'Anthony' Chen, Fabrice Matulic, William Buxton, and Andrew Wilson. 2014. Sensing Techniques for Tablet+Stylus Interaction. In Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology (UIST '14). ACM, NY, NY, USA, 605--614. DOI: http://dx.doi.org/10.1145/2642918.2647379","paperID":"None"},{"content":"12. Ken Hinckley, Koji Yatani, Michel Pahud, Nicole Coddington, Jenny Rodenhouse, Andy Wilson, Hrvoje Benko, and Bill Buxton. 2010. Pen + Touch = New Tools. In Proceedings of the 23Nd Annual ACM Symposium on User Interface Software and Technology (UIST '10). ACM, NY, NY, USA, 27--36. DOI: http://dx.doi.org/10.1145/1866029.1866036","paperID":"None"},{"content":"13. Kenrick Kin, Maneesh Agrawala, and Tony DeRose. 2009. Determining the Benefits of Direct-touch, Bimanual, and Multifinger Input on a Multitouch Workstation. In Proceedings of Graphics Interface 2009 (GI '09). Canadian Information Processing Society, Toronto, Ont., Canada, Canada, 119--124. http: //dl.acm.org/citation.cfm?id=1555880.1555910","paperID":"None"},{"content":"14. Celine Latulipe, Craig S. Kaplan, and Charles L. A. Clarke. 2005. Bimanual and Unimanual Image Alignment: An Evaluation of Mouse-based Techniques. In Proceedings of the 18th Annual ACM Symposium on User Interface Software and Technology (UIST '05). ACM, NY, NY, USA, 123--131. DOI: http://dx.doi.org/10.1145/1095034.1095057","paperID":"None"},{"content":"15. Celine Latulipe, Stephen Mann, Craig S. Kaplan, and Charlie L. A. Clarke. 2006. symSpline: Symmetric Two-handed Spline Manipulation. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '06). ACM, NY, NY, USA, 349--358. DOI: http://dx.doi.org/10.1145/1124772.1124825","paperID":"None"},{"content":"16. Andrea Leganchuk, Shumin Zhai, and William Buxton. 1998. Manual and Cognitive Benefits of Two-handed Input: An Experimental Study. ACM Trans. Comput.-Hum. Interact. 5, 4 (Dec. 1998), 326--359. DOI:http://dx.doi.org/10.1145/300520.300522","paperID":"None"},{"content":"17. Pedro Lopes, Daniel Mendes, Bruno Araújo, and Joaquim A. Jorge. 2011. Combining Bimanual Manipulation and Pen-based Input for 3D Modelling. In Proceedings of the Eighth Eurographics Symposium on Sketch-Based Interfaces and Modeling (SBIM '11). ACM, NY, NY, USA, 15--22. DOI: http://dx.doi.org/10.1145/2021164.2021168","paperID":"None"},{"content":"18. Fabrice Matulic and Moira Norrie. 2012. Empirical Evaluation of Uni- and Bimodal Pen and Touch Interaction Properties on Digital Tabletops. In Proceedings of the 2012 ACM International Conference on Interactive Tabletops and Surfaces (ITS '12). ACM, NY, NY, USA, 143--152. DOI: http://dx.doi.org/10.1145/2396636.2396659","paperID":"None"},{"content":"19. Mathieu Nancel, Julie Wagner, Emmanuel Pietriga, Olivier Chapuis, and Wendy Mackay. 2011. Mid-air Pan-and-zoom on Wall-sized Displays. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '11). ACM, NY, NY, USA, 177--186. DOI: http://dx.doi.org/10.1145/1978942.1978969","paperID":"None"},{"content":"20. Ken Pfeuffer, Jason Alexander, Ming Ki Chong, and Hans Gellersen. 2014. Gaze-touch: Combining Gaze with Multi-touch for Interaction on the Same Surface. In Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology (UIST '14). ACM, NY, NY, USA, 509--518. DOI: http://dx.doi.org/10.1145/2642918.2647397","paperID":"None"},{"content":"21. Ken Pfeuffer, Jason Alexander, Ming Ki Chong, Yanxia Zhang, and Hans Gellersen. 2015. Gaze-Shifting: Direct-Indirect Input with Pen and Touch Modulated by Gaze. In Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology (UIST '15). ACM, NY, NY, USA, 373--383. DOI:http://dx.doi.org/10.1145/2807442.2807460","paperID":"None"},{"content":"22. Ken Pfeuffer, Jason Alexander, and Hans Gellersen. 2015. Gaze+touch vs. Touch: Whats the Trade-off When Using Gaze to Extend Touch to Remote Displays?. In Human-Computer Interaction INTERACT 2015 (Lecture Notes in Computer Science), Vol. 9297. Springer International Publishing, 349--367. DOI: http://dx.doi.org/10.1007/978--3--319--22668--2_27","paperID":"None"},{"content":"23. Sophie Stellmach and Raimund Dachselt. 2012a. Investigating Gaze-supported Multimodal Pan and Zoom. In Proceedings of the Symposium on Eye Tracking Research and Applications (ETRA '12). ACM, NY, NY, USA, 357--360. DOI: http://dx.doi.org/10.1145/2168556.2168636","paperID":"None"},{"content":"24. Sophie Stellmach and Raimund Dachselt. 2012b. Look & Touch: Gaze-supported Target Acquisition. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '12). ACM, NY, NY, USA, 2981--2990. DOI: http://dx.doi.org/10.1145/2207676.2208709","paperID":"None"},{"content":"25. Jayson Turner, Jason Alexander, Andreas Bulling, and Hans Gellersen. 2015. Gaze+RST: Integrating Gaze and Multitouch for Remote Rotate-Scale-Translate Tasks. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI '15). ACM, NY, NY, USA, 4179--4188. DOI: http://dx.doi.org/10.1145/2702123.2702355","paperID":"None"},{"content":"26. Simon Voelker, Andrii Matviienko, Johannes Schöning, and Jan Borchers. 2015. Combining Direct and Indirect Touch Input for Interactive Workspaces Using Gaze Input. In Proceedings of the 3rd ACM Symposium on Spatial User Interaction (SUI '15). ACM, NY, NY, USA, 79--88. DOI: http://dx.doi.org/10.1145/2788940.2788949","paperID":"None"},{"content":"27. Daniel Vogel and Ravin Balakrishnan. 2010. Occlusion-aware Interfaces. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '10). ACM, NY, NY, USA, 263--272. DOI: http://dx.doi.org/10.1145/1753326.1753365","paperID":"None"},{"content":"28. Daniel Vogel and Patrick Baudisch. 2007. Shift: A Technique for Operating Pen-based Interfaces Using Touch. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '07). ACM, NY, NY, USA, 657--666. DOI: http://dx.doi.org/10.1145/1240624.1240727","paperID":"None"},{"content":"29. Daniel Wigdor, Hrvoje Benko, John Pella, Jarrod Lombardo, and Sarah Williams. 2011. Rock & Rails: Extending Multi-touch Interactions with Shape Gestures to Enable Precise Spatial Manipulations. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '11). ACM, NY, NY, USA, 1581--1590. DOI: http://dx.doi.org/10.1145/1978942.1979173","paperID":"None"},{"content":"30. Mike Wu, Chia Shen, Kathy Ryall, Clifton Forlines, and Ravin Balakrishnan. 2006. Gesture Registration, Relaxation, and Reuse for Multi-Point Direct-Touch Surfaces. In Proceedings of the First IEEE International Workshop on Horizontal Interactive Human-Computer Systems (TABLETOP '06). IEEE Computer Society, Washington, DC, USA, 185--192. DOI: http://dx.doi.org/10.1109/TABLETOP.2006.19","paperID":"None"},{"content":"31. Ka-Ping Yee. 2004. Two-handed Interaction on a Tablet Display. In CHI '04 Extended Abstracts on Human Factors in Computing Systems (CHI EA '04). ACM, NY, NY, USA, 1493--1496. DOI: http://dx.doi.org/10.1145/985921.986098","paperID":"None"},{"content":"32. Dongwook Yoon, Nicholas Chen, François Guimbreti'ere, and Abigail Sellen. 2014. RichReview: Blending Ink, Speech, and Gesture to Support Collaborative Document Review. In Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology (UIST '14). ACM, NY, NY, USA, 481--490. DOI: http://dx.doi.org/10.1145/2642918.2647390","paperID":"None"},{"content":"33. Robert Zeleznik, Andrew Bragdon, Ferdi Adeputra, and Hsu-Sheng Ko. 2010. Hands-on Math: A Page-based Multi-touch and Pen Desktop for Technical Work and Problem Solving. In Proceedings of the 23rd Annual ACM Symposium on User Interface Software and Technology (UIST '10). ACM, NY, NY, USA, 17--26. DOI: http://dx.doi.org/10.1145/1866029.1866035","paperID":"None"},{"content":"34. Xinyong Zhang, Xiangshi Ren, and Hongbin Zha. 2008. Improving Eye Cursor's Stability for Eye Pointing Tasks. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '08). ACM, NY, NY, USA, 525--534. DOI: http://dx.doi.org/10.1145/1357054.1357139","paperID":"None"}],"abstract":"Bimanual pen and touch UIs are mainly based on the direct manipulation paradigm. Alternatively we propose partially-indirect bimanual input, where direct pen input is used with the dominant hand, and indirect-touch input with the non-dominant hand. As direct and indirect inputs do not overlap, users can interact in the same space without interference. We investigate two indirect-touch techniques combined with direct pen input: the first redirects touches to the user's gaze position, and the second redirects touches to the pen position. In this paper, we present an empirical user study where we compare both partially-indirect techniques to direct pen and touch input in bimanual pan, zoom, and ink tasks. Our experimental results show that users are comparatively fast with the indirect techniques, but more accurate as users can dynamically change the zoom-target during indirect zoom gestures. Further our studies reveal that direct and indirect zoom gestures have distinct characteristics regarding spatial use, gestural use, and bimanual parallelism.","title":"Partially-indirect Bimanual Input with Gaze, Pen, and Touch for Pan, Zoom, and Ink Interaction","filename":"CHI16/p2845","authors":["Ken Pfeuffer","Jason Alexander","Hans Gellersen"],"conference":"CHI '16"}