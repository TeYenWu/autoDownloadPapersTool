{"paperId":2557407,"reference":[{"content":"Andrea L. Ames, Just what they need, just when they need it: an introduction to embedded assistance, Proceedings of the 19th annual international conference on Computer documentation, October 21-24, 2001, Sante Fe, New Mexico, USA","paperID":"501539"},{"content":"Lawrence Bergman , Vittorio Castelli , Tessa Lau , Daniel Oblinger, DocWizards: a system for authoring follow-me documentation wizards, Proceedings of the 18th annual ACM symposium on User interface software and technology, October 23-26, 2005, Seattle, WA, USA","paperID":"1095067"},{"content":"Floraine Berthouzoz , Wilmot Li , Mira Dontcheva , Maneesh Agrawala, A Framework for content-adaptive photo manipulation macros: Application to face, landscape, and global manipulations, ACM Transactions on Graphics (TOG), v.30 n.5, p.1-14, October 2011","paperID":"2019639"},{"content":"Pei-Yu Chi , Sally Ahn , Amanda Ren , Mira Dontcheva , Wilmot Li , Björn Hartmann, MixT: automatic generation of step-by-step mixed media tutorials, Proceedings of the 25th annual ACM symposium on User interface software and technology, October 07-10, 2012, Cambridge, Massachusetts, USA","paperID":"2380130"},{"content":"Jennifer Fernquist , Tovi Grossman , George Fitzmaurice, Sketch-sketch revolution: an engaging tutorial system for guided sketching and application learning, Proceedings of the 24th annual ACM symposium on User interface software and technology, October 16-19, 2011, Santa Barbara, California, USA","paperID":"2047245"},{"content":"Lorenzo Gomez , Iulian Neamtiu , Tanzirul Azim , Todd Millstein, RERAN: timing- and touch-sensitive record and replay for Android, Proceedings of the 2013 International Conference on Software Engineering, May 18-26, 2013, San Francisco, CA, USA","paperID":"2486799"},{"content":"Google SketchUp Training. http://sketchup.google. com/intl/en/training/index.html.","paperID":"None"},{"content":"Floraine Grabler , Maneesh Agrawala , Wilmot Li , Mira Dontcheva , Takeo Igarashi, Generating photo manipulation tutorials by demonstration, ACM SIGGRAPH 2009 papers, August 03-07, 2009, New Orleans, Louisiana","paperID":"1531372"},{"content":"Tovi Grossman , George Fitzmaurice, ToolClips: an investigation of contextual video assistance for functionality understanding, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 10-15, 2010, Atlanta, Georgia, USA","paperID":"1753552"},{"content":"Tovi Grossman , Justin Matejka , George Fitzmaurice, Chronicle: capture, exploration, and playback of document workflow histories, Proceedings of the 23nd annual ACM symposium on User interface software and technology, October 03-06, 2010, New York, New York, USA","paperID":"1866054"},{"content":"Susan M. Harrison, A comparison of still, animated, or nonillustrated on-line help with written or spoken instructions in a graphical user interface, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, p.82-89, May 07-11, 1995, Denver, Colorado, USA","paperID":"223915"},{"content":"Niels Henze , Enrico Rukzio , Susanne Boll, 100,000,000 taps: analysis and improvement of touch performance in the large, Proceedings of the 13th International Conference on Human Computer Interaction with Mobile Devices and Services, August 30-September 02, 2011, Stockholm, Sweden","paperID":"2037395"},{"content":"Jeff Huang , Michael B. Twidale, Graphstract: minimal graphical help for computers, Proceedings of the 20th annual ACM symposium on User interface software and technology, October 07-10, 2007, Newport, Rhode Island, USA","paperID":"1294248"},{"content":"Caitlin Kelleher , Randy Pausch, Stencils-based tutorials: design and evaluation, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 02-07, 2005, Portland, Oregon, USA","paperID":"1055047"},{"content":"Kevin Knabe, Apple guide: a case study in user-aided design of online help, Conference Companion on Human Factors in Computing Systems, p.286-287, May 07-11, 1995, Denver, Colorado, USA","paperID":"223677"},{"content":"Benjamin Lafreniere , Tovi Grossman , George Fitzmaurice, Community enhanced tutorials: improving tutorials with multiple demonstrations, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 27-May 02, 2013, Paris, France","paperID":"2466235"},{"content":"Nielsen: Average Number of Apps per Smartphone. http://www.nielsen.com/us/en/newswire.html.","paperID":"None"},{"content":"Palaigeorgiou, G., and Despotakis, T. Known and unknown weaknesses in software animated demonstrations (screen-casts): A study in self-paced learning settings.","paperID":"None"},{"content":"Susan Palmiter , Jay Elkerton , P. Baggett, Animated demonstrations vs. written instructions for learning procedural tasks: a preliminary investigation, International Journal of Man-Machine Studies, v.34 n.5, p.687-701, May 1991","paperID":"107797"},{"content":"Palmiter, S., and Elkerton, J. Animated demonstrations for learning procedural computer-based tasks. 193216.","paperID":"None"},{"content":"Suporn Pongnumkul , Mira Dontcheva , Wilmot Li , Jue Wang , Lubomir Bourdev , Shai Avidan , Michael F. Cohen, Pause-and-play: automatically linking screencast video tutorials with applications, Proceedings of the 24th annual ACM symposium on User interface software and technology, October 16-19, 2011, Santa Barbara, California, USA","paperID":"2047213"},{"content":"Android core gesture set. http://developer.android. com/design/patterns/gestures.html.","paperID":"None"},{"content":"Daryl Weir , Simon Rogers , Roderick Murray-Smith , Markus Löchtefeld, A user-specific machine learning approach for improving touch accuracy on mobile devices, Proceedings of the 25th annual ACM symposium on User interface software and technology, October 07-10, 2012, Cambridge, Massachusetts, USA","paperID":"2380175"},{"content":"Susan Wiedenbeck , Patti L. Zila, Hands-on practice in learning to use software: a comparison of exercise, exploration, and combined formats, ACM Transactions on Computer-Human Interaction (TOCHI), v.4 n.2, p.169-196, June 1997","paperID":"254967"},{"content":"Tom Yeh , Tsung-Hsiang Chang , Robert C. Miller, Sikuli: using GUI screenshots for search and automation, Proceedings of the 22nd annual ACM symposium on User interface software and technology, October 04-07, 2009, Victoria, BC, Canada","paperID":"1622213"},{"content":"Tom Yeh , Tsung-Hsiang Chang , Bo Xie , Greg Walsh , Ivan Watkins , Krist Wongsuphasawat , Man Huang , Larry S. Davis , Benjamin B. Bederson, Creating contextual help for GUIs using screenshots, Proceedings of the 24th annual ACM symposium on User interface software and technology, October 16-19, 2011, Santa Barbara, California, USA","paperID":"2047214"}],"citation":[{"content":"Toshiyuki Hagiya , Tomonori Yazaki , Toshiharu Horiuchi , Tsuneo Kato, Typing Tutor: Automatic Error Detection and Instruction in Text Entry for Elderly People, Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct, August 24-27, 2015, Copenhagen, Denmark","paperID":"2793690"},{"content":"Mario Linares-Vásquez , Martin White , Carlos Bernal-Cárdenas , Kevin Moran , Denys Poshyvanyk, Mining Android app usages for generating actionable GUI-based execution scenarios, Proceedings of the 12th Working Conference on Mining Software Repositories, May 16-24, 2015, Florence, Italy","paperID":"2820534"}],"abstract":"We present EverTutor, a system that automatically generates interactive tutorials on smartphone from user demonstration. For tutorial authors, it simplifies the tutorial creation. For tutorial users, it provides contextual step-by-step guidance and avoids the frequent context switching between tutorials and users' primary tasks. In order to generate the tutorials automatically, EverTutor records low-level touch events to detect gestures and identify on-screen targets. When a tutorial is browsed, the system uses vision-based techniques to locate the target regions and overlays the corresponding input prompt contextually. It also identifies the correctness of users' interaction to guide the users step by step. We conducted a 6-person user study for creating tutorials and a 12-person user study for browsing tutorials, and we compared EverTutor's interactive tutorials to static and video ones. Study results show that creating tutorials by EverTutor is simpler and faster than producing static and video tutorials. Also, when using the tutorials, the task completion time for interactive tutorials were 3-6 times faster than static and video tutorials regardless of age group. In terms of user preference, 83% of the users chose interactive type as the preferred tutorial type and rated it easiest to follow and easiest to understand.","video":"http://www.youtube.com/embed/5QsUppdQ2rE?rel=0","title":"EverTutor: automatically creating interactive guided tutorials on smartphones by user demonstration","filename":"CHI14/p4027","authors":["Cheng-Yao Wang","Wei-Chen Chu","Hou-Ren Chen","Chun-Yen Hsu","Mike Y. Chen"],"conference":"CHI '14"}