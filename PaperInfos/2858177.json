{"paperId":2858177,"citation":[],"reference":[{"content":"2014. Bonjour. (2014). https://www.apple.com/support/bonjour/.","paperID":"None"},{"content":"2014. A Common Language for the Internet of Everything - AllJoyn. (2014). https://www.alljoyn.org/.","paperID":"None"},{"content":"2014. UPnP Forum. (2014). http://www.upnp.org/.","paperID":"None"},{"content":"2015. Barcode Scanner. (2015). https://play.google.com/store/apps/details?id=com. google.zxing.client.android&hl=en.","paperID":"None"},{"content":"2015. QRcode.com. (2015). http://www.qrcode.com/en/index.html.","paperID":"None"},{"content":"Florian Alt, Alireza Sahami Shirazi, Thomas Kubitza, and Albrecht Schmidt. 2013. Interaction techniques for creating and exchanging content with public displays. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems CHI '13. ACM Press, NY, NY, USA, 1709. DOI: http://dx.doi.org/10.1145/2470654.2466226","paperID":"None"},{"content":"Debasis Bandyopadhyay and Jaydip Sen. 2011. Internet of Things: Applications and Challenges in Technology and Standardization. Wireless Personal Communications 58, 1 (April 2011), 49--69. DOI: http://dx.doi.org/10.1007/s11277-011-0288-5","paperID":"None"},{"content":"Michael Beigl. 1999. Point & click-interaction in smart environments. In Handheld and Ubiquitous Computing. Springer, 311--313. DOI: http://dx.doi.org/10.1007/3--540--48157--5_31","paperID":"None"},{"content":"Victoria Bellotti, Maribeth Back, W Keith Edwards, Rebecca E Grinter, Austin Henderson, and Cristina Lopes. 2002. Making Sense of Sensing Systems: Five Questions for Designers and Researchers. 1 (2002), 415--422. DOI:http://dx.doi.org/10.1145/503376.503450","paperID":"None"},{"content":"Matthias Budde, Matthias Berning, Christopher Baumgärtner, Florian Kinn, Timo Kopf, Sven Ochs, Frederik Reiche, Till Riedel, and Michael Beigl. 2013. Point & control-interaction in smart environments: you only click twice. In Proceedings of the 2013 ACM conference on Pervasive and ubiquitous computing adjunct publication. ACM, 303--306. DOI: http://dx.doi.org/10.1145/2494091.2494184","paperID":"None"},{"content":"Tsung-Hsiang Chang and Yang Li. Deep shot: a framework for migrating tasks across devices using mobile phone cameras. In CHI '11. NY, NY, USA, 2163--2172. DOI: http://dx.doi.org/10.1145/1978942.1979257","paperID":"None"},{"content":"Yu-Hsiang Chen, Ben Zhang, Claire Tuna, Yang Li, Edward A Lee, and Bjï£¡rn Hartmann. 2013. A Context Menu for the Real World: Controlling Physical Appliances Through Head-Worn Infrared Targeting. Technical Report UCB/EECS-2013-200. EECS Department, University of California, Berkeley. DOI: http://dx.doi.org/No.UCB/EECS-2013-182","paperID":"None"},{"content":"Fred D Davis. 1985. A technology acceptance model for empirically testing new end-user information systems: theory and results. Ph.D. Dissertation. http://dspace.mit.edu/handle/1721.1/15192","paperID":"None"},{"content":"James R. Eagan, Michel Beaudouin-Lafon, and Wendy E. Mackay. 2011. Cracking the Cocoa Nut: User Interface Programming at Runtime. In Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology (UIST '11). ACM, NY, NY, USA, 225--234. DOI: http://dx.doi.org/10.1145/2047196.2047226","paperID":"None"},{"content":"David Fleer and Christian Leichsenring. 2012. MISO: a context-sensitive multimodal interface for smart objects based on hand gestures and finger snaps. In UIST Adjunct Proceedings '12. NY, NY, USA, 93--94. DOI:http://dx.doi.org/10.1145/2380296.2380338","paperID":"None"},{"content":"Peter Hamilton and Daniel J. Wigdor. 2014. Conductor. In CHI '14. NY, NY, USA, 2773--2782. DOI:http://dx.doi.org/10.1145/2556288.2557170","paperID":"None"},{"content":"Jonathon S Hare, Sina Samangooei, and David P Dupplaw. 2011. OpenIMAJ and ImageTerrier: Java libraries and tools for scalable multimedia analysis and indexing of images. In MM '11. NY, NY, USA, 691--694. DOI: http://dx.doi.org/10.1145/2072298.2072421","paperID":"None"},{"content":"Valentin Heun, Shunichi Kasahara, and Pattie Maes. 2013. Smarter Objects: Using AR Technology to Program Physical Objects and Their Interactions. In CHI '13 Extended Abstracts on Human Factors in Computing Systems (CHI EA '13). ACM, NY, NY, USA, 961--966. DOI: http://dx.doi.org/10.1145/2468356.2468528","paperID":"None"},{"content":"Todd D. Hodes, Randy H. Katz, Edouard Servan-Schreiber, and Lawrence Rowe. 1997. Composable ad-hoc mobile services for universal interaction. In MobiCom '97. NY, NY, USA, 1--12. DOI:http://dx.doi.org/10.1145/262116.262121","paperID":"None"},{"content":"Can Liu, Stephane Huot, Jonathan Diehl, Wendy Mackay, and Michel Beaudouin-Lafon. 2012. Evaluating the Benefits of Real-time Feedback in Mobile Augmented Reality with Hand-held Devices. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '12). ACM, NY, NY, USA, 2973--2976. DOI: http://dx.doi.org/10.1145/2207676.2208706","paperID":"None"},{"content":"Qiong Liu, Paul McEvoy, Don Kimber, Patrick Chiu, and Hanning Zhou. 2006. On Redirecting Documents with a Mobile Camera. In Workshop on Multimedia Signal Processing. 467--470. DOI: http://dx.doi.org/10.1109/MMSP.2006.285352","paperID":"None"},{"content":"D.G. Lowe. 1999. Object recognition from local scale-invariant features. In International Conference on Computer Vision, Vol. 2. 1150--1157. DOI: http://dx.doi.org/10.1109/ICCV.1999.790410","paperID":"None"},{"content":"Friedemann Mattern and Christian Floerkemeier. 2010. From the Internet of Computers to the Internet of Things. From Active Data Management to Event-Based Systems and More (Jan. 2010), 242--259. http://dl.acm.org/citation.cfm?id=1985625.1985645","paperID":"None"},{"content":"Simon Mayer, Markus Schalch, Marian George, and Gábor Sörös. 2013. Device recognition for intuitive interaction with the web of things. In UbiComp '13 Adjunct Proceedings. NY, NY, USA, 239--242. DOI: http://dx.doi.org/10.1145/2494091.2494168","paperID":"None"},{"content":"Daniele Miorandi, Sabrina Sicari, Francesco De Pellegrini, and Imrich Chlamtac. 2012. Internet of things: Vision, applications and research challenges. Ad Hoc Networks 10, 7 (Sept. 2012), 1497--1516. DOI: http://dx.doi.org/10.1016/j.adhoc.2012.02.016","paperID":"None"},{"content":"Matei Negulescu and Yang Li. 2013. Open project: a lightweight framework for remote sharing of mobile applications. In UIST '13. NY, NY, USA, 281--290. DOI: http://dx.doi.org/10.1145/2501988.2502030","paperID":"None"},{"content":"Jeffrey Nichols, Brad A. Myers, Michael Higgins, Joseph Hughes, Thomas K. Harris, Roni Rosenfeld, and Mathilde Pignol. 2002. Generating remote control interfaces for complex appliances. In UIST '02. NY, NY, USA, 161--170. DOI: http://dx.doi.org/10.1145/571985.572008","paperID":"None"},{"content":"Jeffrey Nichols, Brad A. Myers, and Brandon Rothrock. 2006. UNIFORM: automatically generating consistent remote control user interfaces. In CHI '06. NY, NY, USA, 611--620. DOI: http://dx.doi.org/10.1145/1124772.1124865","paperID":"None"},{"content":"Shwetak N Patel and Gregory D Abowd. In UbiComp '03. Springer, 200--207. DOI: http://dx.doi.org/10.1007/978-3-540-39653-6_16","paperID":"None"},{"content":"Jukka Riekki, Ivan Sanchez, and Mikko Pyykkönen. 2008. Universal Remote Control for the Smart World. In Ubiquitous Intelligence and Computing (Lecture Notes in Computer Science), Frode Eika Sandnes, Yan Zhang, Chunming Rong, Laurence T. Yang, and Jianhua Ma (Eds.), Vol. 5061. Berlin, Heidelberg, 563--577. DOI: http://dx.doi.org/10.1007/978-3-540-69293-5","paperID":"None"},{"content":"Matthias Ringwald. 2002. UbiControl: Providing New and Easy Ways to Interact with Various Consumer Devices. In UbiComp '02. 81,82.","paperID":"None"},{"content":"Ichiro Satoh. 2011. A Management Framework for Context-Aware Multimedia Services.. In DMS. 165--170.","paperID":"None"},{"content":"Dominik Schmidt, David Molyneaux, and Xiang Cao. 2012. PICOntrol: using a handheld projector for direct control of physical devices through visible light. In UIST '12. ACM Press, NY, NY, USA, 379--388. DOI:http://dx.doi.org/10.1145/2380116.2380166","paperID":"None"},{"content":"Chuong Cong Vo. 2013. A Framework for a Task-Oriented User Interaction with Smart Environments Using Mobile Devices. Ph.D. Dissertation. La Trobe University.","paperID":"None"},{"content":"Hanno Wirtz, Jan Rüth, Martin Serror, Jó Ágila Bitsch Link, and Klaus Wehrle. 2014. Opportunistic interaction in the challenged internet of things. Proceedings of the 9th ACM MobiCom workshop on Challenged networks CHANTS '14 (2014), 7--12. DOI: http://dx.doi.org/10.1145/2645672.2645679","paperID":"None"},{"content":"Jiahui Wu, Gang Pan, Daqing Zhang, Shijian Li, and Zhaohui Wu. 2010. MagicPhone: pointing & interacting. In UbiComp '10. NY, NY, USA, 451--452. DOI:http://dx.doi.org/10.1145/1864431.1864483","paperID":"None"}],"abstract":"The ability to quickly interact with any nearby appliance from a mobile device would allow people to perform a wide range of one-time tasks (e.g., printing a document in an unfamiliar office location). However, users currently lack this capability, and must instead manually configure their devices for each appliance they want to use. To address this problem, we created Snap-To-It, a system that allows users to opportunistically interact with any appliance simply by taking a picture of it. Snap-To-It shares the image of the appliance a user wants to interact with over a local area network. Appliances then analyze this image (along with the user's location and device orientation) to see if they are being \"selected,\" and deliver the corresponding control interface to the user's mobile device. Snap-To-It's design was informed by two technology probes that explored how users would like to select and interact with appliances using their mobile phone. These studies highlighted the need to be able to select hardware and software via a camera, and identified several novel use cases not supported by existing systems (e.g., interacting with disconnected objects, transferring settings between appliances). In this paper, we show how Snap-To-It's design is informed by our probes and how developers can utilize our system. We then show that Snap-To-It can identify appliances with over 95.3% accuracy, and demonstrate through a two-month deployment that our approach is robust to gradual changes to the environment.","title":"Snap-To-It: A User-Inspired Platform for Opportunistic Device Interactions","filename":"CHI16/p5909","authors":["Adrian A. de Freitas","Michael Nebeling","Xiang 'Anthony' Chen","Junrui Yang","Akshaye Shreenithi Kirupa Karthikeyan Ranithangam","Anind K. Dey"],"conference":"CHI '16"}