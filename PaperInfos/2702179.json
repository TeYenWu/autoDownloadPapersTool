{"paperId":2702179,"abstract":"We present a new real-time hand tracking system based on a single depth camera. The system can accurately reconstruct complex hand poses across a variety of subjects. It also allows for robust tracking, rapidly recovering from any temporary failures. Most uniquely, our tracker is highly flexible, dramatically improving upon previous approaches which have focused on front-facing close-range scenarios. This flexibility opens up new possibilities for human-computer interaction with examples including tracking at distances from tens of centimeters through to several meters (for controlling the TV at a distance), supporting tracking using a moving depth camera (for mobile scenarios), and arbitrary camera placements (for VR headsets). These features are achieved through a new pipeline that combines a multi-layered discriminative reinitialization strategy for per-frame pose estimation, followed by a generative model-fitting stage. We provide extensive technical details and a detailed qualitative and quantitative analysis.","reference":[{"content":"3Gear Systems Inc, 2013. http://threegear.com.","paperID":"None"},{"content":"Athitsos, V., and Sclaroff, S. Estimating 3D hand pose from a cluttered image. In Proc. CVPR (2003), II--432.","paperID":"None"},{"content":"Ballan, L., Taneja, A., Gall, J., van Gool, L., and Pollefeys, M. Motion capture of hands in action using discriminative salient points. In Proc. ECCV (2012), 640--653.","paperID":"None"},{"content":"Bray, M., Koller-Meier, E., and Van Gool, L. Smart particle filtering for 3D hand tracking. In Proc. IEEE Conf. Automatic Face and Gesture Recognition (2004), 675--680.","paperID":"None"},{"content":"Criminisi, A., and Shotton, J. Decision Forests for Computer Vision and Medical Image Analysis. Springer, 2013.","paperID":"None"},{"content":"de La Gorce, M., Fleet, D. J., and Paragios, N. Model-based 3D hand pose estimation from monocular video. IEEE Trans. PAMI 33, 9 (Feb. 2011), 1793--1805.","paperID":"None"},{"content":"Dipietro, L., Sabatini, A. M., and Dario, P. A survey of glove-based systems and their applications. IEEE Trans. Sys., Man, and Cybernetics C 38, 4 (2008), 461--482.","paperID":"None"},{"content":"Erol, A., Bebis, G., Nicolescu, M., Boyle, R. D., and Twombly, X. Vision-based hand pose estimation: A review. Comp. Vis. and Image Understanding 108 (2007), 52--73.","paperID":"None"},{"content":"Girshick, R., Shotton, J., Kohli, P., Criminisi, A., and Fitzgibbon, A. Efficient regression of general-activity human poses from depth images. In Proc. ICCV (2011), 415--422.","paperID":"None"},{"content":"Heap, T., and Hogg, D. Towards 3D hand tracking using a deformable model. In Proc. IEEE Conf. Automatic Face and Gesture Recognition (1996), 140--145.","paperID":"None"},{"content":"Juang, C.-F. A hybrid of genetic algorithm and particle swarm optimization for recurrent network design. IEEE Trans. Sys., Man, and Cybernetics B 34, 2 (April 2004), 997--1006.","paperID":"None"},{"content":"Keskin, C., Kiraç, F., Kara, Y. E., and Akarun, L. Hand pose estimation and hand shape classification using multi-layered randomized decision forests. In Proc. ECCV (2012), 852--863.","paperID":"None"},{"content":"Kim, D., Hilliges, O., Izadi, S., Butler, A. D., Chen, J., Oikonomidis, I., and Olivier, P. Digits: freehand 3D interactions anywhere using a wrist-worn gloveless sensor. In Proc. ACM UIST (2012), 167--176.","paperID":"None"},{"content":"Krupka, E., Bar Hillel, A., Klein, B., Vinnikov, A., Freedman, D., and Stachniak, S. Discriminative ferns ensemble for hand pose recognition. In Proc. CVPR (2014).","paperID":"None"},{"content":"Leap Motion Inc, 2014. http://leapmotion.com/product.","paperID":"None"},{"content":"Melax, S., Keselman, L., and Orsten, S. Dynamics based 3D skeletal hand tracking. In Proc. Graphics Interface (2013), 63--70.","paperID":"None"},{"content":"Oikonomidis, I., Kyriazis, N., and Argyros, A. Efficient model-based 3D tracking of hand articulations using Kinect. In Proc. BMVC (2011), 1--11.","paperID":"None"},{"content":"Oikonomidis, I., Kyriazis, N., and Argyros, A. A. Full DoF tracking of a hand interacting with an object by modeling occlusions and physical constraints. In Proc. ICCV (2011), 2088--2095.","paperID":"None"},{"content":"Oikonomidis, I., Kyriazis, N., and Argyros, A. A. Tracking the articulated motion of two strongly interacting hands. In Proc. CVPR (2012), 1862--1869.","paperID":"None"},{"content":"Qian, C., Sun, X., Wei, Y., Tang, X., and Sun, J. Realtime and robust hand tracking from depth. In Proc. CVPR (2014).","paperID":"None"},{"content":"Shotton, J., Fitzgibbon, A., Cook, M., Sharp, T., Finocchio, M., Moore, R., Kipman, A., and Blake, A. Real-time human pose recognition in parts from a single depth image. In Proc. CVPR (2011).","paperID":"None"},{"content":"Shotton, J., Sharp, T., Kohli, P., Nowozin, S., Winn, J., and Criminisi, A. Decision jungles: Compact and rich models for classification. In NIPS (2013).","paperID":"None"},{"content":"Sridhar, S., Oulasvirta, A., and Theobalt, C. Interactive markerless articulated hand motion tracking using RGB and depth data. In Proc. ICCV (Dec. 2013).","paperID":"None"},{"content":"Stenger, B., Mendoncça, P. R., and Cipolla, R. Model-based 3D tracking of an articulated hand. In Proc. CVPR (2001), II--310.","paperID":"None"},{"content":"Sun, M., Kohli, P., and Shotton, J. Conditional regression forests for human pose estimation. In Proc. CVPR (2012), 3394--3401.","paperID":"None"},{"content":"Tang, D., Chang, H. J., Tejani, A., and Kim, T.-K. Latent regression forest: Structured estimation of 3D articulated hand posture. In Proc. CVPR (2014), (in press).","paperID":"None"},{"content":"Tang, D., Yu, T.-H., and Kim, T.-K. Real-time articulated hand pose estimation using semi-supervised transductive regression forests. In Proc. ICCV (2013).","paperID":"None"},{"content":"Taylor, J., Shotton, J., Sharp, T., and Fitzgibbon, A. The Vitruvian Manifold: Inferring dense correspondences for one-shot human pose estimation. In Proc. CVPR (2012), 103--110.","paperID":"None"},{"content":"Taylor, J., Stebbing, R., Ramakrishna, V., Keskin, C., Shotton, J., Izadi, S., Hertzmann, A., and Fitzgibbon, A. User-specific hand modeling from monocular depth sequences. In Proc. CVPR (2014).","paperID":"None"},{"content":"Tompson, J., Stein, M., LeCun, Y., and Perlin, K. Real-time continuous pose recovery of human hands using convolutional networks. In ACM Trans. Graph. (2014).","paperID":"None"},{"content":"Wang, R., Paris, S., and Popović, J. 6D hands. In Proc. ACM UIST (New York, New York, USA, Oct. 2011), 549--558.","paperID":"None"},{"content":"Wang, R. Y., and Popović, J. Real-time hand-tracking with a color glove. In ACM Trans. Graph., vol. 28 (2009), 63:1--63:8.","paperID":"None"},{"content":"Wang, Y., Min, J., Zhang, J., Liu, Y., Xu, F., Dai, Q., and Chai, J. Video-based hand manipulation capture through composite motion control. ACM Trans. Graph. (2013).","paperID":"None"},{"content":"Wu, Y., and Huang, T. S. View-independent recognition of hand postures. In Proc. CVPR (2000), II:88--94.","paperID":"None"},{"content":"Wu, Y., Lin, J. Y., and Huang, T. S. Capturing natural hand articulation. In Proc. CVPR (2001), II:426--432.","paperID":"None"},{"content":"Xu, C., and Cheng, L. Efficient hand pose estimation from a single depth image. In Proc. ICCV (2013), 3456--3462.","paperID":"None"},{"content":"Yuille, A., and Kersten, D. Vision as Bayesian inference: analysis by synthesis? Trends in cognitive sciences 10, 7 (2006), 301--308.","paperID":"None"},{"content":"Zhao, W., Chai, J., and Xu, Y.-Q. Combining marker-based mocap and RGB-D camera for acquiring high-fidelity hand motion data. In Proc. Eurographics Symposium on Computer Animation (2012), 33--42.","paperID":"None"}],"citation":[{"content":"Seung-Tak Noh , Hui-Shyong Yeo , Woontack Woo, An HMD-based mixed reality system for avatar-mediated remote collaboration with bare-hand interaction, Proceedings of the 25th International Conference on Artificial Reality and Telexistence and 20th Eurographics Symposium on Virtual Environments, p.61-68, October 28-30, 2015, Kyoto, Japan","paperID":"2852322"},{"content":"Jiawei Huang , Tsuyoshi Mori , Kazuki Takashima , Shuichiro Hashi , Yoshifumi Kitamura, IM6D: magnetic tracking system with 6-DOF passive markers for dexterous 3D interaction and motion, ACM Transactions on Graphics (TOG), v.34 n.6, November 2015","paperID":"2818135"},{"content":"Xin Yi , Chun Yu , Mingrui Zhang , Sida Gao , Ke Sun , Yuanchun Shi, ATK: Enabling Ten-Finger Freehand Typing in Air Based on 3D Hand Tracking Data, Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology, November 08-11, 2015, Daegu, Kyungpook, Republic of Korea","paperID":"2807504"},{"content":"Matthias Schröder , Jonathan Maycock , Mario Botsch, Reduced marker layouts for optical motion capture of hands, Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, November 16-18, 2015, Paris, France","paperID":"2822026"},{"content":"Alexandre G. Szykman , João Paulo Gois , André Luiz Brandão, A Perspective of Games for People with Physical Disabilities, Proceedings of the Annual Meeting of the Australian Special Interest Group for Computer Human Interaction, December 07-10, 2015, Parkville, VIC, Australia","paperID":"2838765"}],"title":"Accurate, Robust, and Flexible Real-time Hand Tracking","filename":"CHI15/p3633","authors":["Toby Sharp","Cem Keskin","Duncan Robertson","Jonathan Taylor","Jamie Shotton","David Kim","Christoph Rhemann","Ido Leichter","Alon Vinnikov","Yichen Wei","Daniel Freedman","Pushmeet Kohli","Eyal Krupka","Andrew Fitzgibbon","Shahram Izadi"],"conference":"CHI '15"}