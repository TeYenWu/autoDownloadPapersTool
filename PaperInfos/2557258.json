{"paperId":2557258,"citation":[{"content":"Wouter Van Vlaenderen , Jens Brulmans , Jo Vermeulen , Johannes Sch√∂ning, WatchMe: A Novel Input Method Combining a Smartwatch and Bimanual Interaction, Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems, April 18-23, 2015, Seoul, Republic of Korea","paperID":"2732789"}],"reference":[{"content":"Sebastian Boring , David Ledo , Xiang 'Anthony' Chen , Nicolai Marquardt , Anthony Tang , Saul Greenberg, The fat thumb: using the thumb's contact size for single-handed mobile interaction, Proceedings of the 14th international conference on Human-computer interaction with mobile devices and services companion, September 21-24, 2012, San Francisco, California, USA","paperID":"2371711"},{"content":"Beverly L. Harrison , Kenneth P. Fishkin , Anuj Gujar , Carlos Mochon , Roy Want, Squeeze me, hold me, tilt me! An exploration of manipulative user interfaces, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, p.17-24, April 18-23, 1998, Los Angeles, California, USA","paperID":"274647"},{"content":"Chris Harrison , Scott Hudson, Using shear as a supplemental two-dimensional input channel for rich touchscreen interaction, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 05-10, 2012, Austin, Texas, USA","paperID":"2208730"},{"content":"Chris Harrison , Julia Schwarz , Scott E. Hudson, TapSense: enhancing finger interaction on touch surfaces, Proceedings of the 24th annual ACM symposium on User interface software and technology, October 16-19, 2011, Santa Barbara, California, USA","paperID":"2047279"},{"content":"Seongkook Heo , Geehyuk Lee, Force gestures: augmenting touch screen gestures with normal and tangential forces, Proceedings of the 24th annual ACM symposium on User interface software and technology, October 16-19, 2011, Santa Barbara, California, USA","paperID":"2047278"},{"content":"Seongkook Heo , Geehyuk Lee, Forcetap: extending the input vocabulary of mobile touch screens by adding tap gestures, Proceedings of the 13th International Conference on Human Computer Interaction with Mobile Devices and Services, August 30-September 02, 2011, Stockholm, Sweden","paperID":"2037393"},{"content":"Ken Hinckley , Hyunyoung Song, Sensor synaesthesia: touch in motion, and motion in touch, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 07-12, 2011, Vancouver, BC, Canada","paperID":"1979059"},{"content":"Christian Holz , Patrick Baudisch, Fiberio: a touchscreen that senses fingerprints, Proceedings of the 26th annual ACM symposium on User interface software and technology, October 08-11, 2013, St. Andrews, Scotland, United Kingdom","paperID":"2502021"},{"content":"Christian Holz , Patrick Baudisch, The generalized perceived input point model and how to double touch accuracy by extracting fingerprints, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 10-15, 2010, Atlanta, Georgia, USA","paperID":"1753413"},{"content":"Kurt Partridge , Saurav Chatterjee , Vibha Sazawal , Gaetano Borriello , Roy Want, TiltType: accelerometer-supported text entry for very small devices, Proceedings of the 15th annual ACM symposium on User interface software and technology, October 27-30, 2002, Paris, France","paperID":"572013"},{"content":"Anne Roudaut , Eric Lecolinet , Yves Guiard, MicroRolls: expanding touch-screen input vocabulary by distinguishing rolls vs. slides of the thumb, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 04-09, 2009, Boston, MA, USA","paperID":"1518843"},{"content":"Atsushi Sugiura , Yoshiyuki Koseki, A user interface using fingerprint recognition: holding commands and data objects on fingers, Proceedings of the 11th annual ACM symposium on User interface software and technology, p.71-79, November 01-04, 1998, San Francisco, California, USA","paperID":"288575"},{"content":"Daniel Wigdor , Ravin Balakrishnan, TiltText: using tilt for text input to mobile phones, Proceedings of the 16th annual ACM symposium on User interface software and technology, p.81-90, November 02-05, 2003, Vancouver, Canada","paperID":"964705"}],"abstract":"We present TouchSense, which provides additional touchscreen input vocabulary by distinguishing the areas of users' finger pads contacting the touchscreen. It requires minimal touch input area and minimal movement, making it especially ideal for wearable devices such as smart watches and smart glasses. For example, users of a calculator application on a smart watch could tap normally to enter numbers, and tap with the right side of their fingers to enter the operators (e.g. , -, =). Results from two human-factor studies showed that users could tap a touchscreen with five or more distinct areas of their finger pads. Also, they were able to tap with more distinct areas closer to their fingertips. We developed a TouchSense smart watch prototype using inertial measurement sensors, and developed two example applications: a calculator and a text editor. We also collected user feedback via an explorative study.","video":"http://www.youtube.com/embed/3UEW73zYHFs?rel=0","title":"TouchSense: expanding touchscreen input vocabulary using different areas of users' finger pads","filename":"CHI14/p189","authors":["Da-Yuan Huang","Ming-Chang Tsai","Ying-Chao Tung","Min-Lun Tsai","Yen-Ting Yeh","Liwei Chan","Yi-Ping Hung","Mike Y. Chen"],"conference":"CHI '14"}