{"paperId":2858320,"citation":[],"reference":[{"content":"Dirk Bartz, Douglas Cunningham, Jan Fischer, and Christian Wallraven. 2008. The Role of Perception for Computer Graphics. Eurographics state-of-the-art-reports (2008), 65--86. DOI: http://dx.doi.org/10.2312/egst.20081045","paperID":"None"},{"content":"K Tiplitz Blackwell and G Buchsbaum. 1988. The effect of spatial and chromatic parameters on chromatic induction. Color Research & Application 13, 3 (1988), 166-173. DOI: http://dx.doi.org/10.1002/col.5080130309","paperID":"None"},{"content":"Wei-Chung Cheng and Aldo Badano. 2010. A gaze-contingent high-dynamic range display for medical imaging applications. SPIE Medical Imaging 7627 (March 2010), 76270A-76270A-6. DOI: http://dx.doi.org/10.1117/12.845782","paperID":"None"},{"content":"Ken Chiu, Michael Herf, Peter Shirley, S Swamy, Changyaw Wang, Kurt Zimmerman, and Others. 1993. Spatially nonuniform scaling functions for high contrast images. In Graphics Interface. 245. DOI: http://dx.doi.org/10.1.1.136.5090","paperID":"None"},{"content":"Geoff Cumming. 2013. Understanding the new statistics: Effect sizes, confidence intervals, and meta-analysis. Routledge.","paperID":"None"},{"content":"Andrew T. Duchowski and Tiras D Eaddy. 2009. A gaze-contingent display compensating for scotomata. Eurographics (2009).","paperID":"None"},{"content":"David E. Jacobs, Orazio Gallo, Emily A. Cooper, Kari Pulli, and Marc Levoy. 2015. Simulating the Visual Experience of Very Bright and Very Dark Scenes. ACM Transactions on Graphics 34, 3 (May 2015), 25:1--25:15. DOI: http://dx.doi.org/10.1145/2714573","paperID":"None"},{"content":"Eyexblog.tobii.com. 2015a. Avalanche Studios has you literally looking to bag your next trophy | Tobii EyeX Blog. (2015). http://eyexblog.tobii.com/avalanche-studios-has-you-literally-looking-for-your-next-kill/","paperID":"None"},{"content":"Eyexblog.tobii.com. 2015b. Foveated Rendering in VR = easy peasy with Tobii & Starbreeze new collaboration. | Tobii EyeX Blog. (2015). http://eyexblog.tobii.com/starvr/","paperID":"None"},{"content":"Mark D. Fairchild. 2013. Color Appearance Models (3 ed.). Wiley. 408 pages.","paperID":"None"},{"content":"Dean Farnsworth. 1943. The Farnsworth-Munsell 100-Hue and Dichotomous Tests for Color Vision. Journal of the Optical Society of America 33, 10 (Oct. 1943), 568. DOI: http://dx.doi.org/10.1364/JOSA.33.000568","paperID":"None"},{"content":"E. Bruce Goldstein. 2013. Sensation and perception. Cengage Learning.","paperID":"None"},{"content":"Brian Guenter, Mark Finch, Steven Drucker, Desney Tan, and John Snyder. 2012. Foveated 3D graphics. ACM Transactions on Graphics 31, 6 (2012), 1. DOI: http://dx.doi.org/10.1145/2366145.2366183","paperID":"None"},{"content":"Robert W G Hunt. 1952. Light and dark adaptation and the perception of color. JOSA 42, 3 (1952), 190-199.","paperID":"None"},{"content":"Robert W G Hunt. 1987. A model of colour vision for predicting colour appearance in various viewing conditions. Color Research & Application 12, 6 (1987), 297-314. DOI: http://dx.doi.org/10.1002/col.5080120605","paperID":"None"},{"content":"Robert William Gainer Hunt. 1994. An improved predictor of colourfulness in a model of colour vision. Color Research and Application 19, 1 (1994), 23 - 26. DOI: http://dx.doi.org/10.1111/j.1520--6378.1994.tb00056.x","paperID":"None"},{"content":"Dorothea Jameson and Leo M Hurvich. 1961. Opponent chromatic induction: experimental evaluation and theoretical account. Journal of the Optical Society of America 51, 1 (1961), 46-53. DOI: http://dx.doi.org/10.1364/JOSA.51.000046","paperID":"None"},{"content":"Daniel J Jobson, Zia-ur Rahman, and Glenn A Woodell. 1996. Retinex image processing: Improved fidelity to direct visual observation. In Color and Imaging Conference, Vol. 1996. Society for Imaging Science and Technology, 124-125. DOI: http://dx.doi.org/10.1.1.98.6865","paperID":"None"},{"content":"Gordon Kindlmann, Erik Reinhard, Sarah Creem, and Sarah Kindlmann, Gordon and Reinhard, Erik and Creem. 2002. Face-based luminance matching for perceptual colormap generation. In Proceedings of the conference on Visualization (VIS '02). IEEE, IEEE Computer Society, Washington, DC, USA, 299-306. DOI: http://dx.doi.org/10.1109/VISUAL.2002.1183788","paperID":"None"},{"content":"Rex B Kline. 2004. Beyond significance testing: Reforming data analysis methods in behavioral research. (2004).","paperID":"None"},{"content":"Sheng Liu and Hong Hua. 2008. Spatialchromatic Foveation for Gaze Contingent Displays. In Proceedings of the 2008 Symposium on Eye Tracking Research & Applications (ETRA '08). ACM, NY, NY, USA, 139-142. DOI: http://dx.doi.org/10.1145/1344471.1344507","paperID":"None"},{"content":"Thomas Mansencal, Michael Mauderer, and Michael Parsons. 2015. Colour 0.3.6. (Aug. 2015). DOI: http://dx.doi.org/10.5281/zenodo.27234","paperID":"None"},{"content":"Radoslaw Mantiuk and Mateusz Markowski. 2013. Gaze-Dependent Tone Mapping. In Image Analysis and Recognition. 426-433. DOI: http://dx.doi.org/10.1007/978--3--642--39094--4_48","paperID":"None"},{"content":"Michael Mauderer, Simone Conte, Miguel A Nacenta, and Dhanraj Vishwanath. 2014. Depth perception with gaze-contingent depth of field. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 217-226. DOI: http://dx.doi.org/10.1145/2556288.2557089","paperID":"None"},{"content":"Nathan Moroney, Mark D Fairchild, Robert W G Hunt, Changjun Li, M Ronnier Luo, and Todd Newman. 2002. The CIECAM02 color appearance model. In Color and Imaging Conference, Vol. 2002. Society for Imaging Science and Technology, 23-27. DOI: http://dx.doi.org/10.1.1.77.8398","paperID":"None"},{"content":"Hunter Murphy and Andrew T Duchowski. 2001. Gaze-contingent level of detail rendering. Eurographics (2001).","paperID":"None"},{"content":"Xavier Otazu, Olivier Penacchio, and Laura Dempere-Marco. 2012. Brightness induction by contextual influences in V1: a neurodynamical account. Journal of Vision 12, 9 (Aug. 2012), 1208-1208. DOI: http://dx.doi.org/10.1167/12.9.1208","paperID":"None"},{"content":"Jonathan W Peirce. 2009. Generating stimuli for neuroscience using PsychoPy. Frontiers in Neuroinformatics 2, 10 (2009). DOI: http://dx.doi.org/10.3389/neuro.11.010.2008","paperID":"None"},{"content":"Susanto Rahardja, Farzam Farbiz, and Corey Manders. 2009. Eye HDR: Gaze-adaptive system for displaying high-dynamic-range images. SIGGRAPH ASIA Art Gallery & Emerging Technologies (2009), 68-68. DOI: http://dx.doi.org/10.1145/1665137.1665187","paperID":"None"},{"content":"Eyal M Reingold, Lester C Loschky, George W McConkie, and David M Stampe. 2003. Gaze-contingent multiresolutional displays: an integrative review. Human factors 45, 2 (June 2003), 307-328. DOI: http://dx.doi.org/10.1518/hfes.45.2.307.27235","paperID":"None"},{"content":"Erik Reinhard, Wolfgang Heidrich, Paul Debevec, Sumanta Pattanaik, Greg Ward, and Karol Myszkowski. 2010. High dynamic range imaging: acquisition, display, and image-based lighting (1 ed.). Morgan Kaufmann. 520 pages.","paperID":"None"},{"content":"Alan R Robertson. 1977. The CIE 1976 Color-Difference Formulae. Color Research & Application 2, 1 (1977), 7-11. DOI: http://dx.doi.org/10.1002/j.1520--6378.1977.tb00104.x","paperID":"None"},{"content":"Alan R Robertson. 1990. Historical development of CIE recommended color difference equations. Color Research & Application 15, 3 (1990), 167-170. DOI: http://dx.doi.org/10.1002/col.5080150308","paperID":"None"},{"content":"Athanassios Skodras, Charilaos Christopoulos, and Touradj Ebrahimi. 2001. The JPEG 2000 still image compression standard. Signal Processing Magazine 18, 5 (2001), 36-58. DOI: http://dx.doi.org/10.1109/79.952804","paperID":"None"},{"content":"Ian Spence, Natasha Kutlesa, and David L Rose. 1999. Using Color to Code Quantity in Spatial Displays. Journal of Experimental Psychology: Applied 5, 4 (1999), 393-412. DOI: http://dx.doi.org/10.1037/1076--898X.5.4.393","paperID":"None"},{"content":"Steelseries.com. 2015. sentry gaming eye tracker | SteelSeries. (2015). https://steelseries.com/gaming-controllers/sentry-gaming-eye-tracker","paperID":"None"},{"content":"Margarita Vinnikov and Robert S Allison. 2014. Gaze-contingent Depth of Field in Realistic Scenes: The User Experience. In Proceedings of the Symposium on Eye Tracking Research and Applications (ETRA '14). ACM, NY, NY, USA, 119-126. DOI: http://dx.doi.org/10.1145/2578153.2578170","paperID":"None"},{"content":"Gregory K Wallace. 1991. The JPEG still picture compression standard. Commun. ACM 34, 4 (1991), 30-44.","paperID":"None"},{"content":"Michel Wedel and Rik Pieters. 2008. A review of eye-tracking research in marketing. Review of marketing research 4, 2008 (2008), 123-147. DOI: http://dx.doi.org/10.1108/S1548--6435(2008)0000004009","paperID":"None"},{"content":"Wikipedia. 2015. The dress (viral phenomenon). (2015). https://en.wikipedia.org/wiki/The_dress_(viral_phenomenon)","paperID":"None"},{"content":"Takuya Yamauchi, Toshiaki Mikami, and Osama Ouda. 2011. Improvement and evaluation of real-time tone mapping for high dynamic range images using gaze information. Computer Vision - ACCV 2010 Workshops (2011), 440-449. DOI: http://dx.doi.org/10.1007/978--3--642--22822--3_44","paperID":"None"},{"content":"Lingyun Yu, Konstantinos Efstathiou, Petra Isenberg, and Tobias Isenberg. 2015. CAST: Effective and Efficient User Interaction for Context-Aware Selection in 3D Particle Clouds. (2015). DOI: http://dx.doi.org/10.1109/TVCG.2015.2467202","paperID":"None"}],"abstract":"Using real time eye tracking, gaze-contingent displays can modify their content to represent depth (e.g., through additional depth cues) or to increase rendering performance (e.g., by omitting peripheral detail). However, there has been no research to date exploring how gaze-contingent displays can be leveraged for manipulating perceived color. To address this, we conducted two experiments (color matching and sorting) that manipulated peripheral background and object colors to influence the user's color perception. Findings from our color matching experiment suggest that we can use gaze-contingent simultaneous contrast to affect color appearance and that existing color appearance models might not fully predict perceived colors with gaze-contingent presentation. Through our color sorting experiment we demonstrate how gaze-contingent adjustments can be used to enhance color discrimination. Gaze-contingent color holds the promise of expanding the perceived color gamut of existing display technology and enabling people to discriminate color with greater precision.","title":"Gaze-Contingent Manipulation of Color Perception","filename":"CHI16/p5191","authors":["Michael Mauderer","David R. Flatla","Miguel A. Nacenta"],"conference":"CHI '16"}