{"paperId":2858480,"citation":[],"reference":[{"content":"Bellotti, V., Back, M., Edwards, W. K., Grinter, R. E., Henderson, A., and Lopes, C. Making sense of sensing systems: five questions for designers and researchers. In Proc. CHI'02, ACM (2002), 415-422.","paperID":"None"},{"content":"Bi, X., and Zhai, S. Bayesian touch: a statistical criterion of target selection with finger touch. In Proc. UIST'13, ACM (2013), 51-60.","paperID":"None"},{"content":"Bieg, H.-J., Chuang, L. L., Fleming, R. W., Reiterer, H., and Bulthoff, H. H. Eye and pointer coordination in search and selection tasks. In Proc. ETRA'10, ACM (2010), 89-92.","paperID":"None"},{"content":"Blanch, R., and Ortega, M. Rake cursor: improving pointing performance with concurrent input channels. In Proc. CHI'09, ACM (2009), 1415-1418.","paperID":"None"},{"content":"Bock, O., and Eckmiller, R. Goal-directed arm movements in absence of visual guidance: evidence for amplitude rather than position control. Experimental Brain Research 62, 3 (1986), 451-458.","paperID":"None"},{"content":"Brown, L. E., Rosenbaum, D. A., and Sainburg, R. L. Limb position drift: implications for control of posture and movement. Journal of Neurophysiology 90, 5 (2003), 3105-3118.","paperID":"None"},{"content":"Butscher, S., Hornb√¶k, K., and Reiterer, H. Spacefold and physiclenses: simultaneous multifocus navigation on touch surfaces. In Proc. AVI'14, ACM (2014), 209-216.","paperID":"None"},{"content":"Elmqvist, N., Riche, Y., Henry-Riche, N., and Fekete, J.-D. Melange: Space folding for visual exploration. IEEE TVCG 16, 3 (2010), 468-483.","paperID":"None"},{"content":"Fitzmaurice, G. W., and Buxton, W. An empirical evaluation of graspable user interfaces: towards specialized, space-multiplexed input. In Proc. UIST'97, ACM (1997), 43-50.","paperID":"None"},{"content":"Fitzmaurice, G. W., Ishii, H., and Buxton, W. A. Bricks: laying the foundations for graspable user interfaces. In Proc. CHI'95, ACM (1995), 442-449.","paperID":"None"},{"content":"Flanagan, J. R., Terao, Y., and Johansson, R. S. Gaze behavior when reaching to remembered targets. Journal of neurophysiology 100, 3 (2008), 1533-1543.","paperID":"None"},{"content":"Flemisch, F. O., Adams, C. A., Conway, S. R., Goodrich, K. H., Palmer, M. T., and Schutte, P. C. The h-metaphor as a guideline for vehicle automation and interaction.","paperID":"None"},{"content":"Goodwin, C. Pointing: Where language, culture and cognition meet. Lawrence Erlbaum Associates, 2003, ch. Pointing as situated practice, 217-241.","paperID":"None"},{"content":"Hagiya, T., and Kato, T. Probabilistic touchscreen text entry method incorporating gaze point information. Journal of Information Processing 23, 5 (2015), 708-715.","paperID":"None"},{"content":"Huang, J., White, R., and Buscher, G. User see, user point: gaze and cursor alignment in web search. In Proc. CHI'12, ACM (2012), 1341-1350.","paperID":"None"},{"content":"Jacob, R. J. What you look at is what you get: eye movement-based interaction techniques. In Proc. CHI'90, ACM (1990), 11-18.","paperID":"None"},{"content":"Jacucci, G., Spagnolli, A., Freeman, J., and Gamberini, L. Symbiotic interaction: a critical definition and comparison to other human-computer paradigms. In Symbiotic Interaction'14. Springer, 2014, 3-20.","paperID":"None"},{"content":"Kosunen, I., Jylha, A., Ahmed, I., An, C., Chech, L., Gamberini, L., Cavazza, M., and Jacucci, G. Comparing eye and gesture pointing to drag items on large screens. In Proc. ITS'13, ACM (2013), 425-428.","paperID":"None"},{"content":"Kumar, M., Paepcke, A., and Winograd, T. Eyepoint: practical pointing and selection using gaze and keyboard. In Proc. CHI'07, ACM (2007), 421-430.","paperID":"None"},{"content":"Mankoff, J., Hudson, S. E., and Abowd, G. D. Providing integrated toolkit-level support for ambiguity in recognition-based interfaces. In Proc. CHI'00, ACM (2000), 368-375.","paperID":"None"},{"content":"Pfeuffer, K., Alexander, J., Chong, M. K., and Gellersen, H. Gaze-touch: Combining gaze with multi-touch for interaction on the same surface. In Proc. UIST'14, ACM (2014), 509-518.","paperID":"None"},{"content":"Pfeuffer, K., Alexander, J., Chong, M. K., Zhang, Y., and Gellersen, H. Gaze-shifting: Direct-indirect input with pen and touch modulated by gaze. In Proc. UIST'15, ACM (2015), 373-383.","paperID":"None"},{"content":"Pohl, H., and Murray-Smith, R. Focused and casual interactions: Allowing users to vary their level of engagement. In Proc. CHI'13, ACM (2013), 2223-2232.","paperID":"None"},{"content":"Rodden, K., Fu, X., Aula, A., and Spiro, I. Eye-mouse coordination patterns on web search results pages. In Proc. CHI EA'08, ACM (2008), 2997-3002.","paperID":"None"},{"content":"Schwarz, J., Hudson, S., Mankoff, J., and Wilson, A. D. A framework for robust and flexible handling of inputs with uncertainty. In Proc. UIST'10, ACM (2010), 47-56.","paperID":"None"},{"content":"Schwarz, J., Mankoff, J., and Hudson, S. E. An architecture for generating interactive feedback in probabilistic user interfaces. In Proc. CHI'15, ACM (2015), 2545-2554.","paperID":"None"},{"content":"Serim, B. Querying and display of information: symbiosis in exploratory search interaction scenarios. In Symbiotic Interaction'14. Springer, 2014, 115-120.","paperID":"None"},{"content":"Sibert, L. E., and Jacob, R. J. Evaluation of eye gaze interaction. In Proc. CHI'00, ACM (2000), 281-288.","paperID":"None"},{"content":"Spijkers, W., and Spellerberg, S. On-line visual control of aiming movements? Acta psychologica 90, 1 (1995), 333-348.","paperID":"None"},{"content":"Stellmach, S., and Dachselt, R. Look & touch: gaze-supported target acquisition. In Proc. CHI'12, ACM (2012), 2981-2990.","paperID":"None"},{"content":"Stellmach, S., and Dachselt, R. Still looking: investigating seamless gaze-supported selection, positioning, and manipulation of distant targets. In Proc. CHI'13, ACM (2013), 285-294.","paperID":"None"},{"content":"Tuddenham, P., Kirk, D., and Izadi, S. Graspables revisited: multi-touch vs. tangible input for tabletop displays in acquisition and manipulation tasks. In Proc. CHI'10, ACM (2010), 2223-2232.","paperID":"None"},{"content":"Turner, J., Alexander, J., Bulling, A., Schmidt, D., and Gellersen, H. Eye pull, eye push: Moving objects between large screens and personal devices with gaze and touch. In INTERACT'2013. Springer, 2013, 170-186.","paperID":"None"},{"content":"Ware, C., and Mikaelian, H. H. An evaluation of an eye tracker as a device for computer input. In Proc. CHI'87, ACM (1987), 183-188.","paperID":"None"},{"content":"Weir, D., Pohl, H., Rogers, S., Vertanen, K., and Kristensson, P. O. Uncertain text entry on mobile devices. In Proc. CHI'14, ACM (2014), 2307-2316.","paperID":"None"},{"content":"Weiss, M., Wacharamanotham, C., Voelker, S., and Borchers, J. Fingerflux: near-surface haptic feedback on tabletops. In Proc. UIST'11, ACM (2011), 615-620.","paperID":"None"},{"content":"Weiss, M., Wagner, J., Jansen, Y., Jennings, R., Khoshabeh, R., Hollan, J. D., and Borchers, J. Slap widgets: bridging the gap between virtual and physical controls on tabletops. In Proc. CHI'09, ACM (2009), 481-490.","paperID":"None"},{"content":"Wigdor, D., Williams, S., Cronin, M., Levy, R., White, K., Mazeev, M., and Benko, H. Ripples: utilizing per-contact visualizations to improve user interaction with touch displays. In Proc. UIST'09, ACM (2009), 3-12.","paperID":"None"},{"content":"Williamson, J. Continuous uncertain interaction. PhD thesis, University of Glasgow, 2006.","paperID":"None"},{"content":"Wu, J., Yang, J., and Honda, T. Fitts law holds for pointing movements under conditions of restricted visual feedback. Human movement science 29, 6 (2010), 882-892.","paperID":"None"},{"content":"Zhai, S., Morimoto, C., and Ihde, S. Manual and gaze input cascaded (magic) pointing. In Proc. CHI'99, ACM (1999), 246-253.","paperID":"None"}],"abstract":"We propose using eye tracking to support interface use with decreased reliance on visual guidance. While the design of most graphical user interfaces take visual guidance during manual input for granted, eye tracking allows distinguishing between the cases when the manual input is conducted with or without guidance. We conceptualize the latter cases as input with uncertainty that require separate handling. We describe the design space of input handling by utilizing input resources available to the system, possible actions the system can realize and various feedback techniques for informing the user. We demonstrate the particular action mechanisms and feedback techniques through three applications we developed for touch interaction on a large screen. We conducted a two stage study of positional accuracy during target acquisition with varying visual guidance, to determine the selection range around a touch point due to positional uncertainty. We also conducted a qualitative evaluation of example applications with participants to identify perceived utility and hand eye coordination challenges while using interfaces with decreased visual guidance.","title":"Pointing while Looking Elsewhere: Designing for Varying Degrees of Visual Guidance during Manual Input","filename":"CHI16/p5789","authors":["Baris Serim","Giulio Jacucci"],"conference":"CHI '16"}