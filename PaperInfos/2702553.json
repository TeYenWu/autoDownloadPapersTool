{"paperId":2702553,"abstract":"In the past half-decade, Amazon Mechanical Turk has radically changed the way many scholars do research. The availability of a massive, distributed, anonymous crowd of individuals willing to perform general human-intelligence micro-tasks for micro-payments is a valuable resource for researchers and practitioners. This paper addresses the challenges of obtaining quality annotations for subjective judgment oriented tasks of varying difficulty. We design and conduct a large, controlled experiment (N=68,000) to measure the efficacy of selected strategies for obtaining high quality data annotations from non-experts. Our results point to the advantages of person-oriented strategies over process-oriented strategies. Specifically, we find that screening workers for requisite cognitive aptitudes and providing training in qualitative coding techniques is quite effective, significantly outperforming control and baseline conditions. Interestingly, such strategies can improve coder annotation accuracy above and beyond common benchmark strategies such as Bayesian Truth Serum (BTS).","citation":[{"content":"Michelle Fung , Yina Jin , RuJie Zhao , Mohammed (Ehsan) Hoque, ROC speak: semi-automated personalized feedback on nonverbal behavior from recorded videos, Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing, September 07-11, 2015, Osaka, Japan","paperID":"2804265"},{"content":"M. Iftekhar Tanveer , Ru Zhao , Kezhen Chen , Zoe Tiet , Mohammed Ehsan Hoque, AutoManner: An Automated Interface for Making Public Speakers Aware of Their Mannerisms, Proceedings of the 21st International Conference on Intelligent User Interfaces, March 07-10, 2016, Sonoma, California, USA","paperID":"2856785"},{"content":"Sanjay Kairam , Jeffrey Heer, Parting Crowds: Characterizing Divergent Interpretations in Crowdsourced Annotation Tasks, Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work & Social Computing, February 27-March 02, 2016, San Francisco, California, USA","paperID":"2820016"},{"content":"Joel Chan , Steven Dang , Steven P. Dow, Improving Crowd Innovation with Expert Facilitation, Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work & Social Computing, February 27-March 02, 2016, San Francisco, California, USA","paperID":"2820023"}],"reference":[{"content":"Paul Andr√© , Aniket Kittur , Steven P. Dow, Crowd synthesis: extracting categories and clusters from complex data, Proceedings of the 17th ACM conference on Computer supported cooperative work & social computing, February 15-19, 2014, Baltimore, Maryland, USA","paperID":"2531653"},{"content":"Berinsky, A.J., Huber, G.A., and Lenz, G.S. Evaluating Online Labor Markets for Experimental Research: Amazon.com's Mechanical Turk. Political Analysis 20, 3 2012, 351--368.","paperID":"None"},{"content":"David M. Blei , Andrew Y. Ng , Michael I. Jordan, Latent dirichlet allocation, The Journal of Machine Learning Research, 3, p.993-1022, 3/1/2003","paperID":"944937"},{"content":"Carlos Castillo , Marcelo Mendoza , Barbara Poblete, Information credibility on twitter, Proceedings of the 20th international conference on World wide web, March 28-April 01, 2011, Hyderabad, India","paperID":"1963500"},{"content":"Chang, J., Boyd-Graber, J., Gerrish, S., Wang, C., and Blei, D. Reading Tea Leaves: How Humans Interpret Topic Models. NIPS 2009, 288--296. https://www.mturk.com/mturk/help?helpPage=worker","paperID":"None"},{"content":"Crump, M.J.C., McDonnell, J.V., and Gureckis, T.M. Evaluating Amazon's Mechanical Turk as a Tool for Experimental Beh. Res. PLoS ONE 8, 3 2013.","paperID":"None"},{"content":"Navneet Dalal , Bill Triggs, Histograms of Oriented Gradients for Human Detection, Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Volume 1, p.886-893, June 20-26, 2005","paperID":"1069007"},{"content":"Julie S. Downs , Mandy B. Holbrook , Steve Sheng , Lorrie Faith Cranor, Are your participants gaming the system?: screening mechanical turk workers, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 10-15, 2010, Atlanta, Georgia, USA","paperID":"1753688"},{"content":"Eric Gilbert, What if we ask a different question?: social inferences create product ratings faster, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 26-May 01, 2014, Toronto, Ontario, Canada","paperID":"2557081"},{"content":"Hart, S.G. and Staveland, L.E. Development of NASATLX (Task Load Index): Results of empirical and theoretical research. Adv. in psych. 52, 1988, 139--183.","paperID":"None"},{"content":"Jeffrey Heer , Michael Bostock, Crowdsourcing graphical perception: using mechanical turk to assess visualization design, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 10-15, 2010, Atlanta, Georgia, USA","paperID":"1753357"},{"content":"Shih-Wen Huang , Wai-Tat Fu, Don't hide in the crowd!: increasing social transparency between peer workers improves crowdsourcing outcomes, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 27-May 02, 2013, Paris, France","paperID":"2470743"},{"content":"Hutto, C.J. and Gilbert, E. VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. ICWSM 2014, 216--255.","paperID":"None"},{"content":"Panagiotis G. Ipeirotis, Analyzing the Amazon Mechanical Turk marketplace, XRDS: Crossroads, The ACM Magazine for Students, v.17 n.2, Winter 2010","paperID":"1869094"},{"content":"Panagiotis G. Ipeirotis , Foster Provost , Jing Wang, Quality management on Amazon Mechanical Turk, Proceedings of the ACM SIGKDD Workshop on Human Computation, July 25-25, 2010, Washington DC","paperID":"1837906"},{"content":"Gabriella Kazai , Jaap Kamps , Natasa Milic-Frayling, Worker types and personality traits in crowdsourcing relevance labels, Proceedings of the 20th ACM international conference on Information and knowledge management, October 24-28, 2011, Glasgow, Scotland, UK","paperID":"2063860"},{"content":"Aniket Kittur , Ed H. Chi , Bongwon Suh, Crowdsourcing user studies with Mechanical Turk, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 05-10, 2008, Florence, Italy","paperID":"1357127"},{"content":"Travis Kriplean , Caitlin Bonnar , Alan Borning , Bo Kinney , Brian Gill, Integrating on-demand fact-checking with public dialogue, Proceedings of the 17th ACM conference on Computer supported cooperative work & social computing, February 15-19, 2014, Baltimore, Maryland, USA","paperID":"2531677"},{"content":"Walter S. Lasecki , Mitchell Gordon , Danai Koutra , Malte F. Jung , Steven P. Dow , Jeffrey P. Bigham, Glance: rapidly coding behavioral video with the crowd, Proceedings of the 27th annual ACM symposium on User interface software and technology, October 05-08, 2014, Honolulu, Hawaii, USA","paperID":"2647367"},{"content":"Lau, J.H., Collier, N., and Baldwin, T. On-line Trend Analysis with Topic Models: #twitter Trends Detection Topic Model Online. COLING 2012, 1519--1534.","paperID":"None"},{"content":"Greg Little , Lydia B. Chilton , Max Goldman , Robert C. Miller, Exploring iterative and parallel human computation processes, Proceedings of the ACM SIGKDD Workshop on Human Computation, July 25-25, 2010, Washington DC","paperID":"1837907"},{"content":"MacDonald, P.L. and Gardner, R.C. Type I error rate comparisons of post hoc procedures for I j Chi-Square tables. Ed. and Psych. Meas. 60, 5 2000, 735--754.","paperID":"None"},{"content":"Mason, W. and Suri, S. Conducting behavioral research on Amazon's Mechanical Turk. Behavior research methods 44, 1 2012, 1--23.","paperID":"None"},{"content":"Winter Mason , Duncan J. Watts, Financial incentives and the \"performance of crowds\", ACM SIGKDD Explorations Newsletter, v.11 n.2, December 2009","paperID":"1809422"},{"content":"Meredith Ringel Morris , Scott Counts , Asta Roseway , Aaron Hoff , Julia Schwarz, Tweeting is believing?: understanding microblog credibility perceptions, Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work, February 11-15, 2012, Seattle, Washington, USA","paperID":"2145274"},{"content":"Mor Naaman , Jeffrey Boase , Chih-Hui Lai, Is it really about me?: message content in social awareness streams, Proceedings of the 2010 ACM conference on Computer supported cooperative work, February 06-10, 2010, Savannah, Georgia, USA","paperID":"1718953"},{"content":"Paolacci, G., Chandler, J., and Ipeirotis, P.G. Running experiments on Amazon Mechanical Turk. Judgment and Decision Making 5, 5 2010, 411--419.","paperID":"None"},{"content":"Constantine Papageorgiou , Tomaso Poggio, A Trainable System for Object Detection, International Journal of Computer Vision, v.38 n.1, p.15-33, June 2000","paperID":"355341"},{"content":"Peer, E., Vosgerau, J., and Acquisti, A. Reputation as a sufficient condition for data quality on Amazon Mechanical Turk. Behavior Research Methods, 2013, 1--9.","paperID":"None"},{"content":"Prelec, D. A Bayesian truth serum for subjective data. Science 306, 5695 2004, 462--466.","paperID":"None"},{"content":"Vahed Qazvinian , Emily Rosengren , Dragomir R. Radev , Qiaozhu Mei, Rumor has it: identifying misinformation in microblogs, Proceedings of the Conference on Empirical Methods in Natural Language Processing, July 27-31, 2011, Edinburgh, United Kingdom","paperID":"2145602"},{"content":"Cyrus Rashtchian , Peter Young , Micah Hodosh , Julia Hockenmaier, Collecting image annotations using Amazon's Mechanical Turk, Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon's Mechanical Turk, p.139-147, June 06-06, 2010, Los Angeles, California","paperID":"1866717"},{"content":"Rosenthal, R. and Rubin, D.B. Multiple contrasts and ordered Bonferroni procedures. J. Ed. Psy. 76, 6 1984.","paperID":"None"},{"content":"Saldana, J. The Coding Manual for Qualitative Researchers. SAGE Publications, 2009.","paperID":"None"},{"content":"Aaron D. Shaw , John J. Horton , Daniel L. Chen, Designing incentives for inexpert human raters, Proceedings of the ACM 2011 conference on Computer supported cooperative work, March 19-23, 2011, Hangzhou, China","paperID":"1958865"},{"content":"Victor S. Sheng , Foster Provost , Panagiotis G. Ipeirotis, Get another label? improving data quality and data mining using multiple, noisy labelers, Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining, August 24-27, 2008, Las Vegas, Nevada, USA","paperID":"1401965"},{"content":"Sheshadri, A. and Lease, M. SQUARE: A Benchmark for Research on Computing Crowd Consensus. HCOMP 2013, 156--164.","paperID":"None"},{"content":"Rion Snow , Brendan O'Connor , Daniel Jurafsky , Andrew Y. Ng, Cheap and fast---but is it good?: evaluating non-expert annotations for natural language tasks, Proceedings of the Conference on Empirical Methods in Natural Language Processing, October 25-27, 2008, Honolulu, Hawaii","paperID":"1613751"},{"content":"Soni, S., Mitra, T., Gilbert, E., and Eisenstein, J. Modeling Factuality Judgments in Social Media Text. In Proc. ACL, 415--420, 2014.","paperID":"None"},{"content":"Sorokin, A. and Forsyth, D. Utility data annotation with Amazon Mechanical Turk. CVPRW 2008, 1--8.","paperID":"None"},{"content":"Sun, Y.-A., Roy, S., and Little, G. Beyond Independent Agreement: A Tournament Selection Approach for Quality Assurance of Human Computation Tasks. Human Computation, 2011.","paperID":"None"},{"content":"James Surowiecki, The Wisdom of Crowds, Anchor, 2005","paperID":"1095645"},{"content":"Yi-Chia Wang , Robert Kraut , John M. Levine, To stay or leave?: the relationship of emotional and informational support to commitment in online health support groups, Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work, February 11-15, 2012, Seattle, Washington, USA","paperID":"2145329"},{"content":"Wesley Willett , Jeffrey Heer , Maneesh Agrawala, Strategies for crowdsourcing social data analysis, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 05-10, 2012, Austin, Texas, USA","paperID":"2207709"},{"content":"Wayne Xin Zhao , Jing Jiang , Jianshu Weng , Jing He , Ee-Peng Lim , Hongfei Yan , Xiaoming Li, Comparing twitter and traditional media using topic models, Proceedings of the 33rd European conference on Advances in information retrieval, April 18-21, 2011, Dublin, Ireland","paperID":"1996934"}],"title":"Comparing Person- and Process-centric Strategies for Obtaining Quality Data on Amazon Mechanical Turk","filename":"CHI15/p1345","authors":["Tanushree Mitra","C.J. Hutto","Eric Gilbert"],"conference":"CHI '15"}