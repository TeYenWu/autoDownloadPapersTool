{"paperId":2858404,"citation":[],"reference":[{"content":"Alnajar, F., Gevers, T., Valenti, R. and Ghebreab, S. 2013. Calibration-Free Gaze Estimation Using Human Gaze Patterns. 2013 IEEE International Conference on Computer Vision (Dec. 2013), 137-144.","paperID":"None"},{"content":"B. A. Shenoi 2005. Introduction to Digital Signal Processing and Filter Design. Wiley.","paperID":"None"},{"content":"Breiman, L. 2001. Random forests. Machine Learning. 45, (2001), 5-32.","paperID":"None"},{"content":"Chen, M.C., Anderson, J.R. and Sohn, M.H. 2001. What can a mouse cursor tell us more? CHI '01 extended abstracts on Human factors in computing systems CHI '01 (NY, NY, USA, 2001), 281.","paperID":"None"},{"content":"Cootes, T.F., Edwards, G.J. and Taylor, C.J. 2001. Active appearance models. IEEE Transactions on Pattern Analysis and Machine Intelligence. 23, 6 (Jun. 2001), 681-685.","paperID":"None"},{"content":"Fares, R., Fang, S. and Komogortsev, O. 2013. Can we beat the mouse with MAGIC? Proceedings of the SIGCHI Conference on Human Factors in Computing Systems CHI '13 (NY, NY, USA, 2013), 1387.","paperID":"None"},{"content":"Guo, Q. and Agichtein, E. 2010. Towards predicting web searcher gaze position from mouse movements. Proceedings of the 28th of the international conference extended abstracts on Human factors in computing systems CHI EA '10 (NY, NY, USA, 2010), 3601.","paperID":"None"},{"content":"Hansen, D.W. and Ji, Q. 2010. In the eye of the beholder: a survey of models for eyes and gaze. IEEE transactions on pattern analysis and machine intelligence. 32, 3 (Mar. 2010), 478-500.","paperID":"None"},{"content":"Hornof, A.J. and Halverson, T. 2002. Cleaning up systematic error in eye-tracking data by using required fixation locations. Behavior research methods, instruments, & computers : a journal of the Psychonomic Society, Inc. 34, (2002), 592-604.","paperID":"None"},{"content":"Huang, J., White, R. and Buscher, G. 2012. User see, user point: gaze and cursor alignment in web search. Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems CHI '12 (NY, NY, USA, 2012), 1341.","paperID":"None"},{"content":"Huang, J., White, R.W. and Dumais, S. 2011. No clicks, no problem: using cursor movements to understand and improve search. Proceedings of the 2011 annual conference on Human factors in computing systems CHI '11 (NY, NY, USA, 2011), 1225.","paperID":"None"},{"content":"Huang, M.X., Kwok, T.C.K., Ngai, G., Leong, H.V. and Chan, C.F.S. 2014. Building a Self-Learning Eye Gaze Model from User Interaction Data. ACM Multimedia (2014).","paperID":"None"},{"content":"Jacob, R.J.K. 1990. What you look at is what you get: eye movement-based interaction techniques. Proceedings of the SIGCHI conference on Human factors in computing systems Empowering people CHI '90 (NY, NY, USA, 1990), 11-18.","paperID":"None"},{"content":"Judd, T., Ehinger, K., Durand, F. and Torralba, A. 2009. Learning to predict where humans look. 2009 IEEE 12th International Conference on Computer Vision (Sep. 2009), 2106-2113.","paperID":"None"},{"content":"Liebling, D.J. and Dumais, S.T. 2014. Gaze and mouse coordination in everyday work. Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing Adjunct Publication - UbiComp '14 Adjunct (2014), 1141- 1150.","paperID":"None"},{"content":"Lu, F., Okabe, T., Sugano, Y. and Sato, Y. 2014. Learning gaze biases with head motion for head posefree gaze estimation. Image and Vision Computing. 32, 3 (Mar. 2014), 169-179.","paperID":"None"},{"content":"Lu, F., Sugano, Y., Okabe, T. and Sato, Y. 2012. Head pose-free appearance-based gaze sensing via eye image synthesis. International Conference on Pattern Recognition (ICPR), (2012), 1008 - 1011.","paperID":"None"},{"content":"Lu, F., Sugano, Y., Okabe, T. and Sato, Y. 2014. Inferring Human Gaze from Appearance via Adaptive Linear Regression. IEEE Transactions on Pattern Analysis and Machine Intelligence. (2014), 1-1.","paperID":"None"},{"content":"Rodden, K., Fu, X., Aula, A. and Spiro, I. 2008. Eyemouse coordination patterns on web search results pages. Proceeding of the twenty-sixth annual CHI conference extended abstracts on Human factors in computing systems CHI '08 (NY, NY, USA, 2008), 2997.","paperID":"None"},{"content":"Saragih, J.M., Lucey, S. and Cohn, J.F. 2009. Face alignment through subspace constrained mean-shifts. 2009 IEEE 12th International Conference on Computer Vision (Sep. 2009), 1034-1041.","paperID":"None"},{"content":"Sugano, Y., Matsushita, Y. and Sato, Y. 2013. Appearance-based gaze estimation using visual saliency. IEEE transactions on pattern analysis and machine intelligence. 35, 2 (Feb. 2013), 329-41.","paperID":"None"},{"content":"Sugano, Y., Matsushita, Y., Sato, Y. and Koike, H. 2008. An Incremental Learning Method for Unconstrained Gaze Estimation. 10th European Conference on Computer Vision, ECCV' 2008 (2008), 656-667.","paperID":"None"},{"content":"Williams, O., Blake, A. and Cipolla, R. Sparse and Semi-supervised Visual Mapping with the S^3GP. 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Volume 1 (CVPR'06) 230-237.","paperID":"None"},{"content":"Wood, E. and Bulling, A. 2014. EyeTab. Proceedings of the Symposium on Eye Tracking Research and Applications - ETRA '14 (NY, NY, USA, 2014), 207-210.","paperID":"None"},{"content":"Xiong, X. and De la Torre, F. 2013. Supervised Descent Method and Its Applications to Face Alignment. 2013 IEEE Conference on Computer Vision and Pattern Recognition (Jun. 2013), 532-539.","paperID":"None"},{"content":"Zhang, Y. and Hornof, A.J. 2014. Easy post-hoc spatial recalibration of eye tracking data. Proceedings of the Symposium on Eye Tracking Research and Applications - ETRA '14 (2014), 95-98.","paperID":"None"},{"content":"Zhang, Y. and Hornof, A.J. 2011. Mode-of-disparities error correction of eye-tracking data. Behavior research methods. 43, (2011), 834-842.","paperID":"None"},{"content":"Zhu, Z., Ji, Q. and Bennett, K.P. 2006. Nonlinear Eye Gaze Mapping Function Estimation via Support Vector Regression. 18th International Conference on Pattern Recognition (ICPR'06) (2006), 1132-1135.","paperID":"None"}],"abstract":"We present PACE, a Personalized, Automatically Calibrating Eye-tracking system that identifies and collects data unobtrusively from user interaction events on standard computing systems without the need for specialized equipment. PACE relies on eye/facial analysis of webcam data based on a set of robust geometric gaze features and a two-layer data validation mechanism to identify good training samples from daily interaction data. The design of the system is founded on an in-depth investigation of the relationship between gaze patterns and interaction cues, and takes into consideration user preferences and habits. The result is an adaptive, data-driven approach that continuously recalibrates, adapts and improves with additional use. Quantitative evaluation on 31 subjects across different interaction behaviors shows that training instances identified by the PACE data collection have higher gaze point-interaction cue consistency than those identified by conventional approaches. An in-situ study using real-life tasks on a diverse set of interactive applications demonstrates that the PACE gaze estimation achieves an average error of 2.56ยบ, which is comparable to state-of-the-art, but without the need for explicit training or calibration. This demonstrates the effectiveness of both the gaze estimation method and the corresponding data collection mechanism.","title":"Building a Personalized, Auto-Calibrating Eye Tracker from User Interactions","filename":"CHI16/p5169","authors":["Michael Xuelin Huang","Tiffany C.K. Kwok","Grace Ngai","Stephen C.F. Chan","Hong Va Leong"],"conference":"CHI '16"}