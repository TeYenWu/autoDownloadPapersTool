{"paperId":2858425,"citation":[],"reference":[{"content":"Agarwal, D., Chen, B.C., and Elango, P. (2009) Explore/Exploit Schemes for Web Content Optimization. Ninth IEEE International Conference on Data Mining, 1-10.","paperID":"None"},{"content":"Auer, P., Cesa-Bianchi, N., and Fischer, P. (2002) Finite-time Analysis of the Multiarmed Bandit Problem. Machine Learning, 235-256.","paperID":"None"},{"content":"Berry, D. (2011) Adaptive Clinical Trials: The Promise and the Caution. Journal of clinical oncology: official journal of the American Society of Clinical Oncology 29, 6. 603-6.","paperID":"None"},{"content":"Birkett, A. (2015) When to Run Bandit Tests Instead of A/B/n Tests. http://conversionxl.com/bandit-tests/","paperID":"None"},{"content":"Bostrom, N. (2003). Ethical issues in advanced artificial intelligence. Science Fiction and Philosophy: From Time Travel to Superintelligence, 277--284.","paperID":"None"},{"content":"Brezzi, M. and Lai, T.L. (2002) Optimal learning and experimentation in bandit problems. Journal of Economic Dynamics and Control 27, 1. 87-108.","paperID":"None"},{"content":"Card, S., Mackinlay, J., & Robertson, G. (1990). The design space of input devices. ACM CHI","paperID":"None"},{"content":"Chapelle, O., & Li, L. (2011). An empirical evaluation of thompson sampling. InAdvances in neural information processing systems (pp. 2249--2257).","paperID":"None"},{"content":"Crook, T., Frasca, B., Kohavi, R., & Longbotham, R. (2009, June). Seven pitfalls to avoid when running controlled experiments on the web. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining (pp. 1105--1114). ACM.","paperID":"None"},{"content":"Drachen, A. and Canossa, A. (2009) Towards Gameplay Analysis via Gameplay Metrics. ACM MindTrek, 202- 209.","paperID":"None"},{"content":"Fogarty, J., Forlizzi, J., and Hudson, S.E. (2001) Aesthetic Information Collages: Generating Decorative Displays that Contain Information. ACM CHI","paperID":"None"},{"content":"Gajos, K., & Weld, D. S. (2005). Preference elicitation for interface optimization. ACM UIST (pp. 173--182).","paperID":"None"},{"content":"Gajos, K., Weld, D., and Wobbrock, J. DecisionTheoretic User Interface Generation. AAAI, (2008), 1532-1536.","paperID":"None"},{"content":"Gittins, J. (1979) Bandit Processes and Dynamic Allocation Indicies. Journal of the Royal Statistical Society. Series B., 148-177.","paperID":"None"},{"content":"Glaser, R. (1976). Components of a psychology of instruction: Toward a science of design. Review of Educational Research, 46(1), 1-24.","paperID":"None"},{"content":"Hacker, S. (2014) Duolingo: Learning a Language While Translating the Web. PhD Thesis, Carnegie Mellon University School of Computer Science. May","paperID":"None"},{"content":"Hauser, J.R., Urban, G.L., Liberali, G., and Braun, M. (2009) Website Morphing. Marketing Science. 28, 2, 202-223.","paperID":"None"},{"content":"Khajah, M., Roads, B. D., Lindsey, R. V, Liu, Y., & Mozer, M. C. (2016). Designing Engaging Games Using Bayesian Optimization, ACM CHI.","paperID":"None"},{"content":"Koedinger, K. R., Booth, J. L., Klahr, D. (2013) Instructional Complexity and the Science to Constrain It Science. 22 November 2013: Vol. 342 no. 6161 pp. 935-","paperID":"None"},{"content":"Koedinger, K. R., Baker, R. S., Cunningham, K., Skogsholm, A., Leber, B., & Stamper, J. (2010). A data repository for the EDM community: The PSLC DataShop. Handbook of educational data mining, 43.","paperID":"None"},{"content":"Kohavi, R., Longbotham, R., Sommerfield, D., and Henne, R.M. (2008) Controlled experiments on the web: survey and practical guide. Data Mining and Knowledge Discovery 18, 1 140-181.","paperID":"None"},{"content":"Kohavi, R., Deng, A., Frasca, B., Longbotham, R., Walker, T., and Xu, Y. (2012) Trustworthy Online Controlled Experiments: Five Puzzling Outcomes Explained. KDD","paperID":"None"},{"content":"Kramer, Adam DI, Jamie E. Guillory, and Jeffrey T. Hancock. (2014) Experimental evidence of massivescale emotional contagion through social networks. PNAS","paperID":"None"},{"content":"Lai, T. (1987) Adaptive treatment allocation and the multi-armed bandit problem. The Annals of Statistics; 15(3):1091-1114.","paperID":"None"},{"content":"Lai, T., & Robbins, H. (1985). Asymptotically efficient adaptive allocation rules. Advances in Applied Mathematics, 6, 4-22.","paperID":"None"},{"content":"Li, L., Chu, W., Langford, J., & Schapire, R.E. (2010) A Contextual-Bandit Approach to Personalized News Article Recommendation. WWW","paperID":"None"},{"content":"Liu, Y., Mandel, T., Brunskill, E., & Popovic, Z. (2014) Trading Off Scientific Knowledge and User Learning with Multi-Armed Bandits. Educational Data Mining","paperID":"None"},{"content":"Liu, Y., Mandel, T., Brunskill, E., & Popovi, Z. (2014) Towards Automatic Experimentation of Educational Knowledge. ACM CHI","paperID":"None"},{"content":"Lomas, D., Patel, K., Forlizzi, J. L., & Koedinger, K. R. (2013) Optimizing challenge in an educational game using large-scale design experiments. ACM CHI","paperID":"None"},{"content":"Lomas, D. Harpstead, E., (2012) Design Space Sampling for the Optimization of Educational Games. Game User Experience Workshop, ACM CHI","paperID":"None"},{"content":"Lomas, D. (2014). Optimizing motivation and learning with large-scale game design experiments (Unpublished Doctoral Dissertation). HCI Institute, Carnegie Mellon University. DOI: 10.13140/RG.2.1.5090.8645","paperID":"None"},{"content":"Lomas, D., (2013). Digital Games for Improving Number Sense Retrieved from https://pslcdatashop. web.cmu.edu/Files?datasetId=445","paperID":"None"},{"content":"Maclean, A., Young, R. M., Victoria, M. E., & Moran, T. P. (1991). Questions, Options, and Criteria: Elements of Design Space Analysis. Human Computer Interaction, 6, 201-250.","paperID":"None"},{"content":"Manzi, J. (2012). Uncontrolled: The surprising payoff of trial-and-error for business, politics, and society. Basic Books.","paperID":"None"},{"content":"Norman, D. (in preparation) Technology or People: Putting People Back in Charge. Jnd.org","paperID":"None"},{"content":"Scott, S. (2010) A modern Bayesian look at the multiarmed bandit. Applied Stochastic Models in Business and Industry, 639-658.","paperID":"None"},{"content":"Scott, S. (2014) Google Content Experiments https://support.google.com/analytics/answer/2844870?hl=en&ref_topic=2844866","paperID":"None"},{"content":"Scott, S. L. (2015). Multi-armed bandit experiments in the online service economy. Applied Stochastic Models in Business and Industry, 31(1), 37--45.","paperID":"None"},{"content":"Simon, H. (1969). The Sciences of the Artificial. Cambridge, MA.","paperID":"None"},{"content":"Stamper, J., Lomas, D., Ching, D., Ritter, S., Koedinger, K., & Steinhart, J. (2012) The rise of the super experiment. EDM p. 196-200","paperID":"None"},{"content":"Stampfer, E., Long, Y., Aleven, V., & Koedinger, K. R. (2011, January). Eliciting intelligent novice behaviors with grounded feedback in a fraction addition tutor. In Artificial Intelligence in Education (pp. 560--562). Springer Berlin Heidelberg.","paperID":"None"},{"content":"Vermorel, J. & Mohri, M. (2005) Multi-armed bandit algorithms and empirical evaluation. Machine Learning: ECML 2005, 437-448.","paperID":"None"},{"content":"Yannakakis, G. N., & Hallam, J. (2007). Towards optimizing entertainment in computer games. Applied Artificial Intelligence, 21(10), 933--971.","paperID":"None"}],"abstract":"\"Multi-armed bandits\" offer a new paradigm for the AI-assisted design of user interfaces. To help designers understand the potential, we present the results of two experimental comparisons between bandit algorithms and random assignment. Our studies are intended to show designers how bandits algorithms are able to rapidly explore an experimental design space and automatically select the optimal design configuration. Our present focus is on the optimization of a game design space. The results of our experiments show that bandits can make data-driven design more efficient and accessible to interface designers, but that human participation is essential to ensure that AI systems optimize for the right metric. Based on our results, we introduce several design lessons that help keep human design judgment in the loop. We also consider the future of human-technology teamwork in AI-assisted design and scientific inquiry. Finally, as bandits deploy fewer low-performing conditions than typical experiments, we discuss ethical implications for bandits in large-scale experiments in education.","title":"Interface Design Optimization as a Multi-Armed Bandit Problem","filename":"CHI16/p4142","authors":["J. Derek Lomas","Jodi Forlizzi","Nikhil Poonwala","Nirmal Patel","Sharan Shodhan","Kishan Patel","Ken Koedinger","Emma Brunskill"],"conference":"CHI '16"}