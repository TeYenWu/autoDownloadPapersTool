{"paperId":2470704,"reference":[{"content":"Jeffrey P. Bigham , Chandrika Jayant , Hanjie Ji , Greg Little , Andrew Miller , Robert C. Miller , Robin Miller , Aubrey Tatarowicz , Brandyn White , Samual White , Tom Yeh, VizWiz: nearly real-time answers to visual questions, Proceedings of the 23nd annual ACM symposium on User interface software and technology, October 03-06, 2010, New York, New York, USA","paperID":"1866080"},{"content":"Bradski, G. The OpenCV library. Doctor Dobbs Journal 25, 11 (2000), 120--126.","paperID":"None"},{"content":"Shaun K. Kane , Daniel Avrahami , Jacob O. Wobbrock , Beverly Harrison , Adam D. Rea , Matthai Philipose , Anthony LaMarca, Bonfire: a nomadic system for hybrid laptop-tabletop interaction, Proceedings of the 22nd annual ACM symposium on User interface software and technology, October 04-07, 2009, Victoria, BC, Canada","paperID":"1622202"},{"content":"Shaun K. Kane , Jeffrey P. Bigham , Jacob O. Wobbrock, Slide rule: making mobile touch screens accessible to blind people using multi-touch interaction techniques, Proceedings of the 10th international ACM SIGACCESS conference on Computers and accessibility, October 13-15, 2008, Halifax, Nova Scotia, Canada","paperID":"1414487"},{"content":"Shaun K. Kane , Meredith Ringel Morris , Annuska Z. Perkins , Daniel Wigdor , Richard E. Ladner , Jacob O. Wobbrock, Access overlays: improving non-visual access to large touch screens for blind users, Proceedings of the 24th annual ACM symposium on User interface software and technology, October 16-19, 2011, Santa Barbara, California, USA","paperID":"2047232"},{"content":"Levenshtein, V.I. Binary codes capable of correcting spurious insertions and deletions of ones. Problems of Information Transmission 1, 1 (1965), 8--17.","paperID":"None"},{"content":"Mahmoud, T.M. A new fast skin color detection technique. WEAST 43, (2008), 501--505.","paperID":"None"},{"content":"Suranga Nanayakkara , Roy Shilkrot , Pattie Maes, EyeRing: a finger-worn assistant, CHI '12 Extended Abstracts on Human Factors in Computing Systems, May 05-10, 2012, Austin, Texas, USA","paperID":"2223736"},{"content":"Stauffer, C. and Grimson, W.E.L. Adaptive background mixture models for real-time tracking. Proc. CVPR '00, 252--258.","paperID":"None"},{"content":"Sukthankar, R., Stockton, R.G., and Mullin, M.D. Smarter presentations: exploiting homography in camera-projector systems. Proc. ICCV '01, 247--253.","paperID":"None"},{"content":"Pierre Wellner, Interacting with paper on the DigitalDesk, Communications of the ACM, v.36 n.7, p.87-96, July 1993","paperID":"159630"},{"content":"Samuel White , Hanjie Ji , Jeffrey P. Bigham, EasySnap: real-time audio feedback for blind photography, Adjunct proceedings of the 23nd annual ACM symposium on User interface software and technology, October 03-06, 2010, New York, New York, USA","paperID":"1866244"},{"content":"Wong, E.K. and Chen, M. A new robust algorithm for video text extraction. Pattern Recognition 36, 6 (2003), 1397--1406.","paperID":"None"}],"citation":[{"content":"Huiying Shen , Owen Edwards , Joshua Miele , James M. Coughlan, CamIO: a 3D computer vision system enabling audio/haptic interaction with physical objects by blind users, Proceedings of the 15th International ACM SIGACCESS Conference on Computers and Accessibility, October 21-23, 2013, Bellevue, Washington","paperID":"2513423"},{"content":"Anhong Guo , Xiang 'Anthony' Chen , Jeffrey P. Bigham, ApplianceReader: A Wearable, Crowdsourced, Vision-based System to Make Appliances Accessible, Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems, April 18-23, 2015, Seoul, Republic of Korea","paperID":"2732755"},{"content":"Roy Shilkrot , Jochen Huber , Wong Meng Ee , Pattie Maes , Suranga Chandima Nanayakkara, FingerReader: A Wearable Device to Explore Printed Text on the Go, Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, April 18-23, 2015, Seoul, Republic of Korea","paperID":"2702421"},{"content":"Roy Shilkrot , Jochen Huber , Connie Liu , Pattie Maes , Suranga Chandima Nanayakkara, FingerReader: a wearable device to support text reading on the go, CHI '14 Extended Abstracts on Human Factors in Computing Systems, April 26-May 01, 2014, Toronto, Ontario, Canada","paperID":"2581220"},{"content":"Michael P. Cutter , Roberto Manduchi, Towards Mobile OCR: How to Take a Good Picture of a Document Without Sight, Proceedings of the 2015 ACM Symposium on Document Engineering, September 08-11, 2015, Lausanne, Switzerland","paperID":"2797066"},{"content":"Catherine M. Baker , Lauren R. Milne , Jeffrey Scofield , Cynthia L. Bennett , Richard E. Ladner, Tactile graphics with a voice: using QR codes to access text in tactile graphics, Proceedings of the 16th international ACM SIGACCESS conference on Computers & accessibility, October 20-22, 2014, Rochester, New York, USA","paperID":"2661366"},{"content":"Catherine M. Baker , Lauren R. Milne , Ryan Drapeau , Jeffrey Scofield , Cynthia L. Bennett , Richard E. Ladner, Tactile Graphics with a Voice, ACM Transactions on Accessible Computing (TACCESS), v.8 n.1, January 2016","paperID":"2854005"},{"content":"Anke Brock , Christophe Jouffrais, Interactive audio-tactile maps for visually impaired people, ACM SIGACCESS Accessibility and Computing","paperID":"2850441"},{"content":"Giovanni Fusco , Valerie S. Morash, The Tactile Graphics Helper: Providing Audio Clarification for Tactile Graphics Using Machine Vision, Proceedings of the 17th International ACM SIGACCESS Conference on Computers & Accessibility, October 26-28, 2015, Lisbon, Portugal","paperID":"2809868"}],"abstract":"Gesture-based touch screen user interfaces, when designed to be accessible to blind users, can be an effective mode of interaction for those users. However, current accessible touch screen interaction techniques suffer from one serious limitation: they are only usable on devices that have been explicitly designed to support them. Access Lens is a new interaction method that uses computer vision-based gesture tracking to enable blind people to use accessible gestures on paper documents and other physical objects, such as product packages, device screens, and home appliances. This paper describes the development of Access Lens hardware and software, the iterative design of Access Lens in collaboration with blind computer users, and opportunities for future development.","video":"http://www.youtube.com/embed/LYykeSk2HT4?rel=0","title":"Access lens: a gesture-based screen reader for real-world documents","filename":"CHI13/p347","authors":["Shaun K. Kane","Brian Frey","Jacob O. Wobbrock"],"conference":"CHI '13"}