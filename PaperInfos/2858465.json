{"paperId":2858465,"citation":[],"reference":[{"content":"Joel Brandt, Mira Dontcheva, Marcos Weskamp, and Scott R. Klemmer. 2010. Example-centric programming. Proceedings of the 28th international conference on Human factors in computing systems CHI '10, ACM Press, 513. Retrieved January 7, 2016 from http://dl.acm.org/citation.cfm?id=1753326.1753402","paperID":"None"},{"content":"Bob Carpenter, Andrew Gelman, Matt Hoffman, et al. 2015. Stan: A Probabilistic Programming Language. Journal of Statistical Software In press.","paperID":"None"},{"content":"Geoff Cumming. 2014. The new statistics: why and how. Psychological science 25, 1: 7-29. Retrieved July 9, 2014 from http://pss.sagepub.com/content/early/2013/11/07/09567 97613504966.abstract","paperID":"None"},{"content":"Zoltan Dienes. 2011. Bayesian Versus Orthodox Statistics: Which Side Are You On? Perspectives on psychological science?: a journal of the Association for Psychological Science 6, 3: 274-90. Retrieved January 7, 2016 from http://pps.sagepub.com/content/6/3/274.abstract","paperID":"None"},{"content":"Pierre Dragicevic. 2016. Fair Statistical Communication in HCI. In Modern Statistical Methods for HCI, Judy Robertson and Maurits Kaptein (eds.). Springer.","paperID":"None"},{"content":"Pierre Dragicevic. 2016. From Statistical Significance to Fair Statistical Communication in HCI. In Modern Statistical Methods for HCI, Judy Robertson and Maurits Kaptein (eds.). Springer.","paperID":"None"},{"content":"Daniel Foreman-Mackey, David W. Hogg, Dustin Lang, and Jonathan Goodman. 2013. emcee?: The MCMC Hammer. Publications of the Astronomical Society of the Pacific 125, 925: 306-312. Retrieved April 21, 2015 from http://arxiv.org/abs/1202.3665","paperID":"None"},{"content":"A. Gelman and J. Carlin. 2014. Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science 9, 6: 641-651. Retrieved November 17, 2014 from http://pps.sagepub.com/content/9/6/641.short","paperID":"None"},{"content":"Andrew Gelman, Aleks Jakulin, Maria Grazia Pittau, and Yu-Sung Su. 2008. A Weakly Informative Default Prior Distribution for Logistic and Other Regression Models. The Annals of Applied Statistics 2, 4: 1360-1383.","paperID":"None"},{"content":"Andrew Gelman and David Weakliem. 2009. Of Beauty, Sex and Power. American Scientist 97, 4: 310- 316.","paperID":"None"},{"content":"Andrew Gelman. 2006. Prior distributions for variance parameters in hierarchical models. Bayesian Analysis 1, 3: 515-533. http://doi.org/10.1214/06-BA117A","paperID":"None"},{"content":"Saul Greenberg and Bill Buxton. 2008. Usability evaluation considered harmful (some of the time). Proceeding of the twenty-sixth annual CHI conference on Human factors in computing systems CHI '08, ACM Press, 111. Retrieved September 25, 2015 from http://dl.acm.org/citation.cfm?id=1357054.1357074","paperID":"None"},{"content":"Larry V. Hedges and Ingram Olkin. 1980. Vote counting methods in research synthesis. Psychological Bulletin 88, 2: 359-369.","paperID":"None"},{"content":"Rink Hoekstra, Richard D. Morey, Jeffrey N. Rouder, and Eric-Jan Wagenmakers. 2014. Robust misinterpretation of confidence intervals. Psychonomic Bulletin & Review 21, 5: 1157-1164. Retrieved July 1, 2015 from http://www.ncbi.nlm.nih.gov/pubmed/24420726","paperID":"None"},{"content":"Kasper Hornb√¶k and Effie Lai-Chong Law. 2007. Meta-analysis of correlations among usability measures. Proceedings of the SIGCHI conference on Human factors in computing systems CHI '07: 617. http://doi.org/10.1145/1240624.1240722","paperID":"None"},{"content":"George S. Howard, Scott E. Maxwell, and Kevin J. Fleming. The proof of the pudding: An illustration of the relative strengths of null hypothesis, meta-analysis, and Bayesian analysis.","paperID":"None"},{"content":"John P A Ioannidis. 2005. Why most published research findings are false. PLoS medicine 2, 8: e124. Retrieved July 9, 2014 from http://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124","paperID":"None"},{"content":"Maurits Kaptein and Judy Robertson. 2012. Rethinking statistical analysis methods for CHI. Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems CHI '12, ACM Press, 1105. Retrieved September 25, 2015 from http://dl.acm.org/citation.cfm?id=2207676.2208557","paperID":"None"},{"content":"John K Kruschke. 2013. Bayesian estimation supersedes the t test. Journal of experimental psychology. General 142, 2: 573-603. Retrieved September 25, 2015 from http://www.ncbi.nlm.nih.gov/pubmed/22774788","paperID":"None"},{"content":"John K. Kruschke. 2010. Bayesian data analysis. Wiley Interdisciplinary Reviews: Cognitive Science 1, 5: 658-676. http://doi.org/10.1002/wcs.72","paperID":"None"},{"content":"John K. Kruschke. 2011. Doing Bayesian Data Analysis. Elsevier Inc.","paperID":"None"},{"content":"Anand Patil, David Huard, and Christopher J Fonnesbeck. 2010. PyMC: Bayesian Stochastic Modelling in Python. Journal of statistical software 35, 4: 1-81. Retrieved December 2, 2015 from http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3097064&tool=pmcentrez&rendertype=abstract","paperID":"None"},{"content":"Martyn Plummer. 2003. JAGS: A Program for Analysis of Bayesian Graphical Models Using Gibbs Sampling. Proceedings of the 3rd International Workshop on Distributed Statistical Computing (DSC 2003). http://doi.org/10.1.1.13.3406","paperID":"None"},{"content":"Ana Villar, Mario Callegaro, and Yongwei Yang. 2013. Where Am I? A Meta-Analysis of Experiments on the Effects of Progress Indicators for Web Surveys. Social Science Computer Review 00, 0: 1-19. http://doi.org/10.1177/0894439313497468","paperID":"None"},{"content":"Suzanne Weisband and S Kiesler. 1996. Self Disclosure on Computer Forms?: Meta-Analysis and Implications. ACM Digital Library CHI, 96: 3-10. http://doi.org/10.1145/238386.238387","paperID":"None"},{"content":"Max Wilson, Wendy E. Mackay, Ed Chi, Michael Bernstein, and Dan Russell. RepliCHI CHI should be replicating and validating results more: discuss. CHI EA '11: Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems. http://doi.org/10.1145/1979742.1979491","paperID":"None"},{"content":"Jacob O Wobbrock, Leah Findlater, Darren Gergle, and James J Higgins. 2011. The Aligned Rank Transform for Nonparametric Factorial Analyses Using Only ANOVA Procedures. CHI '11: 143-146.","paperID":"None"},{"content":"Nick Yee, Nick Yee, Jeremy N Bailenson, Jeremy N Bailenson, Kathryn Rickertsen, and Kathryn Rickertsen. 2007. A meta-analysis of the impact of the inclusion and realism of human-like faces on user experiences in interfaces. Proceedings of the SIGCHI conference on Human factors in computing systems CHI '07: 1. http://doi.org/10.1145/1240624.1240626","paperID":"None"}],"abstract":"A core tradition of HCI lies in the experimental evaluation of the effects of techniques and interfaces to determine if they are useful for achieving their purpose. However, our individual analyses tend to stand alone, and study results rarely accrue in more precise estimates via meta-analysis: in a literature search, we found only 56 meta-analyses in HCI in the ACM Digital Library, 3 of which were published at CHI (often called the top HCI venue). Yet meta-analysis is the gold standard for demonstrating robust quantitative knowledge. We treat this as a user-centered design problem: the failure to accrue quantitative knowledge is not the users' (i.e. researchers') failure, but a failure to consider those users' needs when designing statistical practice. Using simulation, we compare hypothetical publication worlds following existing frequentist against Bayesian practice. We show that Bayesian analysis yields more precise effects with each new study, facilitating knowledge accrual without traditional meta-analyses. Bayesian practices also allow more principled conclusions from small-n studies of novel techniques. These advantages make Bayesian practices a likely better fit for the culture and incentives of the field. Instead of admonishing ourselves to spend resources on larger studies, we propose using tools that more appropriately analyze small studies and encourage knowledge accrual from one study to the next. We also believe Bayesian methods can be adopted from the bottom up without the need for new incentives for replication or meta-analysis. These techniques offer the potential for a more user- (i.e. researcher-) centered approach to statistical analysis in HCI.","title":"Researcher-Centered Design of Statistics: Why Bayesian Statistics Better Fit the Culture and Incentives of HCI","filename":"CHI16/p4521","authors":["Matthew Kay","Gregory L. Nelson","Eric B. Hekler"],"conference":"CHI '16"}