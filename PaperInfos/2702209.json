{"paperId":2702209,"citation":[],"reference":[{"content":"Nikola Banovic , Tovi Grossman , Justin Matejka , George Fitzmaurice, Waken: reverse engineering usage information and interface structure from software videos, Proceedings of the 25th annual ACM symposium on User interface software and technology, October 07-10, 2012, Cambridge, Massachusetts, USA","paperID":"2380129"},{"content":"Brockly, C. Evaluation of direct manipulation techniques for in-scene video navigation. Master's thesis, RWTH Aachen University (2009).","paperID":"None"},{"content":"Pei-Yu Chi , Bongshin Lee , Steven M. Drucker, DemoWiz: re-performing software demonstrations for a live presentation, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 26-May 01, 2014, Toronto, Ontario, Canada","paperID":"2557254"},{"content":"Laurent Denoue , Scott Carter , Matthew Cooper , John Adcock, Real-time direct manipulation of screen-based videos, Proceedings of the companion publication of the 2013 international conference on Intelligent user interfaces companion, March 19-22, 2013, Santa Monica, California, USA","paperID":"2451190"},{"content":"Pierre Dragicevic , Gonzalo Ramos , Jacobo Bibliowitcz , Derek Nowrouzezahrai , Ravin Balakrishnan , Karan Singh, Video browsing by direct manipulation, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 05-10, 2008, Florence, Italy","paperID":"1357096"},{"content":"Dan B. Goldman , Chris Gonterman , Brian Curless , David Salesin , Steven M. Seitz, Video object annotation, navigation, and composition, Proceedings of the 21st annual ACM symposium on User interface software and technology, October 19-22, 2008, Monterey, CA, USA","paperID":"1449719"},{"content":"Tovi Grossman , Justin Matejka , George Fitzmaurice, Chronicle: capture, exploration, and playback of document workflow histories, Proceedings of the 23nd annual ACM symposium on User interface software and technology, October 03-06, 2010, New York, New York, USA","paperID":"1866054"},{"content":"Thorsten Karrer , Malte Weiss , Eric Lee , Jan Borchers, DRAGON: a direct manipulation interface for frame-accurate in-scene video navigation, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 05-10, 2008, Florence, Italy","paperID":"1357097"},{"content":"Juho Kim , Phu Tran Nguyen , Sarah Weir , Philip J. Guo , Robert C. Miller , Krzysztof Z. Gajos, Crowdsourcing step-by-step information extraction to enhance existing how-to videos, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 26-May 01, 2014, Toronto, Ontario, Canada","paperID":"2556986"},{"content":"Ben Lafreniere , Tovi Grossman , Justin Matejka , George Fitzmaurice, Investigating the feasibility of extracting tool demonstrations from in-situ video content, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 26-May 01, 2014, Toronto, Ontario, Canada","paperID":"2557142"},{"content":"Justin Matejka , Tovi Grossman , George Fitzmaurice, Ambient help, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 07-12, 2011, Vancouver, BC, Canada","paperID":"1979349"},{"content":"Suporn Pongnumkul , Mira Dontcheva , Wilmot Li , Jue Wang , Lubomir Bourdev , Shai Avidan , Michael F. Cohen, Pause-and-play: automatically linking screencast video tutorials with applications, Proceedings of the 24th annual ACM symposium on User interface software and technology, October 16-19, 2011, Santa Barbara, California, USA","paperID":"2047213"}],"abstract":"Tutorial videos are widely available to help people use software. These videos, however, are viewed by users as captured and offer little direct interaction between users and software. This paper presents a video navigation method that allows users to interact with software tutorial video as if they were using the software. To make the tutorial video responsive, our method records the user interaction events like mouse click and drag during capturing the video. Our method then analyzes, selects, and visualizes these user interaction events at the event locations. When a user directly interacts with an event visualization, our method automatically navigates to the proper video frame to provide the visual feedback as if the software were responding to the user input. Thus, our method provides the experience of interacting with the software through directly manipulating the tutorial video. Our study shows our method can better help users follow tutorial videos to complete tasks than the baseline timeline interface.","title":"Making Software Tutorial Video Responsive","filename":"CHI15/p1565","authors":["Cuong Nguyen","Feng Liu"],"conference":"CHI '15"}