{"paperId":2481303,"citation":[{"content":"Mark D'Inverno , Jon McCormack, Heroic versus collaborative AI for the arts, Proceedings of the 24th International Conference on Artificial Intelligence, p.2438-2444, July 25-31, 2015, Buenos Aires, Argentina","paperID":"2832589"}],"reference":[{"content":"Aebersold, J., How To Play Jazz & Improvise, Book & CD Set, Vol. 1, 2000.","paperID":"None"},{"content":"Boss, RC-3 Loop Station Owner's Manual, 2011.","paperID":"None"},{"content":"Cherla, S. Automatic Phrase Continuation from Guitar and Bass-guitar Melodies, Master thesis, UPF, 2011.","paperID":"None"},{"content":"Masatoshi Hamanaka , Masataka Goto , Hideki Asoh , Nobuyuki Otsu, A learning-based jam session system that imitates a player's personality model, Proceedings of the 18th international joint conference on Artificial intelligence, p.51-58, August 09-15, 2003, Acapulco, Mexico","paperID":"1630667"},{"content":"Jordan, S., Magic Touch, Blue Note Records 1985.","paperID":"None"},{"content":"Lähdeoja, O., An approach to instrument augmentation: the electric guitar, Proc. New Interfaces for Musical Expression conference, NIME 2008.","paperID":"None"},{"content":"Lévy, B., Bloch, G., and Assayag, G., OMaxist Dialectics: Capturing, Visualizing and Expanding Improvisations, Proc. NIME 2012, Ann Arbor, 2012.","paperID":"None"},{"content":"Peeters, G., A large set of audio features for sound description (similarity and classification) in the CUIDADO project, Ircam Report 2000.","paperID":"None"},{"content":"Reboursière, L., Frisson, C., Lähdeoja, O., Anderson, J., Iii, M., Picard, C., and Todoroff, T., Multimodal Guitar: A Toolbox For Augmented Guitar Performances, Proc. of NIME, 2010.","paperID":"None"},{"content":"Schwarz, D. Current research in Concatenative Sound Synthesis, Proc. Int. Computer Music Conf., 2005.","paperID":"None"},{"content":"H. Lachambre , R. Andre-Obrecht , J. Pinquier, Distinguishing Monophonies From Polyphonies Using Weibull Bivariate Distributions, IEEE Transactions on Audio, Speech, and Language Processing, v.19 n.6, p.1837-1842, August 2011","paperID":"2335910"}],"abstract":"Loop pedals are real-time samplers that playback audio played previously by a musician. Such pedals are routinely used for music practice or outdoor \"busking\". However, loop pedals always playback the same material, which can make performances monotonous and boring both to the musician and the audience, preventing their widespread uptake in professional concerts. In response, we propose a new approach to loop pedals that addresses this issue, which is based on an analytical multi-modal representation of the audio input. Instead of simply playing back prerecorded audio, our system enables real-time generation of an audio accompaniment reacting to what is currently being performed by the musician. By combining different modes of performance - e.g. bass line, chords, solo - from the musician and system automatically, solo musicians can perform duets or trios with themselves, without engendering the so-called canned (boringly repetitive and unresponsive) music effect of loop pedals. We describe the technology, based on supervised classification and concatenative synthesis, and then illustrate our approach on solo performances of jazz standards by guitar. We claim this approach opens up new avenues for concert performance.","video":"http://www.youtube.com/embed/1D_sMj21LGA?rel=0","title":"Reflexive loopers for solo musical improvisation","filename":"CHI13/p2205","authors":["François Pachet","Pierre Roy","Julian Moreira","Mark d'Inverno"],"conference":"CHI '13"}