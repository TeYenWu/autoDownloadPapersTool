{"paperId":2702358,"reference":[{"content":"Action cam with gps - hdr-a30v/b review - sony us. http://store.sony.com/ compact-pov-action-cam-zid27-HDRAS30V/B/ cat-27-catid-All-Action-Cam. (Accessed: 2014-09--22).","paperID":"None"},{"content":"Adobe extensible metadata platform (xmp). http://www.adobe.com/products/xmp.html. (Accessed: 2014-09--22).","paperID":"None"},{"content":"Google maps api. https://developers.google.com/maps/. (Accessed: 2014-09--22).","paperID":"None"},{"content":"Ashihara, K., Kurakata, K., Mizunami, T., and Matsushita, K. Hearing threshold for pure tones above 20 khz. Acoustical science and technology 27, 1 (2006), 12--19.","paperID":"None"},{"content":"Bender, W., Gruhl, D., Morimoto, N., and Lu, A. Techniques for data hiding. IBM systems journal 35, 3.4 (1996), 313--336.","paperID":"None"},{"content":"Casares, J., Long, A. C., Myers, B. A., Bhatnagar, R., Stevens, S. M., Dabbish, L., Yocum, D., and Corbett, A. Simplifying video editing using metadata. In Proceedings of the 4th conference on Designing interactive systems: processes, practices, methods, and techniques, ACM (2002), 157--166.","paperID":"None"},{"content":"Cox, I., Miller, M., Bloom, J., and Miller, M. Digital watermarking. Morgan Kaufmann, 2001.","paperID":"None"},{"content":"Cox, I. J., Kilian, J., Leighton, F. T., and Shamoon, T. Secure spread spectrum watermarking for multimedia. IEEE Transactions on Image Processing 6, 12 (1997), 1673--1687.","paperID":"None"},{"content":"Gebbensleben, S., Dittmann, J., and Vielhauer, C. Multimodal audio guide for museums and exhibitions. In Electronic Imaging 2006, International Society for Optics and Photonics (2006), 60740S--60740S.","paperID":"None"},{"content":"Harada, S., Sato, D., Adams, D. W., Kurniawan, S., Takagi, H., and Asakawa, C. Accessible photo album: Enhancing the photo sharing experience for people with visual impairment. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI '13, ACM (2013), 2127--2136.","paperID":"None"},{"content":"Healy, R., and Timoney, J. Digital audio watermarking with semi-blind detection for in-car music content identification. In Proceedings of the AES 36th International Conference: Automotive AudioSound in Motion (2009).","paperID":"None"},{"content":"Heffner, H. E. Hearing in large and small dogs: Absolute thresholds and size of the tympanic membrane. Behavioral Neuroscience 97, 2 (1983), 310.","paperID":"None"},{"content":"Heffner, H. E., and Heffner, R. S. High-frequency hearing. Handbook of the senses: Audition (2008), 55--60.","paperID":"None"},{"content":"Hirabayashi, M., and Shimizu, M. Cryptone: Interaction between performers and audiences with inaudible dtmf sounds. In SIGGRAPH Asia 2012 Emerging Technologies, SA '12, ACM (2012), 5:1--5:4.","paperID":"None"},{"content":"Lavrenko, V., Feng, S., and Manmatha, R. Statistical models for automatic video annotation and retrieval. In Acoustics, Speech, and Signal Processing, 2004. Proceedings.(ICASSP'04). IEEE International Conference on, vol. 3, IEEE (2004), iii--1044.","paperID":"None"},{"content":"Mackay, W. E., and Beaudouin-Lafon, M. Diva: exploratory data analysis with multimedia streams. In Proceedings of the SIGCHI conference on Human factors in computing systems, ACM Press/Addison-Wesley Publishing Co. (1998), 416--423.","paperID":"None"},{"content":"Matsuoka, H., Nakashima, Y., Yoshimura, T., and Kawahara, T. Acoustic ofdm: Embedding high bit-rate data in audio. In Advances in Multimedia Modeling. Springer, 2008, 498--507.","paperID":"None"},{"content":"Nakayama, A., Machino, T., Kitagishi, I., Iwaki, S., and Okudaira, M. Rich communication with audio-controlled network robot. proposal of \"audio-motionmedia\". In Proceedings of the 11th IEEE International Workshop on Robot and Human Interactive Communication, IEEE (2002), 548--553.","paperID":"None"},{"content":"Patel, S. N., and Abowd, G. D. The contextcam: Automated point of capture video annotation. In Proceedings of the 6th International Conference on Ubiquitous Computing, Springer (2004), 301--318.","paperID":"None"},{"content":"Sarvas, R., Herrarte, E., Wilhelm, A., and Davis, M. Metadata creation system for mobile images. In Proceedings of the 2nd international conference on Mobile systems, applications, and services, ACM (2004), 36--48.","paperID":"None"},{"content":"Schenker, L. Pushbutton calling with a two-group voice-frequency code. Bell System Technical Journal 39, 1 (1960), 235--255.","paperID":"None"},{"content":"Stelmachowicz, P. G., Beauchaine, K. A., Kalberer, A., and Jesteadt, W. Normative thresholds in the 8 to 20khz range as a function of age. The Journal of the Acoustical Society of America 86, 4 (1989), 1384--1391.","paperID":"None"},{"content":"Tachibana, R. Audio watermarking for live performance. In Electronic Imaging 2003, International Society for Optics and Photonics (2003), 32--43.","paperID":"None"},{"content":"Watanabe, K., Tsukada, K., and Yasumura, M. Willcam: A digital camera visualizing users. interest. In CHI '07 Extended Abstracts on Human Factors in Computing Systems, CHI EA '07, ACM (2007), 2747--2752.","paperID":"None"},{"content":"Williams, J. R. Guidelines for the use of multimedia in instruction. In Proceedings of the Human Factors and Ergonomics Society Annual Meeting, vol. 42, SAGE Publications (1998), 1447--1451.","paperID":"None"},{"content":"Yi, J., Peng, Y., and Xiao, J. Exploiting semantic and visual context for effective video annotation. Multimedia, IEEE Transactions on 15, 6 (2013), 1400--1414.","paperID":"None"}],"citation":[],"abstract":"We present a video annotation system called ``AnnoTone', which can embed various contextual information describing a scene, such as geographical location. Then the system allows the user to edit the video using this contextual information, enabling one to, for example, overlay with map or graphical annotations. AnnoTone converts annotation data into high-frequency audio signals (which are inaudible to the human ear), and then transmits them from a smartphone speaker placed near a video camera. This scheme makes it possible to add annotations using standard video cameras with no requirements for specific equipment other than a smartphone. We designed the audio watermarking protocol using dual-tone multi-frequency signaling, and developed a general-purpose annotation framework including an annotation generator and extractor. We conducted a series of performance tests to understand the reliability and the quality of the watermarking method. We then created several examples of video-editing applications using annotations to demonstrate the usefulness of Annotone, including an After Effects plug-in.","title":"AnnoTone: Record-time Audio Watermarking for Context-aware Video Editing","filename":"CHI15/p57","authors":["Ryohei Suzuki","Daisuke Sakamoto","Takeo Igarashi"],"conference":"CHI '15"}