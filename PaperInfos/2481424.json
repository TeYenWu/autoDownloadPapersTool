{"paperId":2481424,"citation":[],"reference":[{"content":"Joel F. Bartlett, Rock 'n' Scroll Is Here to Stay, IEEE Computer Graphics and Applications, v.20 n.3, p.40-45, May 2000","paperID":"618728"},{"content":"Blask√≥, G., Beaver, W., Kamvar, M., and Feiner, S. Workplane-orientation sensing techniques for tablet PCs. Proceedings of the 17th Annual ACM symposium on User Interface Software and Technology, ACM Press (2004), 1--2.","paperID":"None"},{"content":"Chih-Chung Chang , Chih-Jen Lin, LIBSVM: A library for support vector machines, ACM Transactions on Intelligent Systems and Technology (TIST), v.2 n.3, p.1-27, April 2011","paperID":"1961199"},{"content":"Lung-Pan Cheng , Fang-I Hsiao , Yen-Ting Liu , Mike Y. Chen, iRotate: automatic screen rotation based on face orientation, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 05-10, 2012, Austin, Texas, USA","paperID":"2208374"},{"content":"Forstall, S. and Blumenberg, C. Portrait-Landscape Rotation Heuristics for a Portable Multifunction Device. US Patent. 20,080/165,144, 2011.","paperID":"None"},{"content":"Mayank Goel , Jacob Wobbrock , Shwetak Patel, GripSense: using built-in sensors to detect hand posture and pressure on commodity mobile phones, Proceedings of the 25th annual ACM symposium on User interface software and technology, October 07-10, 2012, Cambridge, Massachusetts, USA","paperID":"2380184"},{"content":"Ken Hinckley , Jeff Pierce , Mike Sinclair , Eric Horvitz, Sensing techniques for mobile interaction, Proceedings of the 13th annual ACM symposium on User interface software and technology, p.91-100, November 06-08, 2000, San Diego, California, USA","paperID":"354417"},{"content":"Ken Hinckley , Hyunyoung Song, Sensor synaesthesia: touch in motion, and motion in touch, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 07-12, 2011, Vancouver, BC, Canada","paperID":"1979059"},{"content":"Kee-Eung Kim , Wook Chang , Sung-Jung Cho , Junghyun Shim , Hyunjeong Lee , Joonah Park , Youngbeom Lee , Sangryong Kim, Hand grip pattern recognition for mobile user interfaces, Proceedings of the 18th conference on Innovative applications of artificial intelligence, p.1789-1794, July 16-20, 2006, Boston, Massachusetts","paperID":"1597138"},{"content":"Ording, B., Van Os, M., and Chaudhri, I. Screen Rotation Gestures on a Portable Multifunction Device. US Patent App. 20,080/211,778, 2011.","paperID":"None"},{"content":"Schmidt, A., Beigl, M., and Gellersen, H. W. There is more to context than location. Computers & Graphics 23, 6 (1999), 893--901.","paperID":"None"},{"content":"Brandon T. Taylor , V. Michael Bove, Jr., Graspables: grasp-recognition as a user interface, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 04-09, 2009, Boston, MA, USA","paperID":"1518842"},{"content":"Raphael Wimmer , Sebastian Boring, HandSense: discriminating different ways of grasping and holding a tangible user interface, Proceedings of the 3rd International Conference on Tangible and Embedded Interaction, February 16-18, 2009, Cambridge, United Kingdom","paperID":"1517736"}],"abstract":"Automatic screen rotation improves viewing experience and usability of mobile devices, but current gravity-based approaches do not support postures such as lying on one side, and manual rotation switches require explicit user input. iRotateGrasp automatically rotates screens of mobile devices to match users' viewing orientations based on how users are grasping the devices. Our insight is that users' grasps are consistent for each orientation, but significantly differ between different orientations. Our prototype used a total of 44 capacitive sensors along the four sides and the back of an iPod Touch, and uses support vector machine (SVM) to recognize grasps at 25Hz. We collected 6-users' usage under 108 different combinations of posture, orienta-tion, touchscreen operation, and left/right/both hands. Our offline analysis showed that our grasp-based approach is promising, with 80.9% accuracy when training and testing on different users, and up to 96.7% if users are willing to train the system. Our user study (N=16) showed that iRo-tateGrasp had an accuracy of 78.8% and was 31.3% more accurate than gravity-based rotation.","video":"http://www.youtube.com/embed/k22nhMKsaLs?rel=0","title":"IrotateGrasp: automatic screen rotation based on grasp of mobile devices","filename":"CHI13/p3051","authors":["Lung-Pan Cheng","Meng Han Lee","Che-Yang Wu","Fang-I Hsiao","Yen-Ting Liu","Hsiang-Sheng Liang","Yi-Ching Chiu","Ming-Sui Lee","Mike Y. Chen"],"conference":"CHI '13"}