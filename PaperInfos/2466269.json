{"paperId":2466269,"reference":[{"content":"Michael S. Bernstein , Joel Brandt , Robert C. Miller , David R. Karger, Crowds in two seconds: enabling realtime crowd-powered interfaces, Proceedings of the 24th annual ACM symposium on User interface software and technology, October 16-19, 2011, Santa Barbara, California, USA","paperID":"2047201"},{"content":"Jeffrey P. Bigham , Chandrika Jayant , Hanjie Ji , Greg Little , Andrew Miller , Robert C. Miller , Robin Miller , Aubrey Tatarowicz , Brandyn White , Samual White , Tom Yeh, VizWiz: nearly real-time answers to visual questions, Proceedings of the 23nd annual ACM symposium on User interface software and technology, October 03-06, 2010, New York, New York, USA","paperID":"1866080"},{"content":"Driedger, J. Time-scale modication algorithms for music audio signals. Master's thesis, Saarland University, 2011.","paperID":"None"},{"content":"C. Jensema, R. McCann, S. Ramsey. Closed-captioned TV presentation speed and vocabulary. In Am Ann Deaf. 141(4):284--92. 1996.","paperID":"None"},{"content":"Walter S. Lasecki , Jeffrey P. Bigham, Online quality control for real-time crowd captioning, Proceedings of the 14th international ACM SIGACCESS conference on Computers and accessibility, October 22-24, 2012, Boulder, Colorado, USA","paperID":"2384942"},{"content":"Walter S. Lasecki , Kyle I. Murray , Samuel White , Robert C. Miller , Jeffrey P. Bigham, Real-time crowd control of existing interfaces, Proceedings of the 24th annual ACM symposium on User interface software and technology, October 16-19, 2011, Santa Barbara, California, USA","paperID":"2047200"},{"content":"Walter Lasecki , Christopher Miller , Adam Sadilek , Andrew Abumoussa , Donato Borrello , Raja Kushalnagar , Jeffrey Bigham, Real-time captioning by groups of non-experts, Proceedings of the 25th annual ACM symposium on User interface software and technology, October 07-10, 2012, Cambridge, Massachusetts, USA","paperID":"2380122"},{"content":"Y. C. Beatrice Liem, H. Zhang. An iterative dual pathway structure for speech-to-text transcription. In HCOMP 2011.","paperID":"None"},{"content":"Saturnino Luz , Masood Masoodian , Bill Rogers, Supporting collaborative transcription of recorded speech with a 3D game interface, Proceedings of the 14th international conference on Knowledge-based and intelligent information and engineering systems: Part IV, September 08-10, 2010, Cardiff, UK","paperID":"1894019"},{"content":"Walter S. Lasecki , Young Chol Song , Henry Kautz , Jeffrey P. Bigham, Real-time crowd labeling for deployable activity recognition, Proceedings of the 2013 conference on Computer supported cooperative work, February 23-27, 2013, San Antonio, Texas, USA","paperID":"2441912"},{"content":"Werner Verhelst , Marc Roelands, An overlap-add technique based on waveform similarity (WSOLA) for high quality time-scale modification of speech, Proceedings of the 1993 IEEE international conference on Acoustics, speech, and signal processing: speech processing, April 27-30, 1993, Minneapolis, Minnesota, USA","paperID":"1947097"}],"citation":[{"content":"Walter S. Lasecki , Christopher D. Miller , Raja Kushalnagar , Jeffrey P. Bigham, Legion scribe: real-time captioning by the non-experts, Proceedings of the 10th International Cross-Disciplinary Conference on Web Accessibility, May 13-15, 2013, Rio de Janeiro, Brazil","paperID":"2461151"},{"content":"Walter S. Lasecki , Christopher D. Miller , Raja Kushalnagar , Jeffrey P. Bigham, Real-time captioning by non-experts with legion scribe, Proceedings of the 15th International ACM SIGACCESS Conference on Computers and Accessibility, October 21-23, 2013, Bellevue, Washington","paperID":"2513401"},{"content":"Walter S. Lasecki , Raja Kushalnagar , Jeffrey P. Bigham, Legion scribe: real-time captioning by non-experts, Proceedings of the 16th international ACM SIGACCESS conference on Computers & accessibility, October 20-22, 2014, Rochester, New York, USA","paperID":"2661352"},{"content":"Walter S. Lasecki , Jeffrey P. Bigham, Real-time captioning with the crowd, interactions, v.21 n.3, May-June 2014","paperID":"2594459"},{"content":"Walter S. Lasecki , Raja Kushalnagar , Jeffrey P. Bigham, Helping students keep up with real-time captions by pausing and highlighting, Proceedings of the 11th Web for All Conference, April 07-07, 2014, Seoul, Korea","paperID":"2596701"},{"content":"Soraia Silva Prietch , Napoliana Silva de Souza , Lucia Villela Leite Filgueiras, Application Requirements for Deaf Students to use in Inclusive Classrooms, Proceedings of the Latin American Conference on Human Computer Interaction, November 18-21, 2015, CÃ³rdoba, Argentina","paperID":"2824898"},{"content":"Rajan Vaish , Keith Wyngarden , Jingshu Chen , Brandon Cheung , Michael S. Bernstein, Twitch crowdsourcing: crowd contributions in short bursts of time, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 26-May 01, 2014, Toronto, Ontario, Canada","paperID":"2556996"},{"content":"Raja S. Kushalnagar , Walter S. Lasecki , Jeffrey P. Bigham, Accessibility Evaluation of Classroom Captions, ACM Transactions on Accessible Computing (TACCESS), v.5 n.3, p.1-24, January 2014","paperID":"2543578"},{"content":"Vinay Shashidhar , Nishant Pandey , Varun Aggarwal, Spoken English Grading: Machine Learning with Crowd Intelligence, Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, August 10-13, 2015, Sydney, NSW, Australia","paperID":"2788595"},{"content":"Erin Brady , Jeffrey P. Bigham, Crowdsourcing Accessibility: Human-Powered Access Technologies, Foundations and Trends in Human-Computer Interaction, v.8 n.4, p.273-372, 11 2015","paperID":"2864704"},{"content":"Erin Brady , Jeffrey P. Bigham, Crowdsourcing Accessibility: Human-Powered Access Technologies, Foundations and Trends in Human-Computer Interaction, v.8 n.4, p.273-372, 11 2015","paperID":"2858992"}],"abstract":"In this paper, we introduce the idea of \"warping time\" to improve crowd performance on the difficult task of captioning speech in real-time. Prior work has shown that the crowd can collectively caption speech in real-time by merging the partial results of multiple workers. Because non-expert workers cannot keep up with natural speaking rates, the task is frustrating and prone to errors as workers buffer what they hear to type later. The TimeWarp approach automatically increases and decreases the speed of speech playback systematically across individual workers who caption only the periods played at reduced speed. Studies with 139 remote crowd workers and 24 local participants show that this approach improves median coverage (14.8%), precision (11.2%), and per-word latency (19.1%). Warping time may also help crowds outperform individuals on other difficult real-time performance tasks.","video":"http://www.youtube.com/embed/MOp7uf2CY1o?rel=0","title":"Warping time for more effective real-time crowdsourcing","filename":"CHI13/p2033","authors":["Walter S. Lasecki","Christopher D. Miller","Jeffrey P. Bigham"],"conference":"CHI '13"}