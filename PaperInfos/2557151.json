{"paperId":2557151,"citation":[{"content":"Chat Wacharamanotham, Making bare hand input more accurate, CHI '14 Extended Abstracts on Human Factors in Computing Systems, April 26-May 01, 2014, Toronto, Ontario, Canada","paperID":"2559955"},{"content":"Euan Freeman , Stephen Brewster , Vuokko Lantz, Tactile Feedback for Above-Device Gesture Interfaces: Adding Touch to Touchless Interactions, Proceedings of the 16th International Conference on Multimodal Interaction, November 12-16, 2014, Istanbul, Turkey","paperID":"2663280"},{"content":"Sang Ho Yoon , Ke Huo , Karthik Ramani, TMotion: Embedded 3D Mobile Input using Magnetic Sensing Technique, Proceedings of the TEI '16: Tenth International Conference on Tangible, Embedded, and Embodied Interaction, February 14-17, 2016, Eindhoven, Netherlands","paperID":"2839463"}],"reference":[{"content":"Amartya Banerjee , Jesse Burstyn , Audrey Girouard , Roel Vertegaal, Pointable: an in-air pointing technique to manipulate out-of-reach targets on tabletops, Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces, November 13-16, 2011, Kobe, Japan","paperID":"2076357"},{"content":"William Buxton, A three-state model of graphical input, Proceedings of the IFIP TC13 Third Interational Conference on Human-Computer Interaction, p.449-456, August 27-31, 1990","paperID":"725582"},{"content":"F. Camp, A. Schick, and R. Stiefelhagen. How to click in mid-air. In Distributed, Ambient, and Pervasive Interactions, volume 8028 of LCNS, 78--86. 2013.","paperID":"None"},{"content":"M. Desmurget, M. Jordan, C. Prablanc, and M. Jeannerod. Constrained and unconstrained movements involve different control strategies. J NEUROPHYSIOL, 77(3):1644--1650, 1997.","paperID":"None"},{"content":"Otmar Hilliges , Shahram Izadi , Andrew D. Wilson , Steve Hodges , Armando Garcia-Mendoza , Andreas Butz, Interactions in the air: adding further depth to interactive tabletops, Proceedings of the 22nd annual ACM symposium on User interface software and technology, October 04-07, 2009, Victoria, BC, Canada","paperID":"1622203"},{"content":"M. Jeannerod. The timing of natural prehension movements. J MOTOR BEHAV, 16(3):235, 1984.","paperID":"None"},{"content":"Haruhisa Kato , Hiromasa Yanagihara, PACMAN UI: vision-based finger detection for positioning and clicking manipulations, Proceedings of the 15th international conference on Human-computer interaction with mobile devices and services, August 27-30, 2013, Munich, Germany","paperID":"2494652"},{"content":"Raghavendra S. Kattinakere , Tovi Grossman , Sriram Subramanian, Modeling steering within above-the-surface interaction layers, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 28-May 03, 2007, San Jose, California, USA","paperID":"1240678"},{"content":"Jinha Lee , Alex Olwal , Hiroshi Ishii , Cati Boulanger, SpaceTop: integrating 2D and spatial 3D interactions in a see-through desktop environment, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 27-May 02, 2013, Paris, France","paperID":"2470680"},{"content":"Nicolai Marquardt , Ricardo Jota , Saul Greenberg , Joaquim A. Jorge, The continuous interaction space: interaction techniques unifying touch and gesture on and above a digital surface, Proceedings of the 13th IFIP TC 13 international conference on Human-computer interaction, September 05-09, 2011, Lisbon, Portugal","paperID":"2042224"},{"content":"C. Mueller-Tomfelde, A. Wessels, and C. Schremmer. Tilted tabletops: In between horizontal and vertical workspaces. In Wksp on Horizontal Interactive Human Computer Systems, TABLETOP '08, 49--56. 2008.","paperID":"None"},{"content":"T. Mysliwiec. Fingermouse: A freehand computer pointing interface. In Int'l Conference on Automatic Face and Gesture Recognition, 372--377. 1994.","paperID":"None"},{"content":"Michael Ortega , Laurence Nigay, AirMouse: Finger Gesture for 2D and 3D Interaction, Proceedings of the 12th IFIP TC 13 International Conference on Human-Computer Interaction: Part II, August 24-28, 2009, Uppsala, Sweden","paperID":"1616253"},{"content":"Dmitry Pyryeskin , Mark Hancock , Jesse Hoey, Comparing elicited gestures to designer-created gestures for selection above a multitouch surface, Proceedings of the 2012 ACM international conference on Interactive tabletops and surfaces, November 11-14, 2012, Cambridge, Massachusetts, USA","paperID":"2396638"},{"content":"Martin Spindler , Marcel Martsch , Raimund Dachselt, Going beyond the surface: studying multi-layer interaction above the tabletop, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 05-10, 2012, Austin, Texas, USA","paperID":"2208583"},{"content":"Martin Spindler , Sophie Stellmach , Raimund Dachselt, PaperLens: advanced magic lens interaction above the tabletop, Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces, November 23-25, 2009, Banff, Alberta, Canada","paperID":"1731920"},{"content":"Sriram Subramanian , Dzimitry Aliakseyeu , Andr√©s Lucero, Multi-layer interaction for digital tables, Proceedings of the 19th annual ACM symposium on User interface software and technology, October 15-18, 2006, Montreux, Switzerland","paperID":"1166295"},{"content":"Daniel Vogel , Ravin Balakrishnan, Distant freehand pointing and clicking on very large, high resolution displays, Proceedings of the 18th annual ACM symposium on User interface software and technology, October 23-26, 2005, Seattle, WA, USA","paperID":"1095041"},{"content":"Andrew D. Wilson, Robust computer vision-based detection of pinching for one and two-handed gesture input, Proceedings of the 19th annual ACM symposium on User interface software and technology, October 15-18, 2006, Montreux, Switzerland","paperID":"1166292"},{"content":"Andrew D. Wilson , Hrvoje Benko, Combining multiple depth cameras and projectors for interactions on, above and between surfaces, Proceedings of the 23nd annual ACM symposium on User interface software and technology, October 03-06, 2010, New York, New York, USA","paperID":"1866073"},{"content":"Jacob O. Wobbrock , Leah Findlater , Darren Gergle , James J. Higgins, The aligned rank transform for nonparametric factorial analyses using only anova procedures, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 07-12, 2011, Vancouver, BC, Canada","paperID":"1978963"},{"content":"Chun Yu , Xu Tan , Yue Shi , Yuanchun Shi, Air finger: enabling multi-scale navigation by finger height above the surface, Proceedings of the 13th international conference on Ubiquitous computing, September 17-21, 2011, Beijing, China","paperID":"2030188"}],"abstract":"Using the space above desktop input devices adds a rich new input channel to desktop interaction. Input in this elevated layer has been previously used to modify the granularity of a 2D slider, navigate layers of a 3D body scan above a multitouch table and access vertically stacked menus. However, designing these interactions is challenging because the lack of haptic and direct visual feedback easily leads to input errors. For bare finger input, the user's fingers needs to reliably enter and stay inside the interactive layer, and engagement techniques such as midair clicking have to be disambiguated from leaving the layer. These issues have been addressed for interactions in which users operate other devices in midair, but there is little guidance for the design of bare finger input in this space.In this paper, we present the results of two user studies that inform the design of finger input above desktop devices. Our studies show that 2 cm is the minimum thickness of the above-surface volume that users can reliably remain within. We found that when accessing midair layers, users do not automatically move to the same height. To address this, we introduce a technique that dynamically determines the height at which the layer is placed, depending on the velocity profile of the user's initial finger movement into midair. Finally, we propose a technique that reliably distinguishes clicking from homing movements, based on the user's hand shape. We structure the presentation of our findings using Buxton's three-state input model, adding additional states and transitions for above-surface interactions.","video":"http://www.youtube.com/embed/GLZSzc2vuF4?rel=0","title":"Understanding finger input above desktop devices","filename":"CHI14/p1083","authors":["Chat Wacharamanotham","Kashyap Todi","Marty Pye","Jan Borchers"],"conference":"CHI '14"}