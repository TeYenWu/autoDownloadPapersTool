{"paperId":2702271,"citation":[{"content":"Peter Kiefer , Ioannis Giannopoulos, A Framework for Attention-Based Implicit Interaction on Mobile Screens, Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct, August 24-27, 2015, Copenhagen, Denmark","paperID":"2794339"}],"abstract":"We study eye gaze movement behavior during paper reading and generate a series of annotations from a user's reading features: gray shading to indicate reading speed, borders to indicate frequency of re-reading, and lines to indicate transitions between sections of a document. Through a user study, we validate that our SocialReading system that shares teachers' gaze data for an academic paper can improve students' reading comprehension of that paper.","reference":[{"content":"Ralf Biedert , Georg Buscher , Sven Schwarz , JÃ¶rn Hees , Andreas Dengel, Text 2.0, CHI '10 Extended Abstracts on Human Factors in Computing Systems, April 10-15, 2010, Atlanta, Georgia, USA","paperID":"1754093"},{"content":"Ralf Biedert , Andreas Dengel , Mostafa Elshamy , Georg Buscher, Towards robust gaze-based objective quality measures for text, Proceedings of the Symposium on Eye Tracking Research and Applications, March 28-30, 2012, Santa Barbara, California","paperID":"2168593"},{"content":"Georg Buscher , Andreas Dengel , Ludger van Elst , Florian Mittag, Generating and using gaze-based document annotations, CHI '08 Extended Abstracts on Human Factors in Computing Systems, April 05-10, 2008, Florence, Italy","paperID":"1358805"},{"content":"Luke Chircop , Jithin Radhakrishnan , Laila Selener , Ju Chiu, Markitup: crowdsourced collaborative reading, CHI '13 Extended Abstracts on Human Factors in Computing Systems, April 27-May 02, 2013, Paris, France","paperID":"2468831"},{"content":"Connor, C. E., Egeth, H. E., and Yantis, S. Visual attention: bottom-up versus top-down. Current Biology 14, 19 (2004), 850--852.","paperID":"None"},{"content":"Kai Kunze , Masakazu Iwamura , Koichi Kise , Seiichi Uchida , Shinichiro Omachi, Activity Recognition for the Mind: Toward a Cognitive \"Quantified Self\", Computer, v.46 n.10, p.105-108, October 2013","paperID":"2546347"},{"content":"Kai Kunze , Yuzuko Utsumi , Yuki Shiga , Koichi Kise , Andreas Bulling, I know what you are reading: recognition of document types using mobile eye tracking, Proceedings of the 2013 International Symposium on Wearable Computers, September 08-12, 2013, Zurich, Switzerland","paperID":"2494354"},{"content":"Lenzner, T., Kaczmirek, L., and Galesic, M. Seeing through the eyes of the respondent: an eye-tracking study on survey question comprehension. Int'l Journal of Public Opinion Research 23, 3 (2011), 361--373.","paperID":"None"},{"content":"Craig S. Tashman , W. Keith Edwards, Active reading and its discontents: the situations, problems and ideas of readers, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 07-12, 2011, Vancouver, BC, Canada","paperID":"1979376"},{"content":"Tan Vo , B. Sumudu U. Mendis , Tom Gedeon, Gaze pattern and reading comprehension, Proceedings of the 17th international conference on Neural information processing: models and applications, November 22-25, 2010, Sydney, Australia","paperID":"1939769"}],"title":"Gaze-Based Annotations for Reading Comprehension","filename":"CHI15/p1569","authors":["Shiwei Cheng","Zhiqiang Sun","Lingyun Sun","Kirsten Yee","Anind K. Dey"],"conference":"CHI '15"}