{"paperId":2858046,"abstract":"Smartwatches and activity trackers are becoming prevalent, providing information about health and fitness, and offering personalized progress monitoring. These wearable devices often offer multimodal feedback with embedded visual, audio, and vibrotactile displays. Vibrations are particularly useful when providing discreet feedback, without users having to look at a display or anyone else noticing, thus preserving the flow of the primary activity. Yet, current use of vibrations is limited to basic patterns, since representing more complex information with a single actuator is challenging. Moreover, it is unclear how much the user--s current physical activity may interfere with their understanding of the vibrations. We address both issues through the design and evaluation of ActiVibe, a set of vibrotactile icons designed to represent progress through the values 1 to 10. We demonstrate a recognition rate of over 96% in a laboratory setting using a commercial smartwatch. ActiVibe was also evaluated in situ with 22 participants for a 28-day period. We show that the recognition rate is 88.7% in the wild and give a list of factors that affect the recognition, as well as provide design guidelines for communicating progress via vibrations.","reference":[{"content":"Eve Hoggan, Andrew Crossan, Stephen A. Brewster, and Topi Kaaresoja. 2009. Audio or Tactile Feedback: Which Modality When--. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'09), 2253--2256.","paperID":"None"},{"content":"Martin Pielot and Rodrigo de Oliveira. 2013. Peripheral Vibro-Tactile Displays. In Proceedings of the 15th international conference on Human-computer interaction with mobile devices and services (MobileHCI'13), 1--10.","paperID":"None"},{"content":"Diane Tam, Karon E. MacLean, Joanna McGrenere, and Katherine J. Kuchenbecker. 2013. The Design and Field Observation of a Haptic Notification System for Timing Awareness During Oral Presentations. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'13), 1689--1698.","paperID":"None"},{"content":"Ringly. Ringly. 2015. Retrieved 09/15/2015 from: https://ringly.com.","paperID":"None"},{"content":"Bruce JP Mortimer, Gary A Zets, and Roger W Cholewiak. 2007. Vibrotactile Transduction and Transducers. The Journal of the Acoustical Society of America 121, 5: 2970--2977.","paperID":"None"},{"content":"Stephen Brewster and Lorna M. Brown. 2004. Tactons: Structured Tactile Messages for Non-Visual Information Display. In Proceedings of the fifth conference on Australasian user interface - Vol. 28, Australian Computer Society, Inc. 15--23.","paperID":"None"},{"content":"Sabrina Paneels, Margarita Anastassova, Steven Strachan, Sophie Pham Van, Saranya Sivacoumarane, and Christian Bolzmacher. 2013. What's around Me-- Multi-Actuator Haptic Feedback on the Wrist. In World Haptics Conference (WHC'13), 407--412.","paperID":"None"},{"content":"Thomas Pietrzak, Andrew Crossan, Stephen Brewster, Benoit Martin, and Isabelle Pecci. 2009. Creating Usable Pin Array Tactons for Nonvisual Information. IEEE Transactions on Haptics 2, 2: 61--72.","paperID":"None"},{"content":"Jerome Pasquero, Scott J. Stobbe, and Noel Stonehouse. 2011. A Haptic Wristwatch for Eyes-Free Interactions. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'11), 3257--3266.","paperID":"None"},{"content":"Hong Z. Tan and Alex Pentland. 1997. Tactual Displays for Wearable Computing. Personal Technologies 1, 4: 225--230.","paperID":"None"},{"content":"Ali Israr and Ivan Poupyrev. 2011. Tactile Brush: Drawing on Skin with a Tactile Grid Display. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'11), 2019--2028.","paperID":"None"},{"content":"Seungyon \"Claire\" Lee and Thad Starner. 2010. Buzzwear: Alert Perception in Wearable Tactile Displays on the Wrist. In SIGCHI Conference on Human Factors in Computing Systems (CHI'10), 433442.","paperID":"None"},{"content":"Koji Yatani and Khai Nhut Truong. 2009. Semfeel: A User Interface with Semantic Tactile Feedback for Mobile Touch-Screen Devices. In Proceedings of the 22nd annual ACM symposium on User interface software and technology (UIST'09), 111--120.","paperID":"None"},{"content":"Kevin A. Li, Timothy Y. Sohn, Steven Huang, and William G. Griswold. 2008. Peopletones: A System for the Detection and Notification of Buddy Proximity on Mobile Phones. In Proceedings of the 6th international conference on Mobile systems, applications, and services (MobiSys'08), 160--173.","paperID":"None"},{"content":"Sonja RÃ¼melin, Enrico Rukzio, and Robert Hardy. 2011. Naviradar: A Novel Tactile Information Display for Pedestrian Navigation. In Proceedings of the 24th annual ACM symposium on User interface software and technology (UIST'11), 293--302.","paperID":"None"},{"content":"Sunny Consolvo, David W. McDonald, Tammy Toscos, Mike Y. Chen, Jon Froehlich, Beverly Harrison, Predrag Klasnja, Anthony LaMarca, Louis LeGrand, Ryan Libby, Ian Smith, and James A. Landay. 2008. Activity Sensing in the Wild: A Field Trial of Ubifit Garden. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'08), 1797--1806.","paperID":"None"},{"content":"Predrag Klasnja, Beverly L. Harrison, Louis LeGrand, Anthony LaMarca, Jon Froehlich, and Scott E. Hudson. 2008. Using Wearable Sensors and Real Time Inference to Understand Human Recall of Routine Activities. In Proceedings of the 10th international conference on Ubiquitous computing (Ubicomp'08), 154--163.","paperID":"None"},{"content":"Nicholas D Lane, Mashfiqui Mohammod, Mu Lin, Xiaochao Yang, Hong Lu, Shahid Ali, Afsaneh Doryab, Ethan Berke, Tanzeem Choudhury, and Andrew Campbell. 2011. Bewell: A Smartphone Application to Monitor, Model and Promote Wellbeing. In Proceedings of the 5th international ICST conference on pervasive computing technologies for healthcare. (Pervasive Health'11), 23--26.","paperID":"None"},{"content":"Michael C Frank, Evelina Fedorenko, Peter Lai, Rebecca Saxe, and Edward Gibson. 2012. Verbal Interference Suppresses Exact Numerical Representation. Cognitive psychology 64, 1: 74--92.","paperID":"None"},{"content":"Karon E. MacLean. 2009. Putting Haptics into the Ambience. IEEE Transactions on Haptics 2, 3: 123135.","paperID":"None"}],"citation":[],"title":"ActiVibe: Design and Evaluation of Vibrations for Progress Monitoring","filename":"CHI16/p3261","authors":["Jessica R. Cauchard","Janette L. Cheng","Thomas Pietrzak","James A. Landay"],"conference":"CHI '16"}