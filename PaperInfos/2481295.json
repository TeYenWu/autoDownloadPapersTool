{"paperId":2481295,"citation":[{"content":"Gerardo Reynaga , Sonia Chiasson , Paul C. van Oorschot, Heuristics for the evaluation of captchas on smartphones, Proceedings of the 2015 British HCI Conference, July 13-17, 2015, Lincoln, Lincolnshire, United Kingdom","paperID":"2783583"}],"reference":[{"content":"Santosh Basapur , Shuang Xu , Mark Ahlenius , Young Seok Lee, User expectations from dictation on mobile devices, Proceedings of the 12th international conference on Human-computer interaction: interaction platforms and techniques, July 01, 2007, Beijing, China","paperID":"1757294"},{"content":"Bhatt, K., Evens, M., Argamon, S. Hedged Responses and Expressions of Affect in Human/Human and Human/Computer Tutorial Interactions. In Proc. COGSCI 2004.","paperID":"None"},{"content":"Jeffrey P. Bigham , Anna C. Cavender, Evaluating existing audio CAPTCHAs and an interface optimized for non-visual use, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 04-09, 2009, Boston, MA, USA","paperID":"1518983"},{"content":"Elie Bursztein , Steven Bethard , Celine Fabry , John C. Mitchell , Dan Jurafsky, How Good Are Humans at Solving CAPTCHAs? A Large Scale Evaluation, Proceedings of the 2010 IEEE Symposium on Security and Privacy, p.399-413, May 16-19, 2010","paperID":"1849987"},{"content":"Elie Bursztein , Matthieu Martin , John Mitchell, Text-based CAPTCHA strengths and weaknesses, Proceedings of the 18th ACM conference on Computer and communications security, October 17-21, 2011, Chicago, Illinois, USA","paperID":"2046724"},{"content":"Elie Bursztein , Romain Beauxis , Hristo Paskov , Daniele Perito , Celine Fabry , John Mitchell, The Failure of Noise-Based Non-continuous Audio Captchas, Proceedings of the 2011 IEEE Symposium on Security and Privacy, p.19-31, May 22-25, 2011","paperID":"2006754"},{"content":"Anna L. Cox , Paul A. Cairns , Alison Walton , Sasha Lee, Tlk or txt? Using voice input for SMS composition, Personal and Ubiquitous Computing, v.12 n.8, p.567-588, November  2008","paperID":"1416966"},{"content":"Christos A. Fidas , Artemios G. Voyiatzis , Nikolaos M. Avouris, On the necessity of user-friendly CAPTCHA, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 07-12, 2011, Vancouver, BC, Canada","paperID":"1979325"},{"content":"Aditi Sharma Grover , Madelaine Plauché , Etienne Barnard , Christiaan Kuun, HIV health information access using spoken dialogue systems: touchtone vs. speech, Proceedings of the 3rd international conference on Information and communication technologies and development, April 17-19, 2009, Doha, Qatar","paperID":"1812541"},{"content":"Myounghoon Jeon , Bruce N. Walker , Abhishek Srivastava, “Spindex” (Speech Index) Enhances Menus on Touch Screen Devices with Tapping, Wheeling, and Flicking, ACM Transactions on Computer-Human Interaction (TOCHI), v.19 n.2, p.1-27, July 2012","paperID":"2240162"},{"content":"Johnston, M., et al. Multimodal Language Processing for Mobile Information Access. In Proc. ICSLP 2002.","paperID":"None"},{"content":"Anuj Kumar , Tim Paek , Bongshin Lee, Voice typing: a new speech interaction model for dictation on touchscreen devices, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 05-10, 2012, Austin, Texas, USA","paperID":"2208386"},{"content":"Jonathan Lazar , Jinjuan Feng , Tim Brooks , Genna Melamed , Brian Wentz , Jon Holman , Abiodun Olalere , Nnanna Ekedebe, The SoundsRight CAPTCHA: an improved approach to audio human interaction proofs for blind users, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 05-10, 2012, Austin, Texas, USA","paperID":"2208385"},{"content":"MacKenzie, I. S., and Soukore, R. W. Text Entry for Mobile Computing: Models and Methods, Theory and Practice. Human-Computer Interaction, 17(2), 147--198.","paperID":"None"},{"content":"Indrani Medhi , Somani Patnaik , Emma Brunskill , S.N. Nagasena Gautama , William Thies , Kentaro Toyama, Designing mobile interfaces for novice and low-literacy users, ACM Transactions on Computer-Human Interaction (TOCHI), v.18 n.1, p.1-28, April 2011","paperID":"1959024"},{"content":"Antti Oulasvirta , Sakari Tamminen , Virpi Roto , Jaana Kuorelahti, Interaction in 4-second bursts: the fragmented nature of attentional resources in mobile HCI, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 02-07, 2005, Portland, Oregon, USA","paperID":"1055101"},{"content":"Lawrence Rabiner , Biing-Hwang Juang, Fundamentals of speech recognition, Prentice-Hall, Inc., Upper Saddle River, NJ, 1993","paperID":"153687"},{"content":"Julie Rico, Evaluating the social acceptability of multimodal mobile interactions, CHI '10 Extended Abstracts on Human Factors in Computing Systems, April 10-15, 2010, Atlanta, Georgia, USA","paperID":"1753877"},{"content":"Sauer, G., Hochheiser, H., Feng, J., Lazar, J. Towards a universally usable CAPTCHA. In Proc. SOAPS '08.","paperID":"None"},{"content":"Graig Sauer , Jonathan Lazar , Harry Hochheiser , Jinjuan Feng, Towards A Universally Usable Human Interaction Proof: Evaluation of Task Completion Strategies, ACM Transactions on Accessible Computing (TACCESS), v.2 n.4, p.1-32, June 2010","paperID":"1786776"},{"content":"Shirali-Shahreza, S., Penn, G. Realistic Answer Verification: An Analysis of User Errors in a Sentence-Repetition Task. To appear in Proc. SLT 2012.","paperID":"None"},{"content":"Shirali-Shahreza, S., Ganjali, Y., Balakrishnan, R. Verifying human users in Speech-Based interactions. In Proc. INTERSPEECH 2011, 1585--1588.","paperID":"None"},{"content":"Shirali-Shahreza, S., Shirali-Shahreza, M. A survey of human interactive proof systems. International Journal of Innovative Computing, Information and Control (IJICIC), 6, 3A, 855--876 (March 2010).","paperID":"None"},{"content":"Keith Vertanen , Per Ola Kristensson, Parakeet: a continuous speech recognition system for mobile touch-screen devices, Proceedings of the 14th international conference on Intelligent user interfaces, February 08-11, 2009, Sanibel Island, Florida, USA","paperID":"1502685"},{"content":"Luis von Ahn , Manuel Blum , John Langford, Telling humans and computers apart automatically, Communications of the ACM, v.47 n.2, p.56-60, February 2004","paperID":"966390"}],"abstract":"Speech certainly has advantages as an input modality for smartphone applications, especially in scenarios where using touch or keyboard entry is difficult, on increasingly miniaturized devices where useable keyboards are difficult to accommodate, or in scenarios where only small amounts of text need to be input, such as when entering SMS texts or responding to a CAPTCHA challenge. In this paper, we propose two new alternative ways to design CAPTCHAs in which the user says the answer instead of typing it with (a) output stimuli provided visually (SeeSay) or (b) auditorily (HearSay). Our user study results show that SeeSay CAPTCHA requires less time to be solved and users prefer it over current text-based CAPTCHA methods.","video":"http://www.youtube.com/embed/SV9XbWNRfNM?rel=0","title":"SeeSay and HearSay CAPTCHA for mobile interaction","filename":"CHI13/p2147","authors":["Sajad Shirali-Shahreza","Gerald Penn","Ravin Balakrishnan","Yashar Ganjali"],"conference":"CHI '13"}