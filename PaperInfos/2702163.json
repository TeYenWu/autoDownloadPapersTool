{"paperId":2702163,"reference":[{"content":"Argyle, M., and Cook, M. Gaze and mutual gaze. Cambridge University Press Cambridge, Eng. ; New York, 1976.","paperID":"None"},{"content":"Bee, N., Wagner, J., André, E., Vogt, T., Charles, F., Pizzi, D., and Cavazza, M. Discovering eye gaze behavior during human-agent conversation in an interactive storytelling application. In International Conference on Multimodal Interfaces and the Workshop on Machine Learning for Multimodal Interaction (2010), 9:1--9:8.","paperID":"None"},{"content":"Castiello, U. Understanding other people's actions: Intention and attention. Journal of Experimental Psychology: Human Perception and Performance 29 (2003), 416--430.","paperID":"None"},{"content":"Das, D., Rashed, M. G., Kobayashi, Y., and Kuno, Y. Recognizing gaze pattern for human robot interaction. In Proc. of HRI (2014), 142--143.","paperID":"None"},{"content":"Dorr, M., Böhme, M., Martinetz, T., and Barth, E. Gaze beats mouse: A case study. In The 3rd Conference on Communication by Gaze Interaction (COGAIN 2007) (2007), 16--19.","paperID":"None"},{"content":"Eichner, T., Prendinger, H., André, E., and IshizUnited Kingdoma, M. Attentive presentation agents. In Proc. of the 7th International Conference on Intelligent Virtual Agents (2007), 283--295.","paperID":"None"},{"content":"Emery, N. J. The eyes have it: the neuroethology, function and evolution of social gaze. Neuroscience and Biobehavioural Reviews 24 (2000), 581--604.","paperID":"None"},{"content":"Frischen, A., Bayliss, A. P., and Tipper, S. P. Gaze cueing of attention: visual attention, social cognition, and individual differences. Psychological bulletin 133 (2007).","paperID":"None"},{"content":"Gaver, W. W., Beaver, J., and Benford, S. Ambiguity as a resource for design. In Proc. of CHI (2003), 233--240.","paperID":"None"},{"content":"Grynszpan, O., Simonin, J., Martin, J.-C., and Nadel, J. Investigating social gaze as an action-perception online performance. Frontiers in Human Neuroscience 6, 94 (2012).","paperID":"None"},{"content":"Hillaire, S., Lécuyer, A., Cozot, R., and Casiez, G. Using an eye-tracking system to improve camera motions and depth-of-field blur effects in virtual environments. In VR (2008), 47--50.","paperID":"None"},{"content":"Ishii, R., Nakano, Y. I., and Nishida, T. Gaze awareness in conversational agents: Estimating a user's conversational engagement from eye gaze. ACM Trans. Interact. Intell. Syst. 3, 2 (Aug. 2013), 11:1--11:25.","paperID":"None"},{"content":"Isokoski, P., Joos, M., Spakov, O., and Martin, B. Gaze controlled games. Universal Access in the Information Society 8, 4 (Oct. 2009), 323--337.","paperID":"None"},{"content":"Istance, H., Hyrskykari, A., Vickers, S., and Chaves, T. For your eyes only: Controlling 3d online games by eye-gaze. In Proc. of INTERACT (2009), 314--327.","paperID":"None"},{"content":"Jönsson, E. If looks could kill - An Evaluation of Eye Tracking in Computer Games. Master's thesis, KTH Royal Institute of Technology, Sweden, 2005.","paperID":"None"},{"content":"Kleinke, C. L. Gaze and eye contact: a research review. Psychological bulletin (1986).","paperID":"None"},{"content":"Kobayashi, Y., Shibata, T., Hoshi, Y., Kuno, Y., Okada, M., and Yamazaki, K. Choosing answerers by observing gaze responses for museum guide robots. In Proc. of HRI (2010), 109--110.","paperID":"None"},{"content":"Kumar, M., Paepcke, A., and Winograd, T. Eyepoint: Practical pointing and selection using gaze and keyboard. In Proc. of CHI (2007), 421--430.","paperID":"None"},{"content":"Lahiri, U., Warren, Z., and Sarkar, N. Design of a gaze-sensitive virtual social interactive system for children with autism. Neural Systems and Rehabilitation Engineering, IEEE Transactions on 19, 4 (Aug 2011), 443--452.","paperID":"None"},{"content":"Mollenbach, E., Hansen, J., and Lillholm, M. Eye movements in gaze interaction. Journal of Eye Movement Research 6(2) (2013), 1--15.","paperID":"None"},{"content":"Muñoz, J., Yannakakis, G. N., Mulvey, F., Hansen, D. W., Gutierrez, G., and Sanchis, A. Towards Gaze-Controlled Platform Games. In Proc. of IEEE Conference on Computational Intelligence and Games (2011).","paperID":"None"},{"content":"Nacke, L. E., Kalyn, M., Lough, C., and Mandryk, R. L. Biofeedback game design: Using direct and indirect physiological control to enhance game interaction. In Proc. of CHI (2011), 103--112.","paperID":"None"},{"content":"Ruhland, K., Andrist, S., Badler, J. B., Peters, C. E., Badler, N. I., Gleicher, M., Mutlu, B., and McDonnell, R. Look me in the Eyes: A Survey of Eye and Gaze Animation for Virtual Agents and Artificial Systems. In EG 2014 - STARs, Eurographics Association (2014), 69--91.","paperID":"None"},{"content":"Smith, J. D., and Graham, T. C. N. Use of eye movements for video game control. In Proc. of ACE (2006).","paperID":"None"},{"content":"Stellmach, S., and Dachselt, R. Designing gaze-based user interfaces for steering in virtual environments. In Proc. of ETRA (2012), 131--138.","paperID":"None"},{"content":"Stellmach, S., and Dachselt, R. Investigating gaze-supported multimodal pan and zoom. In Proc. of ETRA (2012), 357--360.","paperID":"None"},{"content":"Sweetser, P., and Wyeth, P. Gameflow: A model for evaluating player enjoyment in games. Computers in Entertainment 3, 3 (July 2005), 3--3.","paperID":"None"},{"content":"Turner, J., Bulling, A., Alexander, J., and Gellersen, H. Cross-device gaze-supported point-to-point content transfer. In Proc. of ETRA (2014), 19--26.","paperID":"None"},{"content":"Vertegaal, R., Weevers, I., Sohn, C., and Cheung, C. Gaze-2: Conveying eye contact in group video conferencing using eye-controlled camera direction. In Proc. of CHI (2003), 521--528.","paperID":"None"},{"content":"Wetzel, S., Spiel, K., and Bertel, S. Dynamically adapting an ai game engine based on players' eye movements and strategies. In Proc. of the 2014 ACM SIGCHI Symposium on Engineering Interactive Computing Systems (2014), 3--12.","paperID":"None"},{"content":"Yang, R., and Zhang, Z. Eye gaze correction with stereovision for video-teleconferencing. In Proc. of ECCV (2002), 479--494.","paperID":"None"}],"citation":[{"content":"Andreas Bulling, Human visual behaviour for collaborative human-machine interaction, Adjunct Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2015 ACM International Symposium on Wearable Computers, September 07-11, 2015, Osaka, Japan","paperID":"2815378"},{"content":"Andrew T. Duchowski , Sophie Jörg , Tyler N. Allen , Ioannis Giannopoulos , Krzysztof Krejtz, Eye movement synthesis, Proceedings of the Ninth Biennial ACM Symposium on Eye Tracking Research & Applications, March 14-17, 2016, Charleston, South Carolina","paperID":"2857528"}],"abstract":"The eyes are a rich channel for non-verbal communication in our daily interactions. We propose social gaze interaction as a game mechanic to enhance user interactions with virtual characters. We develop a game from the ground-up in which characters are designed to be reactive to the player's gaze in social ways, such as getting annoyed when the player seems distracted or changing their dialogue depending on the player's apparent focus of attention. Results from a qualitative user study provide insights about how social gaze interaction is intuitive for users, elicits deep feelings of immersion, and highlight the players' self-consciousness of their own eye movements through their strong reactions to the characters.","title":"The Royal Corgi: Exploring Social Gaze Interaction for Immersive Gameplay","filename":"CHI15/p115","authors":["Melodie Vidal","Remi Bismuth","Andreas Bulling","Hans Gellersen"],"conference":"CHI '15"}