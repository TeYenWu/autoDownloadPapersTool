{"paperId":2702581,"citation":[],"reference":[{"content":"Braitenberg, V. Vehicles: Experiments in synthetic psychology. Cambridge, MA: MIT Press. 1984.","paperID":"None"},{"content":"Chan, L., Liang, R-H., Tsai M-C., Cheng K-Y., Su, CH., Chen, M.Y., Cheng, W-H., and Chen, B-Y. FingerPad: private and subtle interaction using fingertips. UIST '13. 255--260.","paperID":"None"},{"content":"Chen, K., Lyons, K., White, S., Patel, S. uTrack: 3D input using two magnetic sensors. UIST'13. 237--244.","paperID":"None"},{"content":"Coros, S,. Thomaszewski, B., Noris, G., Sueda, S., Forberg, M., Sumner, R., Matusik, W., and Bickel, B. Computational design of mechanical characters. ACM Trans. Graph. 32, 4 (July), 83:1--83:12.","paperID":"None"},{"content":"Follmer, S., Carr, D., Lovell, E., and Ishii, H. CopyCAD: remixing physical objects with copy and paste from the real world. UIST '10, 381--382.","paperID":"None"},{"content":"Follmer, S., and Ishii, H. KidCAD: digitally remixing toys through tangible tools. CHI '12, 2401--2410.","paperID":"None"},{"content":"Gershenfeld, N. Fab: The Coming of Revolution on Your Desktop-from Personal Computers to Personal Fabrication. Basic Books, New York, 2005.","paperID":"None"},{"content":"Gross, M., and Kemp, A. Gesture Modeling: Using Video to Capture Freehand Modeling Commands. CAAD Futures '01, 33--46.","paperID":"None"},{"content":"Grossman, T., Wigdor, D., and Balakrishnan, R. Multifinger gestural interaction with 3d volumetric displays. UIST '04, 61--70.","paperID":"None"},{"content":"Gustafson, S., Holz, C., and Baudisch, P. Imaginary phone. UIST '11, 283--292.","paperID":"None"},{"content":"Harrison, C., Benko, H., and Wilson, A.D. OmniTouch: wearable multitouch interaction everywhere. UIST '11, 441--450.","paperID":"None"},{"content":"Harrison, C., Ramamurthy, S., Hudson, S.E. Onbody interaction: armed and dangerous. TEI'12, 69--76.","paperID":"None"},{"content":"Harrison, C., Tan, D., Morris, D. Skinput: appropriating the body as an input surface. CHI'10. 453--462.","paperID":"None"},{"content":"Hincapie-Ramos, J-D,. Guo, X., Moghadasian, P. and Irani, P. 2014. Consumed Endurance: a metric to quantify arm fatigue of mid-air interactions. CHI'14, 1063--1072.","paperID":"None"},{"content":"Hinckley, K., Pausch, R., Goble, J. C., and Kassell, N. F. A survey of design issues in spatial input. UIST '94, 213--222.","paperID":"None"},{"content":"Holz, C., Grossman, T., Fitzmaurice, G., and Agur, A. Implanted user interfaces. CHI '12, 503--512.","paperID":"None"},{"content":"Holz, C., Wilson, A.D. Data Miming: inferring spatial object descriptions from human gesture. CHI '11, 811--820.","paperID":"None"},{"content":"Johnson, G., Gross, M., Do, E. Y.-L., and Hong, J. 2012. Sketch it, make it: sketching precise drawings for laser cutting. CHI'12, 1079--1082.","paperID":"None"},{"content":"Kim, D., Hilliges, O., Izadi, S., et al. Digits: freehand 3D interactions anywhere using a wrist-worn gloveless sensor. In UIST '12 , ACM Press (2012), 167--176.","paperID":"None"},{"content":"Kim, H., Albuquerque, G., Havemann, S., and Fellner, D. W. Tangible 3D: hand gesture interaction for immersive 3D modeling. EGVE '05, 191--199.","paperID":"None"},{"content":"Lau, M., Hirose, M., Ohgawara, A., Mitani, J., and Igarashi, T. Situated modeling: a shape-stamping interface with tangible primitives. TEI '12, 275--282.","paperID":"None"},{"content":"Leithinger, D., Lakatos, D., DeVincenzi, A., Blackshaw, M., Ishii, H. 2011. Direct and gestural interaction with relief: a 2.5D shape display. UIST '11, 541--548.","paperID":"None"},{"content":"Lin, S.-Y., Su, C.-H., Cheng, K.-Y., Liang, R.-H., Kuo, T.-H., and Chen, B.-Y. Pub - point upon body: exploring eyes-free interaction and methods on an arm. UIST '11, ACM Press (2011), 481--488.","paperID":"None"},{"content":"Liu, Y-J., Zhang, D-L., Yuen, M-F. A survey on CAD methods in 3D garment design. Computers in Industry, 61:6, August 2010, 576--593.","paperID":"None"},{"content":"Llamas, I., Kim, B., Gargus, J., Rossignac, J., and Shaw, C. D. Twister: a space-warp operator for the two-handed editing of 3D shapes. ACM Trans. Graph 22 (3), 2003. 663--668.","paperID":"None"},{"content":"Mori, Y., and Igarashi, T. Plushie: an interactive design system for plush toys. In ACM SIGGRAPH (2007).","paperID":"None"},{"content":"Mueller, S., Lopes, P., and Baudisch, P. Interactive construction: interactive fabrication of functional mechanical devices. UIST (2012), 599--606.","paperID":"None"},{"content":"Mujibiya, A., Cao, X., Tan, D.S., Morris, D., Patel, S.N., and Rekimoto, J. The sound of touch: on-body touch and gesture sensing based on transdermal ultrasound propagation. ITS '13 , 189--198.","paperID":"None"},{"content":"Ni, T., Karlson, A.K., and Wigdor, D. AnatOnMe: facilitating doctor-patient communication using a projection-based handheld device. CHI '11, 3333--3342.","paperID":"None"},{"content":"Ogata, M., Sugiura, Y., Makino, Y., Inami, M., and Imai, M. SenSkin: Adapting Skin as a Soft Interface. UIST'13, ACM Press (2013), 539--544.","paperID":"None"},{"content":"Olberding, S., Yeo, K.P., Nanayakkara, S., and Steimle, J. AugmentedForearm: exploring the design space of a display-enhanced forearm. AH '13, 9--12.","paperID":"None"},{"content":"Pottmann, H. Architectural Geometry and FabricationAware Design. Nexus Network Journal, 15:2, August 2013, Springer, Basel. 195--208.","paperID":"None"},{"content":"Saul, G., Lau, M., Mitani, J., and Igarashi, T. Sketchchair: an all-in-one chair design system for end users. TEI (2011), 73--80.","paperID":"None"},{"content":"Schkolne, S., Pruett, M., and Schröder, P. Surface drawing: creating organic 3D shapes with the hand and tangible tools. Proc. CHI '01, 261--268.","paperID":"None"},{"content":"Sheng, J., Balakrishnan, R., and Singh, K. An interface for virtual 3d sculpting via physical proxy. GRAPHITE (2006), 213--220.","paperID":"None"},{"content":"Smith, R.T., Thomas, B.H., and Piekarski, W. Digital foam interaction techniques for 3D modeling. VRST '08, 61--68.","paperID":"None"},{"content":"Umetani N., Danny M., Igarashi T., and Grinspun E. Sensitive couture for interactive garment modeling and editing. ACM Trans. Graph., 30:90:1--90:12, 2011.","paperID":"None"},{"content":"Volino, P., Cordier, F., and Magnenat-Thalmann, N. From early virtual garment simulation to interactive fashion design. Computer-Aided Design, 37:6, May 2005, 593--608.","paperID":"None"},{"content":"Wagner, J., Nancel, M., Gustafson, S.G., Huot, S., and Mackay, W.E. Body-centric design space for multisurface interaction. CHI'13, 1299--1308.","paperID":"None"},{"content":"Wang, J., Lu, G., Li, W., Chen, L., and Sakaguti, Y. Interactive 3D garment design with constrained contour curves and style curves. Computer-Aided Design, 41:9, September 2009, 614--625.","paperID":"None"},{"content":"Wang, R., Paris, S., and Popovíc, J. 6D hands: markerless hand-tracking for computer aided design. UIST'11, 549--558.","paperID":"None"},{"content":"Weichel, C., Lau, M., Kim, D., Villar, N., and Gellersen, H.W. MixFab: a mixed-reality environment for personal fabrication. CHI '14, 3855--3864.","paperID":"None"},{"content":"Weigel, M., Mehta, V., Steimle, J. More Than Touch: Understanding How People Use Skin as an Input Surface for Mobile Computing CHI '14.","paperID":"None"},{"content":"Wibowo, A., Sakamoto, D., Mitani, J., and Igarashi, T. DressUp: a 3D interface for clothing design with a physical mannequin. Proc. TEI '12, 99--102.","paperID":"None"},{"content":"Willis, K.D.D., Xu, C., Wu, J.K., Levin, G., and Gross, M.D. Interactive fabrication: new interfaces for digital fabrication. TEI '11, 69--72.","paperID":"None"},{"content":"Wilson, A. D. Using a depth camera as a touch sensor. ITS (2010), 69--72.","paperID":"None"},{"content":"Yamashita, M. M., Yamaoka, J., and Kakehi, Y. Enchanted Scissors: a scissor interface for support in cutting and interactive fabrication. In ACM SIGGRAPH 2013 Posters. SIGGRAPH '13.","paperID":"None"},{"content":"Yang, X.-D., Grossman, T., Wigdor, D., and Fitzmaurice, G. Magic finger: always-available input through finger instrumentation. ACM UIST'12, 147--156.","paperID":"None"},{"content":"Zhang. Y., Han, T., Ren, Z., Umetani, N., Tong, X., Liu, Y., Shiratori, T., and Cao, X. BodyAvatar: creating freeform 3D avatars using first-person body gestures. UIST '13, 387--396.","paperID":"None"},{"content":"Zoran, A., Shilkrot, R., and Paradiso, J. (2013) Humancomputer interaction for hybrid carving. UIST '13, 433440.","paperID":"None"}],"abstract":"Skin-based input has become an increasingly viable interaction model for user interfaces, however it has yet to be explored outside the domain of mobile computing. In this paper, we examine skin as an interactive input surface for gestural 3D modeling-to-fabrication systems. When used as both the input surface and base canvas for digital design, skin-input can enable non-experts users to intuitively create precise forms around highly complex physical contexts: our own bodies. In this paper, we outline design considerations when creating interfaces for such systems. We then discuss interaction techniques for three different modes of skin-centric modeling: direct, parametric, and generative. We also present Tactum, a new fabrication-aware design system that captures a user's skin-centric gestures for 3D modeling directly on the body. Lastly, we show sample artifacts generated with our system, and share a set of observations from design professionals.","video":"http://www.youtube.com/embed/2_U4oaZ850I?rel=0","title":"Tactum: A Skin-Centric Approach to Digital Design and Fabrication","filename":"CHI15/p1779","authors":["Madeline Gannon","Tovi Grossman","George Fitzmaurice"],"conference":"CHI '15"}