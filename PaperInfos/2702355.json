{"paperId":2702355,"citation":[{"content":"Lars Lischke , Jürgen Grüninger , Khalil Klouche , Albrecht Schmidt , Philipp Slusallek , Giulio Jacucci, Interaction Techniques for Wall-Sized Screens, Proceedings of the 2015 International Conference on Interactive Tabletops & Surfaces, November 15-18, 2015, Madeira, Portugal","paperID":"2835071"},{"content":"Andreas Bulling, Human visual behaviour for collaborative human-machine interaction, Adjunct Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2015 ACM International Symposium on Wearable Computers, September 07-11, 2015, Osaka, Japan","paperID":"2815378"},{"content":"Marcus Carter , Joshua Newn , Eduardo Velloso , Frank Vetere, Remote Gaze and Gesture Tracking on the Microsoft Kinect: Investigating the Role of Feedback, Proceedings of the Annual Meeting of the Australian Special Interest Group for Computer Human Interaction, December 07-10, 2015, Parkville, VIC, Australia","paperID":"2838778"},{"content":"Ken Pfeuffer , Jason Alexander , Ming Ki Chong , Yanxia Zhang , Hans Gellersen, Gaze-Shifting: Direct-Indirect Input with Pen and Touch Modulated by Gaze, Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology, November 08-11, 2015, Daegu, Kyungpook, Republic of Korea","paperID":"2807460"}],"reference":[{"content":"Ravin Balakrishnan , Ken Hinckley, Symmetric bimanual interaction, Proceedings of the SIGCHI conference on Human Factors in Computing Systems, p.33-40, April 01-06, 2000, The Hague, The Netherlands","paperID":"332404"},{"content":"Dominikus Baur , Sebastian Boring , Steven Feiner, Virtual projection: exploring optical projection as a metaphor for multi-device interaction, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 05-10, 2012, Austin, Texas, USA","paperID":"2208297"},{"content":"Sebastian Boring , Dominikus Baur , Andreas Butz , Sean Gustafson , Patrick Baudisch, Touch projector: mobile interaction through video, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 10-15, 2010, Atlanta, Georgia, USA","paperID":"1753671"},{"content":"Raimund Dachselt , Robert Buchholz, Natural throw and tilt interaction between mobile phones and distant displays, CHI '09 Extended Abstracts on Human Factors in Computing Systems, April 04-09, 2009, Boston, MA, USA","paperID":"1520467"},{"content":"Ribel Fares , Dustin Downing , Oleg Komogortsev, Magic-sense: dynamic cursor sensitivity-based magic pointing, CHI '12 Extended Abstracts on Human Factors in Computing Systems, May 05-10, 2012, Austin, Texas, USA","paperID":"2223824"},{"content":"Ribel Fares , Shaomin Fang , Oleg Komogortsev, Can we beat the mouse with MAGIC?, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 27-May 02, 2013, Paris, France","paperID":"2466183"},{"content":"Garner, W. R. The processing of information and structure. Psychology Press, 2014.","paperID":"None"},{"content":"Grasso, M. A., Ebert, D., and Finin, T. The effect of perceptual structure on multimodal speech recognition interfaces. organization (1998).","paperID":"None"},{"content":"Seungju Han , Hyunjeong Lee , Joonah Park , Wook Chang , Changyeong Kim, Remote interaction for 3D manipulation, CHI '10 Extended Abstracts on Human Factors in Computing Systems, April 10-15, 2010, Atlanta, Georgia, USA","paperID":"1754130"},{"content":"Robert J. K. Jacob, What you look at is what you get: eye movement-based interaction techniques, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, p.11-18, April 01-05, 1990, Seattle, Washington, USA","paperID":"97246"},{"content":"Robert J. K. Jacob , Linda E. Sibert , Daniel C. McFarlane , M. Preston Mullen, Jr., Integrality and separability of input devices, ACM Transactions on Computer-Human Interaction (TOCHI), v.1 n.1, p.3-26, March 1994","paperID":"174631"},{"content":"Daniel F. Keefe , Ankit Gupta , Daniel Feldman , John V. Carlis , Susi Krehbiel Keefe , Timothy J. Griffin, Scaling up multi-touch selection and querying: Interfaces and applications for combining mobile multi-touch input with large-scale visualization displays, International Journal of Human-Computer Studies, v.70 n.10, p.703-713, October, 2012","paperID":"2351170"},{"content":"Anthony Martinet , Géry Casiez , Laurent Grisoni, The effect of DOF separation in 3D manipulation tasks with multi-touch displays, Proceedings of the 17th ACM Symposium on Virtual Reality Software and Technology, November 22-24, 2010, Hong Kong","paperID":"1889888"},{"content":"Maurice R. Masliah, Quantifying human coordination in HCI, CHI '99 Extended Abstracts on Human Factors in Computing Systems, May 15-20, 1999, Pittsburgh, Pennsylvania","paperID":"632900"},{"content":"Mathieu Nancel , Julie Wagner , Emmanuel Pietriga , Olivier Chapuis , Wendy Mackay, Mid-air pan-and-zoom on wall-sized displays, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 07-12, 2011, Vancouver, BC, Canada","paperID":"1978969"},{"content":"Ken Pfeuffer , Jason Alexander , Ming Ki Chong , Hans Gellersen, Gaze-touch: combining gaze with multi-touch for interaction on the same surface, Proceedings of the 27th annual ACM symposium on User interface software and technology, October 05-08, 2014, Honolulu, Hawaii, USA","paperID":"2647397"},{"content":"Linda E. Sibert , Robert J. K. Jacob, Evaluation of eye gaze interaction, Proceedings of the SIGCHI conference on Human Factors in Computing Systems, p.281-288, April 01-06, 2000, The Hague, The Netherlands","paperID":"332445"},{"content":"Sophie Stellmach , Raimund Dachselt, Still looking: investigating seamless gaze-supported selection, positioning, and manipulation of distant targets, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 27-May 02, 2013, Paris, France","paperID":"2470695"},{"content":"Turner, J., Alexander, J., Bulling, A., Schmidt, D., and Gellersen, H. Eye pull, eye push: Moving objects between large screens and personal devices with gaze and touch. In Proc. INTERACT '13 (2013).","paperID":"None"},{"content":"Jayson Turner , Andreas Bulling , Jason Alexander , Hans Gellersen, Cross-device gaze-supported point-to-point content transfer, Proceedings of the Symposium on Eye Tracking Research and Applications, March 26-28, 2014, Safety Harbor, Florida","paperID":"2578155"},{"content":"Manuel Veit , Antonio Capobianco , Dominique Bechmann, Influence of degrees of freedom's manipulation on performances during orientation tasks in virtual reality environments, Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology, November 18-20, 2009, Kyoto, Japan","paperID":"1643942"},{"content":"Daniel Vogel , Ravin Balakrishnan, Distant freehand pointing and clicking on very large, high resolution displays, Proceedings of the 18th annual ACM symposium on User interface software and technology, October 23-26, 2005, Seattle, WA, USA","paperID":"1095041"},{"content":"Yanqing Wang , Christine L. MacKenzie , Valerie A. Summers , Kellogg S. Booth, The structure of object transportation and orientation in human-computer interaction, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, p.312-319, April 18-23, 1998, Los Angeles, California, USA","paperID":"274688"},{"content":"ByungIn Yoo , Jae-Joon Han , Changkyu Choi , Kwonju Yi , Sungjoo Suh , Dusik Park , Changyeong Kim, 3D user interface combining gaze and hand gestures for large-scale display, CHI '10 Extended Abstracts on Human Factors in Computing Systems, April 10-15, 2010, Atlanta, Georgia, USA","paperID":"1754043"},{"content":"Shumin Zhai , Paul Milgram, Quantifying coordination in multiple DOF movement and its application to evaluating 6 DOF input devices, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, p.320-327, April 18-23, 1998, Los Angeles, California, USA","paperID":"274689"},{"content":"Shumin Zhai , Carlos Morimoto , Steven Ihde, Manual and gaze input cascaded (MAGIC) pointing, Proceedings of the SIGCHI conference on Human Factors in Computing Systems, p.246-253, May 15-20, 1999, Pittsburgh, Pennsylvania, USA","paperID":"303053"}],"abstract":"Our work investigates the use of gaze and multitouch to fluidly perform rotate-scale-translate (RST) tasks on large displays. The work specifically aims to understand if gaze can provide benefit in such a task, how task complexity affects performance, and how gaze and multitouch can be combined to create an integral input structure suited to the task of RST. We present four techniques that individually strike a different balance between gaze-based and touch-based translation while maintaining concurrent rotation and scaling operations. A 16 participant empirical evaluation revealed that three of our four techniques present viable options for this scenario, and that larger distances and rotation/scaling operations can significantly affect a gaze-based translation configuration. Furthermore we uncover new insights regarding multimodal integrality, finding that gaze and touch can be combined into configurations that pertain to integral or separable input structures.","title":"Gaze+RST: Integrating Gaze and Multitouch for Remote Rotate-Scale-Translate Tasks","filename":"CHI15/p4179","authors":["Jayson Turner","Jason Alexander","Andreas Bulling","Hans Gellersen"],"conference":"CHI '15"}