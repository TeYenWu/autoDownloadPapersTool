{"paperId":2858436,"citation":[],"reference":[{"content":"Ahmed Sabbir Arif and Wolfgang Stuerzlinger. 2009. Analysis of text entry performance metrics. In Proceedings of the Toronto International Conference on Science and Technology for Humanity (TIC-STH). 100-105. DOI: http://dx.doi.org/10.1109/TIC-STH.2009.5444533","paperID":"None"},{"content":"Gilles Bailly, Jorg Muller, Michael Rohs, Daniel Wigdor, and Sven Kratz. 2012. ShoeSense: A New Perspective on Gestural Interaction and Wearable Applications. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '12). 1239-1248. DOI: http://dx.doi.org/10.1145/2207676.2208576","paperID":"None"},{"content":"Stephen Brewster, Roderick Murray-Smith, Andrew Crossan, Yolanda Vasquez-Alvarez, and Julie Rico. 2009. The GAIME project: Gestural and Auditory Interactions for Mobile Environments. In Whole Body Interaction Workshop, CHI'09 (2009).","paperID":"None"},{"content":"Liwei Chan, Chi-Hao Hsieh, Yi-Ling Chen, Shuo Yang, Da-Yuan Huang, Rong-Hao Liang, and Bing-Yu Chen. 2015. Cyclopss: Wearable and Single-Piece Full-Body Gesture Input Devices. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'15). 3001-3009. DOI: http://dx.doi.org/10.1145/2702123.2702464","paperID":"None"},{"content":"Seungmoon Choi and K.J. Kuchenbecker. 2013. Vibrotactile Display: Perception, Technology, and Applications. Proc. IEEE 101, 9 (Sept 2013), 2093-2104. DOI: http://dx.doi.org/10.1109/JPROC.2012.2221071","paperID":"None"},{"content":"Andrea Colaco. 2013. Sensor design and interaction techniques for gestural input to smart glasses and mobile devices. In Adjunct Publication of the Symposium on User Interface Software and Technology (UIST'13 Adjunct). 49-52. DOI: http://dx.doi.org/10.1145/2508468.2508474","paperID":"None"},{"content":"Tamara Denning, Zakariya Dehlawi, and Tadayoshi Kohno. 2014. In Situ with Bystanders of Augmented Reality Glasses: Perspectives on Recording and Privacy-mediating Technologies. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '14). 2377-2386. DOI: http://dx.doi.org/10.1145/2556288.2557352","paperID":"None"},{"content":"David Dobbelstein, Philipp Hock, and Enrico Rukzio. 2015. Belt: An Unobtrusive Touch Input Device for Head-worn Displays. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'15). 2135-2138. DOI: http://dx.doi.org/10.1145/2702123.2702450","paperID":"None"},{"content":"Jacques Foottit, Dave Brown, Stefan Marks, and Andy M. Connor. 2014. An Intuitive Tangible Game Controller. In Proceedings of the Conference on Interactive Entertainment (IE'14). 1-7. DOI: http://dx.doi.org/10.1145/2677758.2677774","paperID":"None"},{"content":"Clifton Forlines and Ravin Balakrishnan. 2008. Evaluating tactile feedback and direct vs. indirect stylus input in pointing and crossing selection tasks. In Proceeding of the SIGCHI Conference on Human Factors in Computing Systems (CHI'08). 1563-1572. DOI: http://dx.doi.org/10.1145/1357054.1357299","paperID":"None"},{"content":"Paulo Gallotti, Alberto Raposo, and Luciano Soares. 2011. v-Glove: A 3D Virtual Touch Interface. In Proceedings of the Symposium on Virtual Reality (SVR '11). 242-251. DOI: http://dx.doi.org/10.1109/SVR.2011.21","paperID":"None"},{"content":"Mayank Goel, Chen Zhao, Ruth Vinisha, and Shwetak N. Patel. 2015. Tongue-in-Cheek: Using Wireless Signals to Enable Non-Intrusive and Flexible Facial Gestures Detection. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'15). 255-258. DOI: http://dx.doi.org/10.1145/2702123.2702591","paperID":"None"},{"content":"Tovi Grossman, Xiang Anthony Chen, and George Fitzmaurice. 2015. Typing on Glasses: Adapting Text Entry to Smart Eyewear. In Proceedings of the SIGCHI Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI'15). 144-152. DOI:http://dx.doi.org/10.1145/2785830.2785867","paperID":"None"},{"content":"Faizan Haque, Mathieu Nancel, and Daniel Vogel. 2015. Myopoint: Pointing and Clicking Using Forearm Mounted Electromyography and Inertial Motion Sensors. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'15). 3653-3656. DOI: http://dx.doi.org/10.1145/2702123.2702133","paperID":"None"},{"content":"Chris Harrison, Desney Tan, and Dan Morris. 2010. Skinput: Appropriating the Body As an Input Surface. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '10). 453-462. DOI: http://dx.doi.org/10.1145/1753326.1753394","paperID":"None"},{"content":"Juan David Hincapie-Ramos, Xiang Guo, Paymahn Moghadasian, and Pourang Irani. 2014. Consumed endurance: A Metric to Quantify Arm Fatigue of Mid-Air Interactions. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'14). 1063-1072. DOI: http://dx.doi.org/10.1145/2556288.2557130","paperID":"None"},{"content":"Yi-Ta Hsieh, Antti Jylha, and Giulio Jacucci. 2014. Pointing and Selecting with Tactile Glove in 3D Environment. In Proceedings of the Workshop on Symbiotic Interaction (Springer LNCS 8820). 133-137. DOI: http://dx.doi.org/10.1007/978--3--319--13500--7_12","paperID":"None"},{"content":"Shoya Ishimaru, Kai Kunze, Koichi Kise, Jens Weppner, Andreas Dengel, Paul Lukowicz, and Andreas Bulling. 2014. In the blink of an eye Combining Head Motion and Eye Blink Frequency for Activity Recognition with Google Glass. In Proceedings of the International Conference on Augmented Human (AH'14). 1-4. DOI: http://dx.doi.org/10.1145/2582051.2582066","paperID":"None"},{"content":"Lei Jing, Zixue Cheng, Yinghui Zhou, Junbo Wang, and Tongjun Huang. 2013. Magic Ring: a self-contained gesture input device on finger. In Proceedings of the International Conference on Mobile and Ubiquitous Multimedia (MUM'13). 1-4. DOI: http://dx.doi.org/10.1145/2541831.2541875","paperID":"None"},{"content":"Antti Jylha, Yi-Ta Hsieh, Valeria Orso, Salvatore Andolina, Luciano Gamberini, and Giulio Jacucci. 2015. A Wearable Multimodal Interface for Exploring Urban Points of Interest. In Proceedings of the International Conference on Multimodal Interaction (ICMI '15). 175-182. DOI: http://dx.doi.org/10.1145/2818346.2820763","paperID":"None"},{"content":"David Kim, Otmar Hilliges, Shahram Izadi, Alex D Butler, Jiawen Chen, Iason Oikonomidis, and Patrick Olivier. 2012. Digits: freehand 3D interactions anywhere using a wrist-worn gloveless sensor. In Proceedings of the Symposium on User Interface Software and Technology (UIST'12). 167-176. DOI: http://dx.doi.org/10.1145/2380116.2380139","paperID":"None"},{"content":"Jungsoo Kim, Jiasheng He, Kent Lyons, and Thad Starner. 2007. The Gesture Watch: A Wireless Contact-free Gesture based Wrist Interface. In Proceedings of the International Symposium on Wearable Computers (ISWC'07). 1-8. DOI: http://dx.doi.org/10.1109/ISWC.2007.4373770","paperID":"None"},{"content":"Marion Koelle, Matthias Kranz, and Andreas Möller. 2015. Don't Look at Me That Way!: Understanding User Attitudes Towards Data Glasses Usage. In Proceedings of the International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI '15). 362-372. DOI: http://dx.doi.org/10.1145/2785830.2785842","paperID":"None"},{"content":"Barry Kollee, Sven Kratz, and Anthony Dunnigan. 2014. Exploring gestural interaction in smart spaces using head mounted devices with ego-centric sensing. In Proceedings of the Symposium on Spatial User Interaction (SUI'14). 40-49. DOI: http://dx.doi.org/10.1145/2659766.2659781","paperID":"None"},{"content":"Andres Lucero and Akos Vetek. 2014. NotifEye: Using Interactive Glasses to Deal with Notifications While Walking in Public. In Proceedings of the Conference on Advances in Computer Entertainment Technology (ACE '14). Article 17, 10 pages. DOI: http://dx.doi.org/10.1145/2663806.2663824","paperID":"None"},{"content":"Zhihan Lv, Alaa Halawani, Shengzhong Feng, Shafiq Ur Rehman, and Haibo Li. 2015. Touch-less Interactive Augmented Reality Game on Vision-based Wearable Device. Personal Ubiquitous Comput. 19, 3--4 (July 2015), 551-567. DOI: http://dx.doi.org/10.1007/s00779-015-0844--1","paperID":"None"},{"content":"K. Lyons, D. Plaisted, and T. Starner. 2004. Expert chording text entry on the Twiddler one-handed keyboard. In Proceedings of the International Symposium on Wearable Computers (ISWC'04), Vol. 1. 94-101. DOI: http://dx.doi.org/10.1109/ISWC.2004.19","paperID":"None"},{"content":"I. Scott MacKenzie and R. William Soukoreff. 2003. Phrase Sets for Evaluating Text Entry Techniques. In Extended Abstracts of SIGCHI Conference on Human Factors in Computing Systems (CHI EA '03). 754-755. DOI: http://dx.doi.org/10.1145/765891.765971","paperID":"None"},{"content":"Anders Markussen, Mikkel Rø nne Jakobsen, and Kasper Hornbæk. 2014. Vulture: A Mid-Air Word-Gesture Keyboard. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'14). 1073-1082. DOI: http://dx.doi.org/10.1145/2556288.2556964","paperID":"None"},{"content":"Tiago Martins, Christa Sommerer, Laurent Mignonneau, and Nuno Correia. 2008. Gauntlet: A Wearable Interface for Ubiquitous Gaming. In Proceedings of the International Conference on Human Computer Interaction with Mobile Devices and Services (MobileHCI '08). 367-370. DOI: http://dx.doi.org/10.1145/1409240.1409290","paperID":"None"},{"content":"Calkin S. Montero, Jason Alexander, Mark T. Marshall, and Sriram Subramanian. 2010. Would You Do That?: Understanding Social Acceptance of Gestural Interfaces. In Proceedings of the International Conference on Human Computer Interaction with Mobile Devices and Services (MobileHCI '10). 275-278. DOI: http://dx.doi.org/10.1145/1851600.1851647","paperID":"None"},{"content":"Anja Naumann, Jorn Hurtienne, Johann Habakuk Israel, Carsten Mohs, Martin Christof Kindsmuller, Herbert A. Meyer, and Steffi Husslein. 2007. Intuitive Use of User Interfaces: Defining a Vague Concept. In Proceedings of the International Conference on Engineering Psychology and Cognitive Ergonomics (EPCE'07). 128-136. http://dl.acm.org/citation.cfm?id=1784197.1784212","paperID":"None"},{"content":"Tao Ni, Doug Bowman, and Chris North. 2011. AirStroke: Bringing Unistroke Text Entry to Freehand Gesture Interfaces. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '11). 2473-2476. DOI: http://dx.doi.org/10.1145/1978942.1979303","paperID":"None"},{"content":"Taiwoo Park, Jinwon Lee, Inseok Hwang, Chungkuk Yoo, Lama Nachman, and Junehwa Song. 2011. E-Gesture: A Collaborative Architecture for Energy-efficient Gesture Recognition with Hand-worn Sensor and Mobile Devices. In Proceedings of the Conference on Embedded Networked Sensor Systems (SenSys '11). 260-273. DOI: http://dx.doi.org/10.1145/2070942.2070969","paperID":"None"},{"content":"Halley P. Profita, James Clawson, Scott Gilliland, Clint Zeagler, Thad Starner, Jim Budd, and Ellen Yi-Luen Do. 2013. Don't Mind Me Touching My Wrist: A Case Study of Interacting with On-body Technology in Public. In Proceedings of the International Symposium on Wearable Computers (ISWC '13). 89-96. DOI: http://dx.doi.org/10.1145/2493988.2494331","paperID":"None"},{"content":"Gang Ren and Eamonn O'Neill. 2013. Freehand Gestural Text Entry for Interactive TV. In Proceedings of the European Conference on Interactive TV and Video (EuroITV '13). 121-130. DOI: http://dx.doi.org/10.1145/2465958.2465966","paperID":"None"},{"content":"Julie Rico and Stephen Brewster. 2010. Usable Gestures for Mobile Interfaces: Evaluating Social Acceptability. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '10). 887-896. DOI: http://dx.doi.org/10.1145/1753326.1753458","paperID":"None"},{"content":"R. Rosenberg and M. Slater. 1999. The chording glove: a glove-based text input device. IEEE Trans. Systems, Man and Cybernetics, Part C (Applications and Reviews) 29, 2 (May 1999), 186-191. DOI: http://dx.doi.org/10.1109/5326.760563","paperID":"None"},{"content":"Tobias Schuchert, Sascha Voth, and Judith Baumgarten. 2012. Sensing visual attention using an interactive bidirectional HMD. In Proceedings of the Workshop on Eye Gaze in Intelligent Human Machine Interaction (Gaze-In'12). 1-3. DOI: http://dx.doi.org/10.1145/2401836.2401852","paperID":"None"},{"content":"Marcos Serrano, Barrett M. Ens, and Pourang P. Irani. 2014. Exploring the use of hand-to-face input for interacting with head-worn displays. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'14). 3181-3190. DOI: http://dx.doi.org/10.1145/2556288.2556984","paperID":"None"},{"content":"Garth Shoemaker, Leah Findlater, Jessica Q. Dawson, and Kellogg S. Booth. 2009. Mid-air text input techniques for very large wall displays. In Proceedings of Graphics Interface. 231-238. http://dl.acm.org/citation.cfm?id=1555880.1555931","paperID":"None"},{"content":"Srinath Sridhar, Anna Maria Feit, Christian Theobalt, and Antti Oulasvirta. 2015. Investigating the Dexterity of Multi-Finger Input for Mid-Air Text Entry. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'15). 3643-3652. DOI: http://dx.doi.org/10.1145/2702123.2702136","paperID":"None"},{"content":"Takumi Toyama, Daniel Sonntag, Andreas Dengel, Takahiro Matsuda, Masakazu Iwamura, and Koichi Kise. 2014. A mixed reality head-mounted text translation system using eye gaze input. In Proceedings of the International Conference on Intelligent User Interfaces (IUI'14). 329-334. DOI: http://dx.doi.org/10.1145/2557500.2557528","paperID":"None"},{"content":"Ying-Chao Tung, Chun-Yen Hsu, Han-Yu Wang, Silvia Chyou, Jhe-Wei Lin, Pei-Jung Wu, Andries Valstar, and Mike Y. Chen. 2015. User-Defined Game Input for Smart Glasses in Public Space. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'15). 3327-3336. DOI: http://dx.doi.org/10.1145/2702123.2702214","paperID":"None"},{"content":"Cheng-Yao Wang, Wei-Chen Chu, Po-Tsung Chiu, Min-Chieh Hsiu, Yih-Harn Chiang, and Mike Y. Chen. 2015. PalmType: Using palms as keyboards for smart glasses. In Proceedings of the SIGCHI Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI'15). 153-160. DOI: http://dx.doi.org/10.1145/2785830.2785886","paperID":"None"},{"content":"Martin Weigel, Tong Lu, Gilles Bailly, Antti Oulasvirta, Carmel Majidi, and Jurgen Steimle. 2015. iSkin: Flexible, Stretchable and Visually Customizable On-Body Touch Sensors for Mobile Computing. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'15). 2991-3000. DOI: http://dx.doi.org/10.1145/2702123.2702391","paperID":"None"},{"content":"Anusha Withana, Roshan Peiris, Nipuna Samarasekara, and Suranga Nanayakkara. 2015. zSense: Enabling Shallow Depth Gesture Recognition for Greater Input Expressivity on SmartWearables. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'15). 3661-3670. DOI: http://dx.doi.org/10.1145/2702123.2702371","paperID":"None"},{"content":"Sang Ho Yoon, Ke Huo, Vinh P Nguyen, and Karthik Ramani. 2015. TIMMi: Finger-worn Textile Input Device with Multimodal Sensing in Mobile Interaction. In Proceedings of the International Conference on Tangible, Embedded, and Embodied Interaction (TEI '15). 269-272. DOI: http://dx.doi.org/10.1145/2677199.2680560","paperID":"None"},{"content":"Xianjun Sam Zheng, Cedric Foucault, Patrik Matos da Silva, Siddharth Dasari, Tao Yang, and Stuart Goose. 2015. Eye-Wearable Technology for Machine Maintenance: Effects of Display Position and Hands-free Operation Xianjun. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'15). 2125-2134. DOI: http://dx.doi.org/10.1145/2702123.2702305","paperID":"None"}],"abstract":"Smart glasses suffer from obtrusive or cumbersome interaction techniques. Studies show that people are not willing to publicly use, for example, voice control or mid-air gestures in front of the face. Some techniques also hamper the high degree of freedom of the glasses. In this paper, we derive design principles for socially acceptable, yet versatile, interaction techniques for smart glasses based on a survey of related work. We propose an exemplary design, based on a haptic glove integrated with smart glasses, as an embodiment of the design principles. The design is further refined into three interaction scenarios: text entry, scrolling, and point-and-select. Through a user study conducted in a public space we show that the interaction technique is considered unobtrusive and socially acceptable. Furthermore, the performance of the technique in text entry is comparable to state-of-the-art techniques. We conclude by reflecting on the advantages of the proposed design.","title":"Designing a Willing-to-Use-in-Public Hand Gestural Interaction Technique for Smart Glasses","filename":"CHI16/p4203","authors":["Yi-Ta Hsieh","Antti Jylhä","Valeria Orso","Luciano Gamberini","Giulio Jacucci"],"conference":"CHI '16"}