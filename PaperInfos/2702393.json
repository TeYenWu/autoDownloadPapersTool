{"paperId":2702393,"citation":[],"reference":[{"content":"Van den Bogaert, T., Klasen, et al. Horizontal localization with bilateral hearing aids: Without is better than with. J. of the Acoustical Society of America 119, 1 (2006), 515.","paperID":"None"},{"content":"Braun, V. and Clarke, V. Using thematic analysis in psychology. Qual. Research Psych. 3, 2 (2006), 77--101.","paperID":"None"},{"content":"Demorest, M. & Erdman, S. Scale Composition and Item Analysis of the Communication Profile for the Hearing Impaired. J. Sp. Lang & Hear Res 29, 4 (1986), 515--535.","paperID":"None"},{"content":"Demorest, M.E. and Erdman, S.A. Development of the Communication Profile for the Hearing Impaired. Journal of Speech and Hearing Disorders 52, 2 (1987), 129--143.","paperID":"None"},{"content":"Gallaudet University. Resources to Develop Speechreading Skills. 2008. http://goo.gl/HALGdz.","paperID":"None"},{"content":"Galvin, K.L., Ginis, J., Cowan, R.S., et al. A Comparison of a New Prototype Tickle TalkerTM with the Tactaid 7. Aus. and NZ Journal of Audiology 23, 1 (2001), 18--36.","paperID":"None"},{"content":"Google Inc. Google Developers Glass Style. https://developers.google.com/glass/design/style.","paperID":"None"},{"content":"Grieco-Calub, T.M. and Litovsky, R.Y. Spatial acuity in 2-to-3year-old children with normal acoustic hearing, unilateral cochlear implants, and bilateral cochlear implants. Ear and hearing 33, 5 (2012), 561--72.","paperID":"None"},{"content":"Hallam, R.S. and Corney, R. Conversation tactics in persons with normal hearing and hearing-impairment. International journal of audiology 53, 3 (2014), 174--81.","paperID":"None"},{"content":"Hart, J., Onceanu, D., Sohn, C., et al. The Attentive Hearing Aid: Eye Selection of Auditory Sources for Hearing Impaired Users. INTERACT 2009, 19--35.","paperID":"None"},{"content":"Ho-Ching, F., Mankoff, J., & Landay, J.A. Can You See What I Hear?: The Design and Evaluation of a Peripheral Sound Display for the Deaf. CHI 2003, 161--168.","paperID":"None"},{"content":"Hruschka, D., Schwartz, D., St. John, D., et al. Reliability in Coding Open-Ended Data: Lessons Learned from HIV Behavioral Research. Fld Methds 16 , 3 (2004), 307--331.","paperID":"None"},{"content":"Jones, M., Lawler, M.J., Hintz, E., et al. Head Mounted Displays and Deaf Children: Facilitating Sign Language in Challenging Learning Environments. IDC'14, 317--320.","paperID":"None"},{"content":"Kaneko, Y., Chung, I., and Suzuki, K. Light-Emitting Device for Supporting Auditory Awareness of Hearing-Impaired People during Group Conversations. iSystems, Man, and Cybernetics (2013), 3567--3572.","paperID":"None"},{"content":"Van Krevelen, D.W.F. and Poelman, R. A Survey of Augmented Reality Technologies, Applications and Limitations. Intl J. of Virtual Reality 9, 2 (2010), 1--20.","paperID":"None"},{"content":"Lasecki, W.S. and Bigham, J.P. Real-time Captioning with the Crowd. interactions 21, 3 (2014), 50--55.","paperID":"None"},{"content":"Matthews, T., Fong, J., Ho-Ching, F., and Mankoff, J. Evaluating non-speech sound visualizations for the deaf. Behaviour & Information Tech. 25, 4 (2006), 333--351.","paperID":"None"},{"content":"Matthews, T., Fong, J., and Mankoff, J. Visualizing non-speech sounds for the deaf. ASSETS'05, 52--59.","paperID":"None"},{"content":"McCreery, R.W., et al. An evidence-based systematic review of directional microphones and digital noise reduction hearing aids in school-age children with hearing loss. American J. of Audiology 21, 2 (2012), 295--312.","paperID":"None"},{"content":"Medenica, Z., Kun, A., Paek, T., & Palinko, O. Augmented Reality vs. Street Views: A Driving Simulator Study Comparing Two Emerging Navigation Aids. MobileHCI'11, 265--274.","paperID":"None"},{"content":"Mueller, M.F., Meisenbacher, K., Lai, W., & Dillier, N. Sound localization with bilateral cochlear implants in noise: how much do head movements contribute to localization? Cochlear Implants Intl 15, 1 (2014), 36--42.","paperID":"None"},{"content":"Mynatt, E.D., Back, M., Want, R., Baer, M., and Ellis, J.B. Designing Audio Aura. CHI'98, 566--573.","paperID":"None"},{"content":"Picou, E., Aspell, E., & Ricketts, T. Potential benefits and limitations of three types of directional processing in hearing aids. Ear and hearing 35, 3 (2014), 339--52.","paperID":"None"},{"content":"Picou, E., Ricketts, T., & Hornsby, B. How Hearing Aids, Background Noise, and Visual Cues Influence Objective Listening Effort. Ear and Hearing 34, 5 (2013).","paperID":"None"},{"content":"Sodnik, J., Tomazic, S., Grasset, R., Duenser, A., and Billinghurst, M. Spatial Sound Localization in an Augmented Reality Environment. OZCHI'06, 111--118.","paperID":"None"},{"content":"Sony. Sony Access Glasses. http://goo.gl/0DKFoQ.","paperID":"None"},{"content":"Tomitsch, M. & Grechenig, T. Design Implications for a Ubiquitous Ambient Sound Display for Deaf. CVHI '07","paperID":"None"},{"content":"Tye-Murray, N., Purdy, S., and Woodworth, G. Reported Use of Communication Strategies by SHHH Members. J. of Speech Lang & Hearing Res 35, 3 (1992), 708.","paperID":"None"},{"content":"Visisonic Inc. VisiSonics RealSpaceTM Audio Camera. http://visisonics.com/realspace-audio-camera.","paperID":"None"},{"content":"Wald, M. Captioning for Deaf and Hard of Hearing People by Editing Automatic Speech Recognition in Real Time. ICCHP'06, 683--690.","paperID":"None"},{"content":"Yeung, E., Boothroyd, A., and Redmond, C. A Wearable Multichannel Tactile Display of Voice Fundamental Frequency. Ear and Hearing 9, 6 (1988), 342--350.","paperID":"None"},{"content":"Yoo, I. & Yook, D. Automatic sound recognition for the hearing impaired. IEEE Trns CE 54, 4 ('08), 2029--2036.","paperID":"None"},{"content":"Yuan, H., Reed, C.M., and Durlach, N.I. Tactual display of consonant voicing as a supplement to lipreading. J. of the Acoustical Society of America 118, 2 (2005), 1003.","paperID":"None"},{"content":"Zhang, Z. and Schuller, B. Semi-supervised learning helps in sound event classification. ICASSP'12, 333--336.","paperID":"None"},{"content":"Zhou, F., Duh, H.B., & Billinghurst, M. Trends in augmented reality tracking, interaction and display: A review of ten years of ISMAR. ISMAR'08, 193--202.","paperID":"None"},{"content":"Zotkin, D.N., et al. Chain architecture: An efficient hardware solution for a large microphone array system. Proceedings of Meetings on Acoustics, 2013, 3302--3322.","paperID":"None"},{"content":"Zotkin, D.N., Duraiswami, R., and Gumerov, N.A. Plane-Wave Decomposition of Acoustical Scenes Via Spherical and Cylindrical Microphone Arrays. IEEE Trans Audio, Speech, & Language Processing on 18, 1 (2010), 2--16.","paperID":"None"}],"abstract":"Persons with hearing loss use visual signals such as gestures and lip movement to interpret speech. While hearing aids and cochlear implants can improve sound recognition, they generally do not help the wearer localize sound necessary to leverage these visual cues. In this paper, we design and evaluate visualizations for spatially locating sound on a head-mounted display (HMD). To investigate this design space, we developed eight high-level visual sound feedback dimensions. For each dimension, we created 3-12 example visualizations and evaluated these as a design probe with 24 deaf and hard of hearing participants (Study 1). We then implemented a real-time proof-of-concept HMD prototype and solicited feedback from 4 new participants (Study 2). Study 1 findings reaffirm past work on challenges faced by persons with hearing loss in group conversations, provide support for the general idea of sound awareness visualizations on HMDs, and reveal preferences for specific design options. Although preliminary, Study 2 further contextualizes the design probe and uncovers directions for future work.","title":"Head-Mounted Display Visualizations to Support Sound Awareness for the Deaf and Hard of Hearing","filename":"CHI15/p241","authors":["Dhruv Jain","Leah Findlater","Jamie Gilkeson","Benjamin Holland","Ramani Duraiswami","Dmitry Zotkin","Christian Vogler","Jon E. Froehlich"],"conference":"CHI '15"}