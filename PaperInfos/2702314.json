{"paperId":2702314,"citation":[{"content":"Mathieu Chollet , Kalin Stefanov , Helmut Prendinger , Stefan Scherer, Public Speaking Training with a Multimodal Interactive Virtual Audience Framework, Proceedings of the 2015 ACM on International Conference on Multimodal Interaction, November 09-13, 2015, Seattle, Washington, USA","paperID":"2823294"},{"content":"Ionut Damian , Elisabeth André, Exploring the Potential of Realtime Haptic Feedback during Social Interactions, Proceedings of the TEI '16: Tenth International Conference on Tangible, Embedded, and Embodied Interaction, February 14-17, 2016, Eindhoven, Netherlands","paperID":"2856519"},{"content":"Jan Schneider , Dirk Börner , Peter van Rosmalen , Marcus Specht, Presentation Trainer, your Public Speaking Multimodal Coach, Proceedings of the 2015 ACM on International Conference on Multimodal Interaction, November 09-13, 2015, Seattle, Washington, USA","paperID":"2830603"},{"content":"Alessandro Montanari, Multimodal Indoor Social Interaction Sensing and Real-time Feedback for Behavioural Intervention, Proceedings of the 2015 Workshop on Wireless of the Students, by the Students, & for the Students, September 11-11, 2015, Paris, France","paperID":"2801706"}],"reference":[{"content":"Batrinca, L., Stratou, G., Shapiro, A., Morency, L.-P., and Scherer, S. Cicero - towards a multimodal virtual audience platform for public speaking training. In Proc. IVA, vol. 8108. Springer, 2013, 116--128.","paperID":"None"},{"content":"Baur, T., Damian, I., Gebhard, P., Porayska-Pomsta, K., and Andre, E. A job interview simulation: Social cue-based interaction with a virtual character. In Proc. SocialCom. IEEE, 2013, 220--227.","paperID":"None"},{"content":"Baur, T., Damian, I., Lingenfelser, F., Wagner, J., and Andre, E. Nova: Automated analysis of nonverbal signals in social interactions. In Human Behavior Understanding, vol. 8212 of LNCS. Springer, 2013.","paperID":"None"},{"content":"Bertin, J. Semiology of graphics: diagrams, networks, maps. University of Wisconsin press, 1983.","paperID":"None"},{"content":"Birdwhistell, R. L. Kinesics and context: Essays on body motion communication. University of Pennsylvania press, 2011.","paperID":"None"},{"content":"Blanch, D. C., Hall, J. A., Roter, D. L., and Frankel, R. M. Is it good to express uncertainty to a patient? correlates and consequences for medical students in a standardized patient visit. In Proc. EACH, vol. 76 (2009), 300--306.","paperID":"None"},{"content":"Caridakis, G., Raouzaiou, A., Karpouzis, K., and Kollias, S. Synthesizing gesture expressivity based on real sequences. Multimodal Corpora (2006). http://goo.gl/QXGyRG","paperID":"None"},{"content":"Carl, H. Nonverbal communication during the employment interview. ABCA Bulletin 44, 4 (1980).","paperID":"None"},{"content":"Cohen, B. M., and Etheredge, J. M. Recruiting's main ingredient. Journal of College Placement (1975).","paperID":"None"},{"content":"de Jong, N. H., and Wempe, T. Praat script to detect syllable nuclei and measure speech rate automatically. Behavior Research Methods 41, 2 (2009), 385--390.","paperID":"None"},{"content":"DeVaul, R. W., Pentland, A. S., and Corey, V. R. The memory glasses: Subliminal vs. overt memory support with imperfect information. In Proc. ISWC (2003).","paperID":"None"},{"content":"Drake, L. R., et al. How do employers value the interview?. Journal of College Placement 32, 3 (1972).","paperID":"None"},{"content":"Engelbart, D. C. Augmenting human intellect: A conceptual framework. Air Force Office of Scientific Research, AFOSR-3233, 1962.","paperID":"None"},{"content":"Fukumoto, K., Terada, T., and Tsukamoto, M. A smile/laughter recognition mechanism for smile-based life logging. In Proc. AH, ACM (2013), 213--220.","paperID":"None"},{"content":"Gabbard, J. L., Swan, J. E., Zedlitz, J., and Winchester, W. W. More than meets the eye: An engineering study to empirically examine the blending of real and virtual color spaces. In Proc. VR, IEEE (2010), 79--86.","paperID":"None"},{"content":"Hill J, R. W., Gratch, J., Marsella, S., Rickel, J., Swartout, W. R., and Traum, D. R. Virtual humans in the mission rehearsal exercise system. KI 17, 4 (2003), 5.","paperID":"None"},{"content":"Hogan, K. Can't Get Through: Eight Barriers to Communication. Pelican Publishing, 2003.","paperID":"None"},{"content":"Hollandsworth, J. G., Kazelskis, R., Stevens, J., and Dressel, M. E. Relative contributions of verbal, articulative, and nonverbal communication to employment decisions in the job interview setting. Personnel Psychology 32, 2 (1979), 359--367.","paperID":"None"},{"content":"Hoque, M. E., Courgeon, M., Martin, J., Mutlu, B., and Picard, R. W. Mach: My automated conversation coach. In Proc. UbiComp (2013).","paperID":"None"},{"content":"Hwang, I., Yoo, C., Hwang, C., Yim, D., Lee, Y., Min, C., Kim, J., and Song, J. Talkbetter: Family-driven mobile intervention care for children with language delay. In Proc. CSCW, ACM (2014), 1283--1296.","paperID":"None"},{"content":"Kim, T., Chang, A., Holland, L., and Pentland, A. S. Meeting mediator: Enhancing group collaborationusing sociometric feedback. In Proc. CSCW, ACM (2008).","paperID":"None"},{"content":"Lee, Y., Min, C., Hwang, C., Lee, J., Hwang, I., Ju, Y., Yoo, C., Moon, M., Lee, U., and Song, J. Sociophone: Everyday face-to-face interaction monitoring platform using multi-phone sensor fusion. In Proc. MobiSys, ACM (2013), 375--388.","paperID":"None"},{"content":"Li, X., and Rekimoto, J. Smartvoice: a presentation support system for overcoming the language barrier. In Proc. CHI, ACM (2014), 1563--1570.","paperID":"None"},{"content":"Lu, H., Frauendorfer, D., Rabbi, M., Mast, M. S., Chittaranjan, G. T., Campbell, A. T., Gatica-Perez, D., and Choudhury, T. Stresssense: Detecting stress in unconstrained acoustic environments using smartphones. In Proc. UbiComp, ACM (2012), 351--360.","paperID":"None"},{"content":"McAtamney, G., and Parker, C. An examination of the effects of a wearable display on informal face-to-face communication. In Proc. CHI, ACM (2006), 45--54.","paperID":"None"},{"content":"Mehrabian, A. Silent messages: Implicit Communication of Emotions and Attitudes. Wadsworth Publishing Co Inc, Belmont, 1981.","paperID":"None"},{"content":"Ofek, E., Iqbal, S. T., and Strauss, K. Reducing disruption from subtle information delivery during a conversation: Mode and bandwidth investigation. In Proc. CHI, ACM (2013), 3111--3120.","paperID":"None"},{"content":"Pan, X., Gillies, M., Barker, Clark, D. M. C. M., and Slater, M. Socially anxious and confident men interact with a forward virtual woman: An experiment study. PLoS ONE 7, 4 (2012), e32931.","paperID":"None"},{"content":"Pease, A. Body Language. Sheldon Press, London, 1988.","paperID":"None"},{"content":"Posthuma, R. A., Morgeson, F. P., and Campion, M. A. Beyond employment interview validity: A comprehensive narrative review of recent research and trends over time. Personnel Psychology 55, 1 (2002).","paperID":"None"},{"content":"Saket, B., Yang, S., Tan, H., Yatani, K., and Edge, D. Talkzones: Section-based time support for presentations. In Proc. MobileHCI, ACM (2014), 263--272.","paperID":"None"},{"content":"Scherl, C. R., and Haley, J. Computer monitor supervision: A clinical note. The American Journal of Family Therapy 28, 3 (2000), 275--282.","paperID":"None"},{"content":"Sieverding, M. be cool!: Emotional costs of hiding feelings in a job interview. International Journal of Selection and Assessment 17, 4 (2009), 391--401.","paperID":"None"},{"content":"Szczerba, J., Hersberger, R., and Riegelman, A. Design and evaluation of a differential speedometer. In Proc. HFES Meeting, vol. 56 (2012), 1629--1633.","paperID":"None"},{"content":"Tan, C. S. S., Schoning, J., Luyten, K., and Coninx, K. Investigating the effects of using biofeedback as visual stress indicator during video-mediated collaboration. In Proc. CHI, ACM (2014), 71--80.","paperID":"None"},{"content":"van der Linden, J., Johnson, R., Bird, J., Rogers, Y., and Schoonderwaldt, E. Buzzing to play: Lessons learned from an in the wild study of real-time vibrotactile feedback. In Proc. CHI, ACM (2011), 533--542.","paperID":"None"},{"content":"Wagner, J., Lingenfelser, F., Baur, T., Damian, I., Kistler, F., and Andre, E. The social signal interpretation (ssi) framework - multimodal signal processing and recognition in real-time. In Proc. ACM MM (2013).","paperID":"None"},{"content":"Xia, C., and Maes, P. The design of artifacts for augmenting intellect. In Proc. AH, ACM (2013).","paperID":"None"}],"abstract":"Nonverbal and unconscious behaviour is an important component of daily human-human interaction. This is especially true in situations such as public speaking, job interviews or information sensitive conversations, where researchers have shown that an increased awareness of one's behaviour can improve the outcome of the interaction. With wearable technology, such as Google Glass, we now have the opportunity to augment social interactions and provide realtime feedback on one's behaviour in an unobtrusive way. In this paper we present Logue, a system that provides realtime feedback on the presenters' openness, body energy and speech rate during public speaking. The system analyses the user's nonverbal behaviour using social signal processing techniques and gives visual feedback on a head-mounted display. We conducted two user studies with a staged and a real presentation scenario which yielded that Logue's feedback was perceived helpful and had a positive impact on the speaker's performance.","title":"Augmenting Social Interactions: Realtime Behavioural Feedback using Social Signal Processing Techniques","filename":"CHI15/p565","authors":["Ionut Damian","Chiew Seng (Sean) Tan","Tobias Baur","Johannes Schöning","Kris Luyten","Elisabeth André"],"conference":"CHI '15"}