{"paperId":2858416,"citation":[],"reference":[{"content":"Stephen Ades and Daniel C Swinehart. 1986. Voice annotation and editing in a workstation environment. XEROX Corporation, Palo Alto Research Center.","paperID":"None"},{"content":"Barry Arons. 1993. SpeechSkimmer: Interactively Skimming Recorded Speech. In Proceedings of the 6th Annual ACM Symposium on User Interface Software and Technology (UIST '93). ACM, NY, NY, USA, 187--196. DOI: http://dx.doi.org/10.1145/168642.168661","paperID":"None"},{"content":"Floraine Berthouzoz, Wilmot Li, and Maneesh Agrawala. 2012. Tools for Placing Cuts and Transitions in Interview Video. ACM Trans. Graph. 31, 4, Article 67 (July 2012), 8 pages. DOI: http://dx.doi.org/10.1145/2185520.2185563","paperID":"None"},{"content":"Steven Bird, Ewan Klein, and Edward Loper. 2009. Natural Language Processing with Python. O'Reilly Media.","paperID":"None"},{"content":"Thomas Cho. 2010. Linguistic Features of Electronic Mail in the Workplace: A Comparison with Memoranda. Language@Internet 7, 3 (2010).","paperID":"None"},{"content":"Juan Casares et al. 2002a. Simplifying Video Editing Using Metadata. In DIS '02 Proceedings. London, 157--166.","paperID":"None"},{"content":"Janet M. Baker et al. 2009. Developments and directions in speech recognition and understanding, Part 1. Signal Processing, IEEE 26, 3 (2009).","paperID":"None"},{"content":"Steve Whittaker et al. 2002b. SCANMail: a voicemail interface that makes speech browsable, readable and searchable. CHI Letters 4, 1 (2002).","paperID":"None"},{"content":"Alec Go, Richa Bhayani, and Lei Huang. 2009. Twitter Sentiment Classification using Distant Supervision. Technical Report. Stanford.","paperID":"None"},{"content":"Jonathan Grudin. 1988. Why CSCW applications fail: Problems in the design and evaluation of organizational interfaces. ACM Conference on Computer-Supported Cooperative Work (1988).","paperID":"None"},{"content":"C Halverson, D Horn, C Karat, and John Karat. 1999. The beauty of errors: Patterns of error correction in desktop speech systems. In Proceedings of INTERACT99. 133--140.","paperID":"None"},{"content":"Sandra G. Hart and Lowell E. Staveland. 1988. Development of NASA-TLX (Task Load Index): Results of empirical and theoretical research. In Human Mental Workload, P. A. Hancock and N. Meshkati (Eds.). North Holland Press, Amsterdam.","paperID":"None"},{"content":"Francis Heylighen and Jean-Marc Dewaele. 2002. Variation in the contextuality of language: an empirical measure. Foundations of Science 7 (2002), 239--340.","paperID":"None"},{"content":"Debby Hindus and Chris Schmandt. 1992. Ubiquitous Audio: Capturing Spontaneous Collaboration. In Proceedings of the 1992 ACM Conference on Computer-supported Cooperative Work (CSCW '92). ACM, NY, NY, USA, 210--217. DOI: http://dx.doi.org/10.1145/143457.143481","paperID":"None"},{"content":"Philip Ice, Reagan Curtis, Perry Phillips, and John Wells. 2007. Using asynchronous audio feedback to enhance teaching presence and students' sense of community. Journal of Asynchronous Learning Networks 11, 2 (2007).","paperID":"None"},{"content":"Sara Kiesler, Jane Siegel, and Timothy W. McGuire. 1984. Social Psychological Aspects of Computer-Mediated Communication. Amer. Psychologist 39, 10 (1984), 1123--1134.","paperID":"None"},{"content":"Henry Kucera and W. Nelson Francis. 1967. Computational Analysis of Present-Day American English. Brown University Press, Providence.","paperID":"None"},{"content":"Jennifer Lai and John Vergo. 1997. MedSpeak: Report Creation with Continuous Speech Recognition. In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems (CHI '97). ACM, NY, NY, USA, 431--438. DOI: http://dx.doi.org/10.1145/258549.258829","paperID":"None"},{"content":"Philip Marriott. 2002. Voice vs text-based discussion forums: An implementation of Wimba Voice Boards. In World Conference on E-Learning in Corporate, Government, Healthcare, and Higher Education, Vol. 2002. 640--646.","paperID":"None"},{"content":"Philip Marriott and Jane Hiscock. 2002. Voice vs Text-based Discussion Forums: An Implementation of Wimba Voice Boards. In Proc. E-Learn: World Conference on E-Learning in Corporate, Government, Healthcare, and Higher Education, M. Driscoll and T. Reeves (Eds.). Chesapeake, VA.","paperID":"None"},{"content":"Jody Oomen-Early, Mary Bold, Kristin L. Wiginton, Tara L. Gallien, and Nancy Anderson. 2008. Using asynchronous audio communication (AAC) in the online classroom: a comparative study. Journal of Online Learning and Teaching 4, 3 (2008).","paperID":"None"},{"content":"Steve Rubin, Floraine Berthouzoz, Gautham J. Mysore, Wilmot Li, and Maneesh Agrawala. 2013. Content-Based Tools for Editing Audio Stories. In UIST '13. 113--122.","paperID":"None"},{"content":"George Saon, Hong-Kwang J. Kuo, Steven Rennie, and Michael Picheny. 2015. The IBM 2015 English Conversational Telephone Speech Recognition System. Interspeech (2015).","paperID":"None"},{"content":"Christopher Schmandt. 1981. The Intelligent Ear: A Graphical Interface to Digital Audio. In Proceedings, IEEE International Conference on Cybernetics and Society, IEEE.","paperID":"None"},{"content":"Hagen Soltau, George Saon, and Tara N. Sainath. 2014. Joint training of convolutional and non-convolutional neural networks. In Proceedings of the IEEE Intl. Conference on Acoustic, Speech and Signal Processing. Florence, 5572--5576.","paperID":"None"},{"content":"Will Styler. 2011. The EnronSent Corpus. Technical Report 01--2011. University of CO at Boulder Institute of Cognitive Science, Boulder, CO.","paperID":"None"},{"content":"Chi-Hsiung Tu and Marina McIsaac. 2002. The Relationship of Social Presence and Interaction in Online Classes. Amer. Journal of Distance Education 16, 3 (2002).","paperID":"None"},{"content":"Sunil Vemuri, Philip DeCamp, Walter Bender, and Chris Schmandt. 2004a. Improving Speech Playback Using Time-compression and Speech Recognition. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '04). ACM, NY, NY, USA, 295--302. DOI: http://dx.doi.org/10.1145/985692.985730","paperID":"None"},{"content":"Sunil Vemuri, Philip DeCamp, Walter Bender, and Chris Schmandt. 2004b. Improving Speech Playback Using Time-Compression and Speech Recognition. CHI Letters 6, 1 (2004).","paperID":"None"},{"content":"Joseph B. Walther. 1995. Relational Aspects of Computer-Mediated Communication: Experimental Observations over Time. Organization Science 6, 2 (1995), 186--203.","paperID":"None"},{"content":"Steve Whittaker and Brian Amento. 2004. Semantic Speech Editing. CHI Letters (2004), 527--534.","paperID":"None"},{"content":"Lynn Wilcox, Ian Smith, and Marcia Bush. 1992. Wordspotting for Voice Editing and Audio Indexing. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '92). ACM, NY, NY, USA, 655--656. DOI: http://dx.doi.org/10.1145/142750.150715","paperID":"None"},{"content":"Dongwook Yoon, Nicholas Chen, Francois Guimbreti'ere, and Abigail Sellen. 2014. RichReview: blending ink, speech, and gesture to support collaborative document review. In Proceedings of the 27th annual ACM symposium on User interface software and technology. ACM, 481--490.","paperID":"None"},{"content":"Dongwook Yoon, Nicholas Chen, Bernie Randles, Amy Cheatle, Corinna E. Loeckenhoff, Steven J. Jackson, Abigail Sellen, and Francois Guimbreti'ere. 2016. Deployment of a Collaborative Multi-Modal Annotation System for Instructor Feedback and Peer Discussion. In Proceedings of the 19th ACM Conference on Computer Supported Cooperative Work & Social Computing. ACM.","paperID":"None"}],"abstract":"Voice communication adds nuance and expressivity to virtual discussions, but its one-shot nature tends to discourage collaborators from utilizing it. However, text-based interfaces have made voice editing much easier, especially with recent advancements enabling live, time-aligned speech transcription. We introduce SimpleSpeech, an easy-to-use platform for asynchronous audio communication (AAC) with lightweight tools for inserting content, adjusting pauses, and correcting transcript errors. Qualitative and quantitative results suggest that novice audio producers, such as high school students, experience decreased mental workload when using SimpleSpeech to produce audio messages than without editing. The linguistic formality in SimpleSpeech messages was also studied, and found to form a middle ground between oral and written media. Our findings on editable voice messages show new implications for the optimal design and use cases of AAC systems.","title":"Simplified Audio Production in Asynchronous Voice-Based Discussions","filename":"CHI16/p1045","authors":["Venkatesh Sivaraman","Dongwook Yoon","Piotr Mitros"],"conference":"CHI '16"}