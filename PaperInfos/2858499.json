{"paperId":2858499,"citation":[],"abstract":"People utilize eye gaze as an important cue for monitoring attention and coordinating awareness. This study investigates how remote pairs make use of a graphical representation of their partner's eye-gaze during a tightly-coupled collaborative task. Our results suggest that reproducing shared gaze in a remote collaboration setting makes pairs more accurate when referring to linguistically complex objects by facilitating the production of efficient forms of deictic references. We discuss how the availability of gaze influences coordination strategies and implications for the design of shared gaze in remote collaboration systems.","reference":[{"content":"Ellen Gurman Bard, Robin L. Hill, Mary Ellen Foster, and Manabu Arai. 2014. Tuning accessibility of referring expressions in situated dialogue. Language, Cognition and Neuroscience 29, 8: 928--949.","paperID":"None"},{"content":"Susan E. Brennan, Xin Chen, Christopher A. Dickinson, Mark B. Neider, and Gregory J. Zelinsky. 2008. Coordinating cognition: The costs and benefits of shared gaze during collaborative search. Cognition 106, 3: 1465--1477.","paperID":"None"},{"content":"Jean Carletta, Robin L. Hill, Craig Nicol, Tim Taylor, Jan Peter De Ruiter, and Ellen Gurman Bard. 2010. Eyetracking for two-person tasks with manipulation of a virtual world. Behavior Research Methods 42, 1: 254--265.","paperID":"None"},{"content":"Alan T. Clark and Darren Gergle. 2011. Mobile dual eye-tracking methods: challenges and opportunities. Proc. of International Workshop on Dual Eye Tracking.","paperID":"None"},{"content":"Herbert H. Clark and Susan E. Brennan. 1991. Grounding in communication. Perspectives on socially shared cognition 13, 1991: 127--149.","paperID":"None"},{"content":"Andrew Duchowski. 2007. Eye tracking methodology: Theory and practice. Springer Science & Business Media.","paperID":"None"},{"content":"Mica R. Endsley. 1995. Toward a theory of situation awareness in dynamic systems. Human Factors: The Journal of the Human Factors and Ergonomics Society 37, 1: 32--64.","paperID":"None"},{"content":"Susan R. Fussell, Robert E. Kraut, and Jane Siegel. 2000. Coordination of communication: Effects of shared visual context on collaborative work. Proceedings of the 2000 ACM conference on Computer supported cooperative work, ACM, 21--30.","paperID":"None"},{"content":"Susan R. Fussell, Leslie D. Setlock, Jie Yang, Jiazhi Ou, Elizabeth Mauer, and Adam DI Kramer. 2004. Gestures over video streams to support remote collaboration on physical tasks. Human-Computer Interaction 19, 3: 273--309.","paperID":"None"},{"content":"Darren Gergle, Robert E. Kraut, and Susan R. Fussell. 2013. Using visual information for grounding and awareness in collaborative tasks. Human-Computer Interaction 28, 1: 1--39.","paperID":"None"},{"content":"Joy E. Hanna and Susan E. Brennan. 2007. Speakers' eye gaze disambiguates referring expressions early during face-to-face conversation. Journal of Memory and Language 57, 4: 596--615.","paperID":"None"},{"content":"Patrick Jermann, Darren Gergle, Roman Bednarik, and Susan Brennan. 2012. Duet 2012: dual eye tracking in CSCW. Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work Companion, ACM, 23--24.","paperID":"None"},{"content":"Robert E. Kraut, Susan R. Fussell, and Jane Siegel. 2003. Visual information as a conversational resource in collaborative physical tasks. Human-Computer Interaction 18, 1: 13--49.","paperID":"None"},{"content":"Robert E. Kraut, Darren Gergle, and Susan R. Fussell. 2002. The use of visual information in shared visual spaces: Informing the development of virtual copresence. Proceedings of the 2002 ACM conference on Computer supported cooperative work, ACM, 31--40.","paperID":"None"},{"content":"Andrew F. Monk and Caroline Gale. 2002. A look is worth a thousand words: Full gaze awareness in video-mediated conversation. Discourse Processes 33, 3: 257--278.","paperID":"None"},{"content":"Mark B. Neider, Xin Chen, Christopher A. Dickinson, Susan E. Brennan, and Gregory J. Zelinsky. 2010. Coordinating spatial referencing using shared gaze. Psychonomic bulletin & review 17, 5: 718--724.","paperID":"None"},{"content":"Jiazhi Ou, Lui Min Oh, Susan R. Fussell, Tal Blum, and Jie Yang. 2008. Predicting visual focus of attention from intention in remote collaborative tasks. Multimedia, IEEE Transactions on 10, 6: 1034--1045.","paperID":"None"},{"content":"Bertrand Schneider and Roy Pea. 2013. Real-time mutual gaze perception enhances collaborative learning and collaboration quality. International Journal of Computer-Supported Collaborative Learning 8, 4: 375--397.","paperID":"None"},{"content":"Roel Vertegaal, Robert Slagter, Gerrit Van der Veer, and Anton Nijholt. 2001. Eye gaze patterns in conversations: there is more to conversational agents than meets the eyes. Proceedings of the SIGCHI conference on Human factors in computing systems, ACM,301--308.","paperID":"None"}],"title":"Gazed and Confused: Understanding and Designing Shared Gaze for Remote Collaboration","filename":"CHI16/p2492","authors":["Sarah D'Angelo","Darren Gergle"],"conference":"CHI '16"}