{"paperId":2466114,"abstract":"Imaginary Interfaces are screen-less ultra-mobile interfaces. Previously we showed that even though they offer no visual feedback they allow users to interact spatially, e.g., by pointing at a location on their non-dominant hand.The primary goal of this paper is to provide a deeper understanding of palm-based imaginary interfaces, i.e., why they work. We perform our exploration using an interaction style inspired by interfaces for visually impaired users. We implemented a system that audibly announces target names as users scrub across their palm. Based on this interface, we conducted three studies. We found that (1) even though imaginary interfaces cannot display visual contents, users' visual sense remains the main mechanism that allows users to control the interface, as they watch their hands interact. (2) When we remove the visual sense by blindfolding, the tactile cues of both hands feeling each other in part replace the lacking visual cues, keeping imaginary interfaces usable. (3) While we initially expected the cues sensed by the pointing finger to be most important, we found instead that it is the tactile cues sensed by the palm that allow users to orient themselves most effectively.While these findings are primarily intended to deepen our understanding of Imaginary Interfaces, they also show that eyes-free interfaces located on skin outperform interfaces on physical devices. In particular, this suggests that palm-based imaginary interfaces may have benefits for visually impaired users, potentially outperforming the touchscreen-based devices they use today.","video":"http://www.youtube.com/embed/jJ9SKdEcIoQ?rel=0","citation":[{"content":"Florian Müller , Mohammadreza Khalilbeigi , Niloofar Dezfuli , Alireza Sahami Shirazi , Sebastian Günther , Max Mühlhäuser, A Study on Proximity-based Hand Input for One-handed Mobile Interaction, Proceedings of the 3rd ACM Symposium on Spatial User Interaction, August 08-09, 2015, Los Angeles, California, USA","paperID":"2788955"},{"content":"David Dobbelstein , Philipp Hock , Enrico Rukzio, Belt: An Unobtrusive Touch Input Device for Head-worn Displays, Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, April 18-23, 2015, Seoul, Republic of Korea","paperID":"2702450"},{"content":"Jérémie Gilliot , Géry Casiez , Nicolas Roussel, Impact of form factors and input conditions on absolute indirect-touch pointing tasks, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 26-May 01, 2014, Toronto, Ontario, Canada","paperID":"2556997"},{"content":"Martin Weigel , Vikram Mehta , Jürgen Steimle, More than touch: understanding how people use skin as an input surface for mobile computing, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 26-May 01, 2014, Toronto, Ontario, Canada","paperID":"2557239"},{"content":"Marcos Serrano , Barrett M. Ens , Pourang P. Irani, Exploring the use of hand-to-face input for interacting with head-worn displays, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 26-May 01, 2014, Toronto, Ontario, Canada","paperID":"2556984"},{"content":"Manuel Prätorius , Dimitar Valkov , Ulrich Burgbacher , Klaus Hinrichs, DigiTap: an eyes-free VR/AR symbolic input device, Proceedings of the 20th ACM Symposium on Virtual Reality Software and Technology, November 11-13, 2014, Edinburgh, Scotland","paperID":"2671029"},{"content":"Uran Oh , Leah Findlater, Design of and subjective response to on-body input for people with visual impairments, Proceedings of the 16th international ACM SIGACCESS conference on Computers & accessibility, October 20-22, 2014, Rochester, New York, USA","paperID":"2661376"},{"content":"Hanlu Ye , Meethu Malu , Uran Oh , Leah Findlater, Current and future mobile and wearable device use by people with visual impairments, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 26-May 01, 2014, Toronto, Ontario, Canada","paperID":"2557085"},{"content":"Christian Corsten , Christian Cherek , Thorsten Karrer , Jan Borchers, HaptiCase: Back-of-Device Tactile Landmarks for Eyes-Free Absolute Indirect Touch, Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, April 18-23, 2015, Seoul, Republic of Korea","paperID":"2702277"},{"content":"Pedro Lopes , Alexandra Ion , Willi Mueller , Daniel Hoffmann , Patrik Jonell , Patrick Baudisch, Proprioceptive Interaction, Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, April 18-23, 2015, Seoul, Republic of Korea","paperID":"2702461"},{"content":"Zhanpeng Huang , Weikai Li , Pan Hui, Ubii: Towards Seamless Interaction between Digital and Physical Worlds, Proceedings of the 23rd ACM international conference on Multimedia, October 26-30, 2015, Brisbane, Australia","paperID":"2806266"},{"content":"Roman Lissermann , Jochen Huber , Aristotelis Hadjakos , Suranga Nanayakkara , Max Mühlhäuser, EarPut: augmenting ear-worn devices for ear-based interaction, Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: the Future of Design, December 02-05, 2014, Sydney, New South Wales, Australia","paperID":"2686655"},{"content":"Cheng-Yao Wang , Wei-Chen Chu , Po-Tsung Chiu , Min-Chieh Hsiu , Yih-Harn Chiang , Mike Y. Chen, PalmType: Using Palms as Keyboards for Smart Glasses, Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services, August 24-27, 2015, Copenhagen, Denmark","paperID":"2785886"},{"content":"Cheng-Yao Wang , Min-Chieh Hsiu , Po-Tsung Chiu , Chiao-Hui Chang , Liwei Chan , Bing-Yu Chen , Mike Y. Chen, PalmGesture: Using Palms as Gesture Interfaces for Eyes-free Input, Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services, August 24-27, 2015, Copenhagen, Denmark","paperID":"2785885"},{"content":"Uran Oh , Leah Findlater, A Performance Comparison of On-Hand versus On-Phone Nonvisual Input by Blind and Sighted Users, ACM Transactions on Accessible Computing (TACCESS), v.7 n.4, p.1-20, November 2015","paperID":"2820616"}],"title":"Understanding palm-based imaginary interfaces: the role of visual and tactile cues when browsing","filename":"CHI13/p889","authors":["Sean G. Gustafson","Bernhard Rabe","Patrick M. Baudisch"],"conference":"CHI '13","reference":[{"content":"Apple. VoiceOver for iPhone. http://www.apple.com/accessibility/iphone/vision.html","paperID":"None"},{"content":"Bolanowski S. J., Verrillo R. T., McGlone F. Passive, active and intraactive (self) touch. Behavioural Brain Research 148, (2004), 41--45.","paperID":"None"},{"content":"Stephen Brewster , Joanna Lumsden , Marek Bell , Malcolm Hall , Stuart Tasker, Multimodal 'eyes-free' interaction techniques for wearable devices, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 05-10, 2003, Ft. Lauderdale, Florida, USA","paperID":"642694"},{"content":"Xiang 'Anthony' Chen , Nicolai Marquardt , Anthony Tang , Sebastian Boring , Saul Greenberg, Extending a mobile device's interaction space through body-centric interaction, Proceedings of the 14th international conference on Human-computer interaction with mobile devices and services, September 21-24, 2012, San Francisco, California, USA","paperID":"2371599"},{"content":"Code Factory. Mobile Speak. http://www.codefactory.es/en/products.asp?id=316","paperID":"None"},{"content":"Niloofar Dezfuli , Mohammadreza Khalilbeigi , Jochen Huber , Florian Müller , Max Mühlhäuser, PalmRC: imaginary palm-based remote control for eyes-free television interaction, Proceedings of the 10th European conference on Interactive tv and video, July 04-06, 2012, Berlin, Germany","paperID":"2325623"},{"content":"Driver J., and Spence C. Attention and the crossmodal construction of space. Trends in Cognitive Sciences 2, 7, (1998), 254--262.","paperID":"None"},{"content":"Eelke Folmer , Tony Morelli, Spatial gestures using a tactile-proprioceptive display, Proceedings of the Sixth International Conference on Tangible, Embedded and Embodied Interaction, February 19-22, 2012, Kingston, Ontario, Canada","paperID":"2148161"},{"content":"Fuentes, C. T., Bastian, A. J. Where is your arm? Variations in proprioception across space and tasks. Journal of Neurophysiology 103, 1 (2010), 164--171.","paperID":"None"},{"content":"Gibson, J. J. Observations on active touch. Psychological Review 69, 6, (1962), 477--491.","paperID":"None"},{"content":"Goldstein, M. and Chincholle, D. Finger-joint gesture wearable keypad. In Proc. MobileHCI, (1999), 9--18.","paperID":"None"},{"content":"Ulrike Gollner , Tom Bieling , Gesche Joost, Mobile Lorm Glove: introducing a communication device for deaf-blind people, Proceedings of the Sixth International Conference on Tangible, Embedded and Embodied Interaction, February 19-22, 2012, Kingston, Ontario, Canada","paperID":"2148159"},{"content":"Sean Gustafson , Daniel Bierwirth , Patrick Baudisch, Imaginary interfaces: spatial interaction with empty hands and without visual feedback, Proceedings of the 23nd annual ACM symposium on User interface software and technology, October 03-06, 2010, New York, New York, USA","paperID":"1866033"},{"content":"Sean Gustafson , Christian Holz , Patrick Baudisch, Imaginary phone: learning imaginary interfaces by transferring spatial memory from a familiar device, Proceedings of the 24th annual ACM symposium on User interface software and technology, October 16-19, 2011, Santa Barbara, California, USA","paperID":"2047233"},{"content":"Chris Harrison , Hrvoje Benko , Andrew D. Wilson, OmniTouch: wearable multitouch interaction everywhere, Proceedings of the 24th annual ACM symposium on User interface software and technology, October 16-19, 2011, Santa Barbara, California, USA","paperID":"2047255"},{"content":"Chris Harrison , Desney Tan , Dan Morris, Skinput: appropriating the body as an input surface, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 10-15, 2010, Atlanta, Georgia, USA","paperID":"1753394"},{"content":"Shaun K. Kane , Jeffrey P. Bigham , Jacob O. Wobbrock, Slide rule: making mobile touch screens accessible to blind people using multi-touch interaction techniques, Proceedings of the 10th international ACM SIGACCESS conference on Computers and accessibility, October 13-15, 2008, Halifax, Nova Scotia, Canada","paperID":"1414487"},{"content":"Shaun K. Kane , Chandrika Jayant , Jacob O. Wobbrock , Richard E. Ladner, Freedom to roam: a study of mobile device adoption and accessibility for people with visual and motor disabilities, Proceedings of the 11th international ACM SIGACCESS conference on Computers and accessibility, October 25-28, 2009, Pittsburgh, Pennsylvania, USA","paperID":"1639663"},{"content":"Falko Kuester , Michelle Chen , Mark E. Phair , Carsten Mehring, Towards keyboard independent touch typing in VR, Proceedings of the ACM symposium on Virtual reality software and technology, November 07-09, 2005, Monterey, CA, USA","paperID":"1101635"},{"content":"Landua, S. and Wells, L. Merging tactile sensory input and audio data by means of the Talking Tactile Tablet. In Proc. Eurohaptics, (2003), 414--418.","paperID":"None"},{"content":"Ladavas, E., Farne, A., Zeloni, G. and di Pellegrino, G. Seeing or not seeing where your hands are. Experimental Brain Research 31, (2000), 458--467.","paperID":"None"},{"content":"Kevin A. Li , Patrick Baudisch , Ken Hinckley, Blindsight: eyes-free access to mobile phones, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 05-10, 2008, Florence, Italy","paperID":"1357273"},{"content":"Frank Chun Yat Li , David Dearman , Khai N. Truong, Virtual shelves: interactions with orientation aware devices, Proceedings of the 22nd annual ACM symposium on User interface software and technology, October 04-07, 2009, Victoria, BC, Canada","paperID":"1622200"},{"content":"Frank Chun Yat Li , David Dearman , Khai N. Truong, Leveraging proprioception to make mobile phones more accessible to users with visual impairments, Proceedings of the 12th international ACM SIGACCESS conference on Computers and accessibility, October 25-27, 2010, Orlando, Florida, USA","paperID":"1878837"},{"content":"Shu-Yang Lin , Chao-Huai Su , Kai-Yin Cheng , Rong-Hao Liang , Tzu-Hao Kuo , Bing-Yu Chen, Pub - point upon body: exploring eyes-free interaction and methods on an arm, Proceedings of the 24th annual ACM symposium on User interface software and technology, October 16-19, 2011, Santa Barbara, California, USA","paperID":"2047259"},{"content":"Maravita, A., Spence, C., Driver, J. Multisensory integration and the body schema: close to hand and within reach. Current Biology 13, (July 2003), R531--R539.","paperID":"None"},{"content":"David McGookin , Stephen Brewster , WeiWei Jiang, Investigating touchscreen accessibility for people with visual impairments, Proceedings of the 5th Nordic conference on Human-computer interaction: building bridges, October 20-22, 2008, Lund, Sweden","paperID":"1463193"},{"content":"Pranav Mistry , Pattie Maes , Liyan Chang, WUW - wear Ur world: a wearable gestural interface, CHI '09 Extended Abstracts on Human Factors in Computing Systems, April 04-09, 2009, Boston, MA, USA","paperID":"1520626"},{"content":"Ian Oakley , Junseok Park, Motion marking menus: An eyes-free approach to motion input for handheld devices, International Journal of Human-Computer Studies, v.67 n.6, p.515-532, June, 2009","paperID":"1523967"},{"content":"Antti Pirhonen , Stephen Brewster , Christopher Holguin, Gestural and audio metaphors as a means of control for mobile devices, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 20-25, 2002, Minneapolis, Minnesota, USA","paperID":"503428"},{"content":"Garth Shoemaker , Takayuki Tsukitani , Yoshifumi Kitamura , Kellogg S. Booth, Body-centric interaction techniques for very large wall displays, Proceedings of the 6th Nordic Conference on Human-Computer Interaction: Extending Boundaries, October 16-20, 2010, Reykjavik, Iceland","paperID":"1868967"},{"content":"Steven Strachan , Roderick Murray-Smith , Sile O'Modhrain, BodySpace: inferring body pose for natural control of a music player, CHI '07 Extended Abstracts on Human Factors in Computing Systems, April 28-May 03, 2007, San Jose, CA, USA","paperID":"1240939"},{"content":"Emi Tamaki , Takashi Miyaki , Jun Rekimoto, Brainy hand: an ear-worn hand gesture interaction device, CHI '09 Extended Abstracts on Human Factors in Computing Systems, April 04-09, 2009, Boston, MA, USA","paperID":"1520649"},{"content":"Vallbo, A. B. and Johansson, R. S. The tactile sensory innervation of the glabrous skin of the human hand. Active Touch, the Mechanism of Recognition of Objects by Manipulation, (1978), 29--54.","paperID":"None"},{"content":"Vanderheiden, G. C. Use of audio-haptic interface techniques to allow nonvisual access to touchscreen appliances. In Proc. Human Factors and Ergonomics Society (Poster), (1996), 1266.","paperID":"None"},{"content":"Voisin, J., Lamarre, Y. and Chapman, C. E. Haptic discrimination of object shape in humans: contribution of cutaneous and proprioceptive inputs. Experimental Brain Research 145, 2 (2002), 251--260.","paperID":"None"},{"content":"Shengdong Zhao , Pierre Dragicevic , Mark Chignell , Ravin Balakrishnan , Patrick Baudisch, Earpod: eyes-free menu selection using touch input and reactive audio feedback, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 28-May 03, 2007, San Jose, California, USA","paperID":"1240836"}]}