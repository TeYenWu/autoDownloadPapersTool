{"paperId":2481301,"citation":[{"content":"Eytan Adar , Mira Dontcheva , Gierad Laput, CommandSpace: modeling the relationships between tasks, descriptions and features, Proceedings of the 27th annual ACM symposium on User interface software and technology, October 05-08, 2014, Honolulu, Hawaii, USA","paperID":"2647395"},{"content":"Yiming Liu , Michael Cohen , Matt Uyttendaele , Szymon Rusinkiewicz, AutoStyle: automatic style transfer from image collections to users' images, Proceedings of the 25th Eurographics Symposium on Rendering, June 25-27, 2014, Lyon, France","paperID":"2855540"}],"reference":[{"content":"Androutsopoulos, L. Natural language interfaces to databases - an introduction. Journal of Natural Language Engineering 1 (1995), 29--81.","paperID":"None"},{"content":"Apple. iPhoto. http://www.apple.com/ilife/iphoto/. Online; accessed Sept 18, 2012.","paperID":"None"},{"content":"Apple. Siri. http://www.apple.com/ios/siri/. Online; accessed Sept 18, 2012.","paperID":"None"},{"content":"Satanjeev Banerjee , Ted Pedersen, An Adapted Lesk Algorithm for Word Sense Disambiguation Using WordNet, Proceedings of the Third International Conference on Computational Linguistics and Intelligent Text Processing, p.136-145, February 17-23, 2002","paperID":"724142"},{"content":"Richard A. Bolt, “Put-that-there”: Voice and gesture at the graphics interface, ACM SIGGRAPH Computer Graphics, v.14 n.3, p.262-270, July 1980","paperID":"807503"},{"content":"Eric Brill, Transformation-based error-driven learning and natural language processing: a case study in part-of-speech tagging, Computational Linguistics, v.21 n.4, p.543-565, December 1995","paperID":"218367"},{"content":"Jackie C. Chang , Annie Lien , Brian Lathrop , Holger Hees, Usability evaluation of a Volkswagen Group in-vehicle speech system, Proceedings of the 1st International Conference on Automotive User Interfaces and Interactive Vehicular Applications, September 21-22, 2009, Essen, Germany","paperID":"1620535"},{"content":"José Coelho , Carlos Duarte , Pradipta Biswas , Patrick Langdon, Developing accessible TV applications, The proceedings of the 13th international ACM SIGACCESS conference on Computers and accessibility, October 24-26, 2011, Dundee, Scotland, UK","paperID":"2049561"},{"content":"Natasha Gelfand , Andrew Adams , Sung Hee Park , Kari Pulli, Multi-exposure imaging on mobile devices, Proceedings of the international conference on Multimedia, October 25-29, 2010, Firenze, Italy","paperID":"1874088"},{"content":"Peter Gorniak , Deb Roy, Augmenting user interfaces with adaptive speech commands, Proceedings of the 5th international conference on Multimodal interfaces, November 05-07, 2003, Vancouver, British Columbia, Canada","paperID":"958467"},{"content":"A. G. Hauptmann, Speech and gestures for graphic image manipulation, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, p.241-245, March 1989","paperID":"67496"},{"content":"Patrick G. T. Healey , Rosemarie McCabe , Yasuhiro Katagiri, A Comparison of Graphics and Speech in a Task-Oriented Interactio, Proceedings of the First International Conference on Theory and Application of Diagrams, p.245-256, September 01-03, 2000","paperID":"675047"},{"content":"iSpeech. iSpeech. http://www.ispeech.org/api. Online; accessed Sept 18, 2012.","paperID":"None"},{"content":"Tessa Lau , Julian Cerruti , Guillermo Manzato , Mateo Bengualid , Jeffrey P. Bigham , Jeffrey Nichols, A conversational interface to web automation, Proceedings of the 23nd annual ACM symposium on User interface software and technology, October 03-06, 2010, New York, New York, USA","paperID":"1866067"},{"content":"Greg Little , Robert C. Miller, Translating keyword commands into executable code, Proceedings of the 19th annual ACM symposium on User interface software and technology, October 15-18, 2006, Montreux, Switzerland","paperID":"1166275"},{"content":"Mitchell P. Marcus , Mary Ann Marcinkiewicz , Beatrice Santorini, Building a large annotated corpus of English: the penn treebank, Computational Linguistics, v.19 n.2, June 1993","paperID":"972475"},{"content":"Robert C. Miller , Victoria H. Chou , Michael Bernstein , Greg Little , Max Van Kleek , David Karger , mc schraefel, Inky: a sloppy command line for the web with rich visual feedback, Proceedings of the 21st annual ACM symposium on User interface software and technology, October 19-22, 2008, Monterey, CA, USA","paperID":"1449737"},{"content":"André D. Milota, Modality fusion for graphic design applications, Proceedings of the 6th international conference on Multimodal interfaces, October 13-15, 2004, State College, PA, USA","paperID":"1027963"},{"content":"Nuance Communications. Dragon. http://www.nuance.com/dragon/index.htm. Online; accessed Sept 18, 2012.","paperID":"None"},{"content":"Sharon Oviatt, Multimodal interactive maps: designing for human performance, Human-Computer Interaction, v.12 n.1, p.93-129, March 1997","paperID":"1462973"},{"content":"Pajari, M. Color mark up terminology. Tech. rep., Widen Enterprises Inc., 2009.","paperID":"None"},{"content":"Siddharth Patwardhan , Satanjeev Banerjee , Ted Pedersen, Using measures of semantic relatedness for word sense disambiguation, Proceedings of the 4th international conference on Computational linguistics and intelligent text processing, February 16-22, 2003, Mexico City, Mexico","paperID":"1791592"},{"content":"Pausch, R., and Leatherby, J. H. An empirical study: Adding voice input to a graphical editor. J. of the American Voice Input/Output Society 9 (1991), 2--55.","paperID":"None"},{"content":"Politepix. OpenEars: speech recognition and speech synthesis for the iPhone. http://www.politepix.com/openears/. Online; accessed Sept 18, 2012.","paperID":"None"},{"content":"Riley, E. How to talk to a retoucher, 2012.","paperID":"None"},{"content":"Tariq Samad , Stephen W. Director, Towards a natural language interface for CAD, Proceedings of the 22nd ACM/IEEE Design Automation Conference, p.2-8, June 1985, Las Vegas, Nevada, USA","paperID":"317826"},{"content":"Jana Sedivy , Hilary Johnson, Supporting creative work tasks: the potential of multimodal tools to support sketching, Proceedings of the 3rd conference on Creativity & cognition, p.42-49, October 11-13, 1999, Loughborough, United Kingdom","paperID":"317571"},{"content":"Woolfe, G. Making color adjustment accessible to non-experts through the use of language. In Proc. of IS&T 15th Color Imaging Conference (2007).","paperID":"None"},{"content":"Xiong, Y., and Pulli, K. Gradient domain image blending and implementation on mobile devices. In Mobile Computing, Applications, and Services. Springer Berlin Heidelberg, 2010, 293--306.","paperID":"None"},{"content":"Zhao, Y., Bala, R., Braun, K. M., Langford, Z., Rolleston, R. J., and Stevens, M. T. Language-based color editing for mobile device. In Proc. of the SPIE, Volume 7879 (2011).","paperID":"None"}],"abstract":"Photo editing can be a challenging task, and it becomes even more difficult on the small, portable screens of mobile devices that are now frequently used to capture and edit images. To address this problem we present PixelTone, a multimodal photo editing interface that combines speech and direct manipulation. We observe existing image editing practices and derive a set of principles that guide our design. In particular, we use natural language for expressing desired changes to an image, and sketching to localize these changes to specific regions. To support the language commonly used in photo-editing we develop a customized natural language interpreter that maps user phrases to specific image processing operations. Finally, we perform a user study that evaluates and demonstrates the effectiveness of our interface.","video":"http://www.youtube.com/embed/JH_6tHFwF64?rel=0","title":"PixelTone: a multimodal interface for image editing","filename":"CHI13/p2185","authors":["Gierad P. Laput","Mira Dontcheva","Gregg Wilensky","Walter Chang","Aseem Agarwala","Jason Linder","Eytan Adar"],"conference":"CHI '13"}