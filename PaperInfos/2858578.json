{"paperId":2858578,"citation":[],"reference":[{"content":"Luis von Ahn, Benjamin Maurer, Colin McMillen, David Abraham, and Manuel Blum. 2008. reCAPTCHA: human-based character recognition via Web security measures. Science (New York, N.Y.) 321: 1465-1468. http://doi.org/10.1126/science.1160379","paperID":"None"},{"content":"Aaron Bangor, Philip Kortum, and James Miller. 2009. Determining what individual SUS scores mean: Adding an adjective rating scale. Journal of usability studies 4, 3: 114-123.","paperID":"None"},{"content":"Kenan Bektas, Arzu Cöltekin, Jens Krüger, and Andrew T Duchowski. 2015. A Testbed Combining Visual Perception Models for Geographic Gaze Contingent Displays. https://diglib.eg.org/handle/10.2312/eurovisshort.2 0151127.067-071.","paperID":"None"},{"content":"Manuel Berning, Kevin M. Boergens, and Moritz Helmstaedter. 2015. SegEM: Efficient Image Analysis for High-Resolution Connectomics. Neuron 87, 6: 1193-1206. http://doi.org/10.1016/j.neuron.2015.09.003","paperID":"None"},{"content":"Davi D Bock, Wei-Chung Allen Lee, Aaron M Kerlin, et al. 2011. Network anatomy and in vivo physiology of visual cortical neurons. Nature 471, 7337: 177-182. http://doi.org/10.1038/nature09802","paperID":"None"},{"content":"Kevin L Briggman, Moritz Helmstaedter, and Winfried Denk. 2011. Wiring specificity in the direction-selectivity circuit of the retina. Nature 471, 7337: 183-188. Retrieved from http://dx.doi.org/10.1038/nature09818","paperID":"None"},{"content":"John Brooke. 1996. SUS-A quick and dirty usability scale. Usability evaluation in industry 189: 194.","paperID":"None"},{"content":"Daniel J Bumbarger, Metta Riebesell, Christian Rödelsperger, and Ralf J Sommer. 2013. Systemwide rewiring underlies behavioral differences in predatory and bacterial-feeding nematodes. Cell 152, 1--2: 109-19. http://doi.org/10.1016/j.cell.2012.12.013","paperID":"None"},{"content":"Randal Burns, William Gray Roncal, Dean Kleissas, et al. 2013. The Open Connectome Project Data Cluster: Scalable Analysis and Vision for High-Throughput Neuroscience. International Conference on Scientific and Statistical Database Management: 1-11. http://doi.org/10.1145/2484838.2484870","paperID":"None"},{"content":"Corrado Calì, Jumana Baghabra, Daniya J Boges, et al. 2015. Three-dimensional immersive virtual reality for studying cellular compartments in 3D models from EM preparations of neural tissues. Journal of Comparative Neurology: n/a-n/a. http://doi.org/10.1002/cne.23852","paperID":"None"},{"content":"K R Cave and N P Bichot. 1999. Visuospatial attention: beyond a spotlight model. Psychonomic bulletin & review 6, 2: 204-223.","paperID":"None"},{"content":"Eyewire. 2014. Reconstructing a Neuron in 3D. Retrieved from https://www.youtube.com/watch?v=noDx7TmMr8 Q","paperID":"None"},{"content":"Ribel Fares, Shaomin Fang, and Oleg Komogortsev. 2013. Can we beat the mouse with MAGIC? Proceedings of the SIGCHI Conference on Human Factors in Computing Systems CHI '13: 1387. http://doi.org/10.1145/2470654.2466183","paperID":"None"},{"content":"P M Fitts. 1992. The information capacity of the human motor system in controlling the amplitude of movement. 1954. Journal of experimental psychology. General 121, 3: 262-269.","paperID":"None"},{"content":"Jan Funke, Bjoern Andres, Fred a. Hamprecht, Albert Cardona, and Matthew Cook. 2012. Efficient automatic 3D-reconstruction of branching neurons from em data. Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition: 1004-1011. http://doi.org/10.1109/CVPR.2012.6247777","paperID":"None"},{"content":"Jan Funke, Björn Andres, Fred Hamprecht, Albert Cardona, and Matthew Cook. 2011. MultiHypothesis CRF-Segmentation of Neural Tissue in Anisotropic EM Volumes. i: 1-8. Retrieved from http://arxiv.org/abs/1109.2449","paperID":"None"},{"content":"Jan Funke, Julien N P Martel, Stephan Gerhard, and Bjoern Andres. 2014. Candidate Sampling for Neuron Reconstruction from Anisotropic Electron Microscopy Volumes. MICCAI Supplement, 1: 0-5. http://doi.org/10.1007/978--3--319--10404--1_3","paperID":"None"},{"content":"Wilson S Geisler and Lawrence K Cormack. 2011. Models of overt attention. In The Oxford handbook of eye movements. 439-454. http://doi.org/10.1093/oxfordhb/9780199539789.01 3.0024","paperID":"None"},{"content":"Daniel Haehn, Seymour Knowles-barley, Mike Roberts, et al. 2014. Design and Evaluation of Interactive Proofreading Tools for Connectomics. http://doi.org/10.1109/TVCG.2014.2346371","paperID":"None"},{"content":"Moritz Helmstaedter, Kevin L Briggman, and Winfried Denk. 2011. High-accuracy neurite reconstruction for high-throughput neuroanatomy. Nature neuroscience 14, 8: 1081-1088. http://doi.org/10.1038/nn.2868","paperID":"None"},{"content":"Moritz Helmstaedter, Kevin L Briggman, and Winfried Denk. 2011. High-accuracy neurite reconstruction for high-throughput neuroanatomy. Nat Neurosci 14, 8: 1081-1088. http://doi.org/10.1038/nn.2868","paperID":"None"},{"content":"Moritz Helmstaedter, Kevin L Briggman, Srinivas C Turaga, Viren Jain, H Sebastian Seung, and Winfried Denk. 2013. Connectomic reconstruction of the inner plexiform layer in the mouse retina. Nature 500, 7461: 168-74. http://doi.org/10.1038/nature12346","paperID":"None"},{"content":"Moritz Helmstaedter and Partha P Mitra. 2012. Computational methods and challenges for largescale circuit mapping. Curr Opin Neurobiol 22, 1: 162-169. http://doi.org/10.1016/j.conb.2011.11.010","paperID":"None"},{"content":"V Jain, J F Murray, F Roth, et al. 2007. Supervised Learning of Image Restoration with Convolutional Networks. Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on, 1-8. http://doi.org/10.1109/ICCV.2007.4408909","paperID":"None"},{"content":"Viren Jain, H Sebastian Seung, and Srinivas C Turaga. 2010. Machines that learn to segment images: a crucial technology for connectomics. Curr Opin Neurobiol 20, 5: 653-666. http://doi.org/10.1016/j.conb.2010.07.004","paperID":"None"},{"content":"Narayanan Kasthuri, Kenneth Jeffrey Hayworth, Daniel Raimund Berger, et al. 2015. Saturated Reconstruction of a Volume of Neocortex. Cell 162: 648-661. http://doi.org/10.1016/j.cell.2015.06.054","paperID":"None"},{"content":"Jinseop S. Kim, Matthew J. Greene, Aleksandar Zlateski, et al. 2014. Space-time wiring specificity supports direction selectivity in the retina. Nature, 4. http://doi.org/10.1038/nature13240","paperID":"None"},{"content":"Manu Kumar, Andreas Paepcke, and Terry Winograd. 2007. EyePoint: practical pointing and selection using gaze and keyboard. Proceedings of the SIGCHI conference on Human factors in computing systems, 430. http://doi.org/10.1145/1240624.1240692","paperID":"None"},{"content":"Jeff William Lichtman. 2014. Brain Connectomics? Retrieved from https://www.youtube.com/watch?v=2QVy0n_rdBI","paperID":"None"},{"content":"Julio C Mateo. 2008. Gaze Beats Mouse?: Handsfree Selection by Combining Gaze and EMG. Chi Ea: 3039-3044. http://doi.org/10.1145/1358628.1358804","paperID":"None"},{"content":"Atsuo Murata. 2006. Eye-Gaze Input Versus Mouse: Cursor Control as a Function of Age. International Journal of Human-Computer Interaction 21, 1: 1-14. http://doi.org/10.1207/s15327590ijhc2101_1","paperID":"None"},{"content":"Marta Pallotto, Paul V Watkins, Boma Fubara, Joshua H Singer, and Kevin L Briggman. 2015. Extracellular space preservation aids the connectomic analysis of neural circuits. eLife. http://doi.org/10.7554/eLife.08206","paperID":"None"},{"content":"Stephen M Plaza, Louis K Scheffer, and Dmitri B Chklovskii. 2014. Toward large-scale connectome reconstructions. Current opinion in neurobiology 25C: 201-210. http://doi.org/10.1016/j.conb.2014.01.019","paperID":"None"},{"content":"M I Posner, C R Snyder, and B J Davidson. 1980. Attention and the detection of signals. Journal of experimental psychology 109, 2: 160-174.","paperID":"None"},{"content":"H S Raffle, A Wong, and R Geiss. 2012. Unlocking a screen using eye tracking information.","paperID":"None"},{"content":"Stephan Saalfeld, Albert Cardona, Volker Hartenstein, and Pavel Tomančák. 2009. CATMAID: Collaborative annotation toolkit for massive amounts of image data. Bioinformatics 25, 15: 1984-1986. http://doi.org/10.1093/bioinformatics/btp266","paperID":"None"},{"content":"M. Sadeghi, G. Tien, G. Hamarneh, and Ms Atkins. 2009. Hands-free interactive image segmentation using eyegaze. Proc. of SPIE Vol 7260: 72601H-1. http://doi.org/10.1117/12.813452","paperID":"None"},{"content":"Johannes Schindelin, Ignacio Arganda-Carreras, Erwin Frise, et al. 2012. Fiji: an open-source platform for biological-image analysis. Nature Methods 9, 7: 676-682. http://doi.org/10.1038/nmeth.2019","paperID":"None"},{"content":"Linda E. Sibert and Robert J. K. Jacob. 2000. Evaluation of eye gaze interaction. Proc. CHI 2, 1: 281-288. http://doi.org/10.1145/332040.332445","paperID":"None"},{"content":"Sophie Stellmach and Raimund Dachselt. 2012. Look & Touch : Gaze-supported Target Acquisition. 2981-2990. http://doi.org/10.1145/2207676.2208709","paperID":"None"},{"content":"Sophie Stellmach, Sebastian Stober, Andreas Nürnberger, and Raimund Dachselt. 2011. Designing gaze-supported multimodal interactions for the exploration of large image collections. Proceedings of the 1st Conference on Novel Gaze-Controlled Applications - NGCA '11: 1-8. http://doi.org/10.1145/1983302.1983303","paperID":"None"},{"content":"Shin-ya Takemura, Arjun Bharioke, Zhiyuan Lu, et al. 2013. A visual motion detection circuit suggested by Drosophila connectomics. Nature 500, 7461: 175-181. Retrieved from http://dx.doi.org/10.1038/nature12450","paperID":"None"},{"content":"Shin-ya Takemura, Arjun Bharioke, Zhiyuan Lu, et al. 2013. A visual motion detection circuit suggested by Drosophila connectomics. Nature 500, 7461: 175-81. http://doi.org/10.1038/nature12450","paperID":"None"},{"content":"Srinivas C Turaga, Joseph F Murray, Viren Jain, et al. 2010. Convolutional networks can learn to generate affinity graphs for image segmentation. Neural Comput. 22, 2: 511-538. http://doi.org/http://dx.doi.org/10.1162/neco.2009.1 0-08--881","paperID":"None"},{"content":"Shumin Zhai, Carlos Morimoto, and Steven Ihde. 1999. Manual and gaze input cascaded (MAGIC) pointing. Proceedings of the SIGCHI conference on Human factors in computing systems the CHI is the limit CHI 99: 246-253. http://doi.org/10.1145/302979.303053","paperID":"None"},{"content":"Eyewire A Game To Map The Brain. Retrieved from https://eyewire.org","paperID":"None"}],"abstract":"We introduce an image annotation approach for the analysis of volumetric electron microscopic imagery of brain tissue. The core task is to identify and link tubular objects (neuronal fibers) in images taken from consecutive ultrathin sections of brain tissue. In our approach an individual 'flies' through the 3D data at a high speed and maintains eye gaze focus on a single neuronal fiber, aided by navigation with a handheld gamepad controller. The continuous foveation on a fiber of interest constitutes an intuitive means to define a trace that is seamlessly recorded with a desktop eyetracker and transformed into precise 3D coordinates of the annotated fiber (skeleton tracing). In a participant experiment we validate the approach by demonstrating a tracing accuracy of about the respective radiuses of the traced fibers with browsing speeds of up to 40 brain sections per second.","title":"Eye-Trace: Segmentation of Volumetric Microscopy Images with Eyegaze","filename":"CHI16/p5812","authors":["Thomas Templier","Kenan Bektas","Richard H.R. Hahnloser"],"conference":"CHI '16"}