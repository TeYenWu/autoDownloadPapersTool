{"paperId":2858137,"citation":[],"reference":[{"content":"Aubert, O., Prié, Y., and Canellas, C. Leveraging video annotations in video-based e-learning. In International Conference on Computer Supported Education (2014).","paperID":"None"},{"content":"Bargeron, D., Grudin, J., Gupta, A., Sanocki, E., Li, F., and Leetiernan, S. Asynchronous Collaboration Around Multimedia Applied to On-Demand Education. Journal of Management Information Systems (2002), 117--145.","paperID":"None"},{"content":"Bassili, J., and Joordens, S. Media Player Tool Use, Satisfaction with Online Lectures and Examination Performance. Journal of Distance Education (2008), 93--108.","paperID":"None"},{"content":"Bauer, A., and Koedinger, K. R. Selection-based note-taking applications. In ACM CHI (2007), 981.","paperID":"None"},{"content":"Cheng, S., Sun, Z., Sun, L., Yee, K., and Dey, A. K. Gaze-Based Annotations for Reading Comprehension. In ACM CHI (2015), 1569--1572.","paperID":"None"},{"content":"Denoue, L., Carter, S., Cooper, M., and Adcock, J. Real-time direct manipulation of screen-based videos. In International conference on Intelligent user interfaces companion, ACM Press (New York, New York, USA, 2013), 43.","paperID":"None"},{"content":"D'Mello, S., Olney, A., Williams, C., and Hays, P. Gaze tutor: A gaze-reactive intelligent tutoring system. International Journal of Human-Computer Studies (2012), 377--398.","paperID":"None"},{"content":"Gašević, D., Mirriahi, N., and Dawson, S. Analytics of the effects of video use and instruction to support reflective learning. In International Conference on Learning Analytics And Knowledge (2014), 123--132.","paperID":"None"},{"content":"Gigonzac, G., Pitie, F., and Kokaram, A. Electronic slide matching and enhancement of a lecture video. In European Conference on Visual Media Production (2007), 9--9.","paperID":"None"},{"content":"Gog, T., and Scheiter, K. Eye tracking as a tool to study and enhance multimedia learning. Learning and Instruction (2010), 95--99.","paperID":"None"},{"content":"Guo, P., Kim, J., and Rubin, R. How video production affects student engagement: An empirical study of mooc videos. In Learning @ scale (2014), 41--50.","paperID":"None"},{"content":"Hosack, B. VideoANT: Extending Online Video Annotation beyond Content Delivery. TechTrends (2010), 45--49.","paperID":"None"},{"content":"Hyrskykari, A., Majaranta, P., and K.J., R. Proactive response to eye movements. In INTERACT (2003), 129.","paperID":"None"},{"content":"Kern, D., Marshall, P., and Schmidt, A. Gazemarks: gaze-based visual placeholders to ease attention switching. In ACM CHI (2010), 2093--2102.","paperID":"None"},{"content":"Kiewra, K., Benton, S., Kim, S.-I., Risch, N., and Christensen, M. Effects of Note-Taking Format and Study Technique on Recall and Relational Performance. Contemporary Educational Psychology (1995), 172--187.","paperID":"None"},{"content":"Lai, M.-L., Tsai, M.-J., Yang, F.-Y., Hsu, C.-Y., Liu, T.-C., Lee, S. W.-Y., Lee, M.-H., Chiou, G.-L., Liang, J.-C., and Tsai, C.-C. A review of using eye-tracking technology in exploring learning from 2000 to 2012. Educational Research Review (2013), 90--115.","paperID":"None"},{"content":"Lee, Y.-c., Lin, W.-c., Cherng, F.-y., Wang, H.-c., Sung, C.-y., and King, J.-t. Using Time-Anchored Peer Comments to Enhance Social Interaction in Online Educational Videos. In ACM CHI (2015), 689--698.","paperID":"None"},{"content":"Marshall, C. C. Annotation: from paper books to the digital library. In ACM ICDL (1997), 131--140.","paperID":"None"},{"content":"Mu, X. Towards effective video annotation: An approach to automatically link notes with video content. Computers and Education (2010), 1752--1763.","paperID":"None"},{"content":"Park, M., Kang, J., Park, S., and Cho, K. A Natural User Interface for E-learning Learners : Focused on the Automatic Speed Control of Multimedia Materials. International Journal of Multimedia & Ubiquitous Engineering (2014), 347--358.","paperID":"None"},{"content":"Piolat, A., and Boch, F. Note Taking and Learning : A Summary of Research. The WAC Journal (2005), 101--113.","paperID":"None"},{"content":"Piolat, A., Olive, T., and Kellogg, R. T. Cognitive effort during note taking. Applied Cognitive Psychology (2005), 291--312.","paperID":"None"},{"content":"Pongnumkul, S., Dontcheva, M., Li, W., and Wang, J. Pause-and-play: automatically linking screencast video tutorials with applications. In ACM UIST (2011).","paperID":"None"},{"content":"Porta, M. Implementing eye-based user-aware e-learning. In Extended Abstracts on Human Factors in Computing Systems (2008), 3087--3092.","paperID":"None"},{"content":"Rayner, K. Eye movements and attention in reading, scene perception, and visual search. Quarterly journal of experimental psychology (2009), 1457--1506.","paperID":"None"},{"content":"Risko, E. F., Foulsham, T., Dawson, S., and Kingstone, A. The Collaborative Lecture Annotation System (CLAS): A New TOOL for Distributed Learning. IEEE Transactions on Learning Technologies (2013), 4--13.","paperID":"None"},{"content":"Salvucci, D., and Goldberg, J. Identifying Fixations and Saccades in Eye-Tracking Protocols. In ACM ETRA (2000), 71--78.","paperID":"None"},{"content":"Sharma, K., Jermann, P., and Dillenbourg, P. How Students Learn using MOOCs: An Eye-tracking Insight. In MOOC European Stakeholders Summit (2014), 147--154.","paperID":"None"},{"content":"Slykhuis, D., Wiebe, E., and Annetta, L. Eye-tracking students' attention to powerpoint photographs in a science education setting. Journal of Science Education and Technology 14, 5--6 (2005), 509--520.","paperID":"None"},{"content":"Song, S., Hong, J.-k., Oakley, I., Cho, J.-d., and Bianchi, A. Automatically Adjusting the Speed of E-Learning Videos. In Extended Abstracts on Human Factors in Computing Systems (2015), 1451--1456.","paperID":"None"}],"abstract":"Taking notes has been shown helpful for learning. This activity, however, is not well supported when learning from watching lecture videos. The conventional video interface does not allow users to quickly locate and annotate important content in the video as notes. Moreover, users sometimes need to manually pause the video while taking notes, which is often distracting. In this paper, we develop a gaze-based system to assist a user in notetaking while watching lecture videos. Our system has two features to support notetaking. First, our system integrates offline video analysis and online gaze analysis to automatically detect and highlight key content from the lecture video for notetaking. Second, our system provides adaptive video control that automatically reduces the video playback speed or pauses it while a user is taking notes to minimize the user's effort in controlling video. Our study shows that our system enables users to take notes more easily and with better quality than the traditional video interface.","title":"Gaze-based Notetaking for Learning from Lecture Videos","filename":"CHI16/p2093","authors":["Cuong Nguyen","Feng Liu"],"conference":"CHI '16"}