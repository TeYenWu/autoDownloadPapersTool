{"paperId":2557320,"citation":[{"content":"Mhd Yamen Saraiji , Charith Lasantha Fernando , Kouta Minamizawa , Susumu Tachi, Development of mutual telexistence system using virtual projection of operator's egocentric body images, Proceedings of the 25th International Conference on Artificial Reality and Telexistence and 20th Eurographics Symposium on Virtual Environments, p.125-132, October 28-30, 2015, Kyoto, Japan","paperID":"2852330"},{"content":"Ikkaku Kawaguchik , Hideaki Kuzuoka , Yusuke Suzuki, Study on Gaze Direction Perception of Face Image Displayed on Rotatable Flat Display, Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, April 18-23, 2015, Seoul, Republic of Korea","paperID":"2702369"},{"content":"Ye Pan , Anthony Steed, Effects of 3D perspective on head gaze estimation with a multiview autostereoscopic display, International Journal of Human-Computer Studies, v.86 n.C, p.138-148, February 2016","paperID":"2870213"},{"content":"Ye Pan , Oyewole Oyekoya , Anthony Steed, A surround video capture and presentation system for preservation of eye-gaze in teleconferencing applications, Presence: Teleoperators and Virtual Environments, v.24 n.1, p.24-43, Winter 2015","paperID":"2812372"}],"reference":[{"content":"Anstis, S. M., Mayhew, J. W., and Morley, T. The perception of where a face or television portrait is looking. The American journal of psychology (1969).","paperID":"None"},{"content":"Kibum Kim , John Bolton , Audrey Girouard , Jeremy Cooperstock , Roel Vertegaal, TeleHuman: effects of 3d perspective on gaze and pose estimation with a life-size cylindrical telepresence pod, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 05-10, 2012, Austin, Texas, USA","paperID":"2208640"},{"content":"Peter Lincoln , Greg Welch , Andrew Nashel , Andrei State , Adrian Ilie , Henry Fuchs, Animatronic shader lamps avatars, Virtual Reality, v.15 n.2-3, p.225-238, June 2011","paperID":"2003447"},{"content":"David Nguyen , John Canny, MultiView: spatially faithful group video conferencing, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 02-07, 2005, Portland, Oregon, USA","paperID":"1055084"},{"content":"Ken-Ichi Okada , Fumihiko Maeda , Yusuke Ichikawaa , Yutaka Matsushita, Multiparty videoconferencing at virtual social distance: MAJIC design, Proceedings of the 1994 ACM conference on Computer supported cooperative work, p.385-393, October 22-26, 1994, Chapel Hill, North Carolina, USA","paperID":"193054"},{"content":"Oyewole Oyekoya , William Steptoe , Anthony Steed, SphereAvatar: a situated display to represent a remote collaborator, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 05-10, 2012, Austin, Texas, USA","paperID":"2208642"},{"content":"Pan, Y., and Steed, A. Preserving gaze direction in teleconferencing using a camera array and a spherical display. In 3DTV-CON, IEEE (2012), 1--4.","paperID":"None"},{"content":"Simon Prince , Adrian David Cheok , Farzam Farbiz , Todd Williamson , Nik Johnson , Mark Billinghurst , Hirokazu Kato, 3-D live: real time interaction for mixed reality, Proceedings of the 2002 ACM conference on Computer supported cooperative work, November 16-20, 2002, New Orleans, Louisiana, USA","paperID":"587129"},{"content":"Schreer, O., Kauff, P., and Sikora, T. 3D videocommunication. Wiley Online Library, 2005.","paperID":"None"},{"content":"Abigail Sellen , Bill Buxton , John Arnott, Using spatial cues to improve videoconferencing, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, p.651-652, May 03-07, 1992, Monterey, California, USA","paperID":"143070"},{"content":"Roel Vertegaal , Ivo Weevers , Changuk Sohn , Chris Cheung, GAZE-2: conveying eye contact in group video conferencing using eye-controlled camera direction, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 05-10, 2003, Ft. Lauderdale, Florida, USA","paperID":"642702"}],"abstract":"Gaze, attention, and eye contact are important aspects of face to face communication, but some subtleties can be lost in videoconferencing because participants look at a single planar image of the remote user. We propose a low-cost cylindrical videoconferencing system that preserves gaze direction by providing perspective-correct images for multiple viewpoints around a conference table. We accomplish this by using an array of cameras to capture a remote person, and an array of projectors to present the camera images onto a cylindrical screen. The cylindrical screen reflects each image to a narrow viewing zone. The use of such a situated display allows participants to see the remote person from multiple viewing directions. We compare our system to three alternative display configurations. We demonstrate the effectiveness of our system by showing it allows multiple participants to simultaneously tell where the remote person is placing their gaze.","video":"http://www.youtube.com/embed/-dS2AagWErw?rel=0","title":"A gaze-preserving situated multiview telepresence system","filename":"CHI14/p2173","authors":["Ye Pan","Anthony Steed"],"conference":"CHI '14"}