{"paperId":2702159,"citation":[],"abstract":"Mobile audio augmented reality systems (MAARS) provide a new and engaging modality to present information or to create playful experiences. Using special filters, spatial audio rendering creates the impression that the sound of a virtual source emanates from a certain position in the physical space. So far, most of the implementations of such systems rely on head tracking to create a realistic effect, which requires additional hardware. Recent results indicate that the built-in sensors of a smartphone can be used as source for orientation measurement, reducing deployment to a simple app download. AudioScope presents an alternative interaction technique to create such an experience, using the metaphor of pointing a directional microphone at the environment. In an experiment with 20 users, we compared the time to locate a proximate audio source and the perceived presence in the virtual environment. Results show that there is no significant difference between head-orientation measurement and AudioScope regarding accuracy and perceived presence. This means that MAARS, such as audio guides for museums, do not require special hardware but can run on the visitor's smartphones with standard headphones.","reference":[{"content":"Begault, D. R., Wenzel, E. M., and Anderson, M. R. Direct Comparison of the Impact of Head Tracking, Reverberation, and Individualized Head-Related Transfer Functions on the Spatial Perception of a Virtual Speech Source. J. Audio Eng. Soc (2001).","paperID":"None"},{"content":"Begault, D. R., Wenzel, E. M., Godfroy, M., Miller, J. D., and Anderson, M. R. Applying Spatial Audio to Human Interfaces: 25 Years of NASA Experience. In AES Conference 40 (2010).","paperID":"None"},{"content":"Billinghurst, M., deo, S., Adams, N., and Lehikoinen, J. Motion-Tracking in Spatial Mobile Audio-Conferencing. In MobileHCI '07 (2007).","paperID":"None"},{"content":"Brungart, D. S., Simpson, B. D., and Kordik, A. J. The detectability of headtracker latency in virtual audio displays. In ICAD '05.","paperID":"None"},{"content":"Christina Dicke , Shaleen Deo , Mark Billinghurst , Nathan Adams , Juha Lehikoinen, Experiments in mobile spatial audio-conferencing: key-based and gesture-based interaction, Proceedings of the 10th international conference on Human computer interaction with mobile devices and services, September 02-05, 2008, Amsterdam, The Netherlands","paperID":"1409251"},{"content":"Florian Heller , Aaron Krämer , Jan Borchers, Simplifying orientation measurement for mobile audio augmented reality applications, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 26-May 01, 2014, Toronto, Ontario, Canada","paperID":"2557021"},{"content":"Kajastila, R., and Lokki, T. Eyes-free methods for accessing large auditory menus. In ICAD '10.","paperID":"None"},{"content":"Loomis, J. M., Hebert, C., and Cicinelli, J. G. Active localization of virtual sounds. The Journal of the Acoustical Society of America (1990).","paperID":"None"},{"content":"Georgios N. Marentakis , Stephen A. Brewster, Effects of feedback, mobility and index of difficulty on deictic spatial audio target acquisition in the horizontal plane, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 22-27, 2006, Montréal, Québec, Canada","paperID":"1124826"},{"content":"Nicholas Mariette, Navigation performance effects of render method and head-turn latency in mobile audio augmented reality, Proceedings of the 6th international conference on Auditory Display, May 18-22, 2009, Copenhagen, Denmark","paperID":"2174874"},{"content":"Middlebrooks, J. C. Virtual localization improved by scaling nonindividualized external-ear transfer functions in frequency. The Journal of the Acoustical Society of America (1999).","paperID":"None"},{"content":"Sander, C., Wefers, F., and Leckschat, D. Scalable Binaural Synthesis on Mobile Devices. In AES Convention 133 (2012).","paperID":"None"},{"content":"Christoph Stahl, The roaring navigator: a group guide for the zoo with shared auditory landmark display, Proceedings of the 9th international conference on Human computer interaction with mobile devices and services, p.383-386, September 09-12, 2007, Singapore","paperID":"1378042"},{"content":"Titus J. J. Tang , Wai Ho Li, An assistive EyeWear prototype that interactively converts 3D object locations into spatial audio, Proceedings of the 2014 ACM International Symposium on Wearable Computers, September 13-17, 2014, Seattle, Washington","paperID":"2634318"},{"content":"Lucia Terrenghi , Andreas Zimmermann, Tailored audio augmented environments for museums, Proceedings of the 9th international conference on Intelligent user interfaces, January 13-16, 2004, Funchal, Madeira, Portugal","paperID":"964523"},{"content":"Yolanda Vazquez-Alvarez , Ian Oakley , Stephen A. Brewster, Auditory display design for exploration in mobile audio-augmented reality, Personal and Ubiquitous Computing, v.16 n.8, p.987-999, December  2012","paperID":"2423805"},{"content":"Wenzel, E. M., Arruda, M., Kistler, D. J., and Wightman, F. L. Localization using nonindividualized head-related transfer functions. The Journal of the Acoustical Society of America (1993).","paperID":"None"},{"content":"Bob G. Witmer , Michael J. Singer, Measuring Presence in Virtual Environments: A Presence Questionnaire, Presence: Teleoperators and Virtual Environments, v.7 n.3, p.225-240, June 1998","paperID":"1246762"}],"title":"AudioScope: Smartphones as Directional Microphones in Mobile Audio Augmented Reality Systems","filename":"CHI15/p949","authors":["Florian Heller","Jan Borchers"],"conference":"CHI '15"}