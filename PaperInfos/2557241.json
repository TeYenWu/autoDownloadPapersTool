{"paperId":2557241,"citation":[{"content":"Juho Kim , Eun-Young Ko , Jonghyuk Jung , Chang Won Lee , Nam Wook Kim , Jihee Kim, Factful: Engaging Taxpayers in the Public Discussion of a Government Budget, Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, April 18-23, 2015, Seoul, Republic of Korea","paperID":"2702352"},{"content":"Sanjay Kairam , Jeffrey Heer, Parting Crowds: Characterizing Divergent Interpretations in Crowdsourced Annotation Tasks, Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work & Social Computing, February 27-March 02, 2016, San Francisco, California, USA","paperID":"2820016"}],"reference":[{"content":"Salman Ahmad , Alexis Battle , Zahan Malkani , Sepander Kamvar, The jabberwocky programming environment for structured social computing, Proceedings of the 24th annual ACM symposium on User interface software and technology, October 16-19, 2011, Santa Barbara, California, USA","paperID":"2047203"},{"content":"Michael S. Bernstein , Greg Little , Robert C. Miller , Björn Hartmann , Mark S. Ackerman , David R. Karger , David Crowell , Katrina Panovich, Soylent: a word processor with a crowd inside, Proceedings of the 23nd annual ACM symposium on User interface software and technology, October 03-06, 2010, New York, New York, USA","paperID":"1866078"},{"content":"Michael S. Bernstein , Jaime Teevan , Susan Dumais , Daniel Liebling , Eric Horvitz, Direct answers for search queries in the long tail, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 05-10, 2012, Austin, Texas, USA","paperID":"2207710"},{"content":"Steven Bird, NLTK: the natural language toolkit, Proceedings of the COLING/ACL on Interactive presentation sessions, p.69-72, July 17-18, 2006, Sydney, Australia","paperID":"1225421"},{"content":"Alberto Cairo, The Functional Art: An introduction to information graphics and visualization, New Riders Publishing, Thousand Oaks, CA, 2012","paperID":"2432449"},{"content":"Chris Callison-Burch , Mark Dredze, Creating speech and language data with Amazon's Mechanical Turk, Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon's Mechanical Turk, p.1-12, June 06-06, 2010, Los Angeles, California","paperID":"1866697"},{"content":"Stuart K. Card , Jock D. Mackinlay , Ben Shneiderman, Readings in information visualization: using vision to think, Morgan Kaufmann Publishers Inc., San Francisco, CA, 1999","paperID":"300679"},{"content":"Lydia B. Chilton , Greg Little , Darren Edge , Daniel S. Weld , James A. Landay, Cascade: crowdsourcing taxonomy creation, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 27-May 02, 2013, Paris, France","paperID":"2466265"},{"content":"William S. Cleveland, The elements of graphing data, Wadsworth Publ. Co., Belmont, CA, 1985","paperID":"4084"},{"content":"Economist Graphic Detail. http://www.economist.com/blogs/graphicdetail. Retrieved Sep 17, 2013.","paperID":"None"},{"content":"Guardian DataBlog. http://www.theguardian.com/datablog. Retrieved Sep 17, 2013.","paperID":"None"},{"content":"Jeffrey Heer , Michael Bostock, Crowdsourcing graphical perception: using mechanical turk to assess visualization design, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 10-15, 2010, Atlanta, Georgia, USA","paperID":"1753357"},{"content":"Pei-Yun Hsueh , Prem Melville , Vikas Sindhwani, Data quality from crowdsourcing: a study of annotation selection criteria, Proceedings of the NAACL HLT 2009 Workshop on Active Learning for Natural Language Processing, June 05-05, 2009, Boulder, Colorado","paperID":"1564137"},{"content":"Jessica Hullman , Eytan Adar , Priti Shah, The impact of social information on visual judgments, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 07-12, 2011, Vancouver, BC, Canada","paperID":"1979157"},{"content":"Jessica Hullman , Nick Diakopoulos, Visualization Rhetoric: Framing Effects in Narrative Visualization, IEEE Transactions on Visualization and Computer Graphics, v.17 n.12, p.2231-2240, December 2011","paperID":"2068623"},{"content":"Jessica Hullman , Nicholas Diakopoulos , Eytan Adar, Contextifier: automatic generation of annotated stock visualizations, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 27-May 02, 2013, Paris, France","paperID":"2481374"},{"content":"Eser Kandogan, Just-in-time annotation of clusters, outliers, and trends in point-based data visualizations, Proceedings of the 2012 IEEE Conference on Visual Analytics Science and Technology (VAST), p.73-82, October 14-19, 2012","paperID":"2478282"},{"content":"Aniket Kittur , Boris Smus , Susheel Khamkar , Robert E. Kraut, CrowdForge: crowdsourcing complex work, Proceedings of the 24th annual ACM symposium on User interface software and technology, October 16-19, 2011, Santa Barbara, California, USA","paperID":"2047202"},{"content":"Kong, N., and Agrawala, M. Graphical overlays: Using layered elements to aid chart reading. IEEE TVCG 18, 12 (2012), 2631--2638.","paperID":"None"},{"content":"Nicholas Kong , Jeffrey Heer , Maneesh Agrawala, Perceptual Guidelines for Creating Rectangular Treemaps, IEEE Transactions on Visualization and Computer Graphics, v.16 n.6, p.990-998, November 2010","paperID":"1907982"},{"content":"Anand Kulkarni , Matthew Can , Björn Hartmann, Collaboratively crowdsourcing workflows with turkomatic, Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work, February 11-15, 2012, Seattle, Washington, USA","paperID":"2145354"},{"content":"Le, J., Edmonds, A., Hester, V., and Biewald, L. Ensuring quality in crowdsourced search relevance evaluation: The effects of training question distribution. In SIGIR 2010 workshop on crowdsourcing for search evaluation (2010), 21--26.","paperID":"None"},{"content":"Greg Little , Lydia B. Chilton , Max Goldman , Robert C. Miller, TurKit: human computation algorithms on mechanical turk, Proceedings of the 23nd annual ACM symposium on User interface software and technology, October 03-06, 2010, New York, New York, USA","paperID":"1866040"},{"content":"Christopher D. Manning , Prabhakar Raghavan , Hinrich Schütze, Introduction to Information Retrieval, Cambridge University Press, New York, NY, 2008","paperID":"1394399"},{"content":"James Mayfield , Dawn Lawrie , Paul McNamee , Douglas W. Oard, Building a cross-language entity linking collection in twenty-one languages, Proceedings of the Second international conference on Multilingual and multimodal information access evaluation, September 19-22, 2011, Amsterdam, The Netherlands","paperID":"2045279"},{"content":"Preslav Nakov, Noun Compound Interpretation Using Paraphrasing Verbs: Feasibility Study, Proceedings of the 13th international conference on Artificial Intelligence: Methodology, Systems, and Applications, September 04-06, 2008, Varna, Bulgaria","paperID":"1433610"},{"content":"Oleson, D., Sorokin, A., Laughlin, G., Hester, V., Le, J., and Biewald, L. Programmatic gold: Targeted and scalable quality assurance in crowdsourcing. Proc. of HComp (2011).","paperID":"None"},{"content":"Pew Research. http://www.pewresearch.org/. Retrieved Sep 17, 2013.","paperID":"None"},{"content":"Manolis Savva , Nicholas Kong , Arti Chhajta , Li Fei-Fei , Maneesh Agrawala , Jeffrey Heer, ReVision: automated classification, analysis and redesign of chart images, Proceedings of the 24th annual ACM symposium on User interface software and technology, October 16-19, 2011, Santa Barbara, California, USA","paperID":"2047247"},{"content":"Edward Segel , Jeffrey Heer, Narrative Visualization: Telling Stories with Data, IEEE Transactions on Visualization and Computer Graphics, v.16 n.6, p.1139-1148, November 2010","paperID":"1908000"},{"content":"Rion Snow , Brendan O'Connor , Daniel Jurafsky , Andrew Y. Ng, Cheap and fast---but is it good?: evaluating non-expert annotations for natural language tasks, Proceedings of the Conference on Empirical Methods in Natural Language Processing, October 25-27, 2008, Honolulu, Hawaii","paperID":"1613751"},{"content":"Substance Abuse and Mental Health Services Administration. http://www.samhsa.gov/. Retrieved Sep 17, 2013.","paperID":"None"},{"content":"Wesley Willett , Jeffrey Heer , Maneesh Agrawala, Strategies for crowdsourcing social data analysis, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 05-10, 2012, Austin, Texas, USA","paperID":"2207709"}],"abstract":"News articles, reports, blog posts and academic papers often include graphical charts that serve to visually reinforce arguments presented in the text. To help readers better understand the relation between the text and the chart, we present a crowdsourcing pipeline to extract the references between them. Specifically, we give crowd workers paragraph-chart pairs and ask them to select text phrases as well as the corresponding visual marks in the chart. We then apply automated clustering and merging techniques to unify the references generated by multiple workers into a single set. Comparing the crowdsourced references to a set of gold standard references using a distance measure based on the F1 score, we find that the average distance between the raw set of references produced by a single worker and the gold standard is 0.54 (out of a max of 1.0). When we apply clustering and merging techniques the average distance between the unified set of references and the gold standard reduces to 0.39; an improvement of 27%. We conclude with an interactive document viewing application that uses the extracted references; readers can select phrases in the text and the system highlights the related marks in the chart.","video":"http://www.youtube.com/embed/cc2fUE-TvUw?rel=0","title":"Extracting references between text and charts via crowdsourcing","filename":"CHI14/p31","authors":["Nicholas Kong","Marti A. Hearst","Maneesh Agrawala"],"conference":"CHI '14"}