{"paperId":2557280,"citation":[{"content":"Jennifer Hyde , Elizabeth J. Carter , Sara Kiesler , Jessica K. Hodgins, Using an Interactive Avatar's Facial Expressiveness to Increase Persuasiveness and Socialness, Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, April 18-23, 2015, Seoul, Republic of Korea","paperID":"2702465"}],"reference":[{"content":"Sean Andrist , Tomislav Pejsa , Bilge Mutlu , Michael Gleicher, Designing effective gaze mechanisms for virtual agents, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 05-10, 2012, Austin, Texas, USA","paperID":"2207777"},{"content":"Baldwin, D., and Tomasello, M. Word learning: A window on early pragmatic understanding. In Proc. Child Language Research Forum. Chicago, IL, 2001, 3--23.","paperID":"None"},{"content":"Christoph Bartneck , Juliane Reichenbach, Subtle emotional expressions of synthetic characters, International Journal of Human-Computer Studies, v.62 n.2, p.179-192, February 2005","paperID":"1066395"},{"content":"Matthew Black , Jeannette Chang , Jonathan Chang , Shrikanth Narayanan, Comparison of child-human and child-computer interactions based on manual annotations, Proceedings of the 2nd Workshop on Child, Computer and Interaction, p.1-6, November 05-05, 2009, Cambridge, Massachusetts","paperID":"1640379"},{"content":"Boker, S. M., Cohn, J. F., Theobald, B.-J., Matthews, I., Brick, T. R., and Spies, J. R. Effects of damping head movement and facial expression in dyadic conversation using real-time facial expression tracking and synthesized avatars. Phil. Trans. R. Soc. B 364, 1535 (2009), 3485--3495.","paperID":"None"},{"content":"Borgers, N., de Leeuw, E., and Hox, J. Children as respondents in survey research: Cognitive development and response quality 1. Bulletin de MÃ©thodologie Sociologique 66, 1 (2000), 60--75.","paperID":"None"},{"content":"Borgers, N., Hox, J., and Sikkel, D. Response effects in surveys on children and adolescents: The effect of number of response options, negative wording, and neutral mid-point. Quality & Quantity 38, 1 (2004), 17--33.","paperID":"None"},{"content":"Winslow Burleson , Rosalind W. Picard, Gender-Specific Approaches to Developing Emotionally Intelligent Learning Companions, IEEE Intelligent Systems, v.22 n.4, p.62-69, July 2007","paperID":"1304506"},{"content":"Calder, A. J., Rowland, D., Young, A. W., Nimmo-Smith, I., Keane, J., and Perrett, D. I. Caricaturing facial expressions. Cognition 76, 2 (2000), 105--146.","paperID":"None"},{"content":"Calder, A. J., Young, A. W., Rowland, D., and Perrett, D. I. Computer-enhanced emotion in facial expressions. Phil. Trans. R. Soc. B 264 (1997), 919--925.","paperID":"None"},{"content":"Justine Cassell, Embodied conversational agents: representation and intelligence in user interfaces, AI Magazine, v.22 n.4, p.67-83, Winter 2001","paperID":"567368"},{"content":"Cassell, J., and Tartaro, A. Intersubjectivity in human-agent interaction. Interaction Studies 8, 3 (2007), 391--410.","paperID":"None"},{"content":"Timothy F. Cootes , Gareth J. Edwards , Christopher J. Taylor, Active Appearance Models, IEEE Transactions on Pattern Analysis and Machine Intelligence, v.23 n.6, p.681-685, June 2001","paperID":"378090"},{"content":"Cootes, T. F., Wheeler, G., Walker, K., and Taylor, C. J. View-based active appearance models. Image and Vision Computing 20, 9-10 (2002), 657--664.","paperID":"None"},{"content":"Costa, P. T., and MacCrae, R. R. Revised NEO Personality Inventory (NEO PI-R) and NEO Five-Factor Inventory (NEO FFI): Professional Manual. Psychological Assessment Resources, 1992.","paperID":"None"},{"content":"Coulston, R., Oviatt, S., and Darves, C. Amplitude convergence in children's conversational speech with animated personas. In Proc. International Conference on Spoken Language Processing, vol. 4 (2002), 2689--2692.","paperID":"None"},{"content":"Darves, C., Oviatt, S., and Coulston, R. Adaptation of users' spoken dialogue patterns in a conversational interface. In Proc. International Conference on Spoken Language Processing, vol. 1 (2002), 561--564.","paperID":"None"},{"content":"Celso M. de Melo , Peter Carnevale , Jonathan Gratch, The impact of emotion displays in embodied agents on emergence of cooperation with people, Presence: Teleoperators and Virtual Environments, v.20 n.5, p.449-465, October 2011","paperID":"2155540"},{"content":"Grist, C. L., Socha, A., and McCord, D. M. The M5-PS-35: A five-factor personality questionnaire for preschool children. Journal of Personality Assessment 94, 3 (2012), 287--295.","paperID":"None"},{"content":"Rosanna E. Guadagno , Kimberly R. Swinth , Jim Blascovich, Social evaluations of embodied agents and avatars, Computers in Human Behavior, v.27 n.6, p.2380-2385, November, 2011","paperID":"2030898"},{"content":"Hayes, D. Anytime Playdate: Inside the Preschool Entertainment Boom, or How Television Became My Baby's Best Friend. Free Press, New York, NY, 2008.","paperID":"None"},{"content":"Hess, U., Blairy, S., and Kleck, R. E. The intensity of emotional facial expressions and decoding accuracy. Journal of Nonverbal Behavior 21, 4 (1997), 241--257.","paperID":"None"},{"content":"Hyde, J., Carter, E. J., Kiesler, S., and Hodgins, J. K. Perceptual effects of damped and exaggerated facial motion in animated characters. In Proc. IEEE International Conference on Automatic Face and Gesture Recognition 2013 (2013).","paperID":"None"},{"content":"Kirkorian, H. L., Wartella, E. A., and Anderson, D. R. Media and young children's learning. Children and Electronic Media 18, 1 (2008), 39--61.","paperID":"None"},{"content":"Knowles, A. D., and Nixon, M. C. Children's comprehension of expressive states depicted in a television cartoon. Australian Journal of Psychology 41, 1 (1989), 17--24.","paperID":"None"},{"content":"Linebarger, D. L., and Walker, D. Infants' and toddlers' television viewing and language outcomes. American Behavioral Scientist 46, X (2004), 1--21.","paperID":"None"},{"content":"Iain Matthews , Simon Baker, Active Appearance Models Revisited, International Journal of Computer Vision, v.60 n.2, p.135-164, November 2004","paperID":"996344"},{"content":"Max Planck Institute for Psycholinguistics, The Language Archive, Nijmegen, The Netherlands. ELAN. http://tla.mpi.nl/tools/tla-tools/elan.","paperID":"None"},{"content":"Oviatt, S. Talking to thimble jellies: Children's conversational speech with animated characters. In Proc. INTERSPEECH 2000 (2000), 877--880.","paperID":"None"},{"content":"Janet C. Read , Stuart MacFarlane, Using the fun toolkit and other survey methods to gather opinions in child computer interaction, Proceedings of the 2006 conference on Interaction design and children, June 07-09, 2006, Tampere, Finland","paperID":"1139096"},{"content":"Rideout, V. J., Vandewater, E. A., and Wartella, E. A. Zero to six: Electronic media in the lives of infants, toddlers and preschoolers. Tech. rep., The Henry J. Kaiser Family Foundation, 2003.","paperID":"None"},{"content":"Scheck, A. M., L. Alvin Malesky, J., Grist, C. L., and McCord, D. M. Personality in preschool children: Preliminary psychometrics of the M5-PS questionnaire. American Journal of Psychological Research 6, 1 (2010), 134--156.","paperID":"None"},{"content":"Sloetjes, H., and Wittenburg, P. Annotation by category: ELAN and ISO DCR. In Proc. LREC (2008).","paperID":"None"},{"content":"Jennifer Tam , Elizbeth Carter , Sara Kiesler , Jessica Hodgins, Video increases the perception of naturalness during remote interactions with latency, CHI '12 Extended Abstracts on Human Factors in Computing Systems, May 05-10, 2012, Austin, Texas, USA","paperID":"2223750"},{"content":"Theobald, B.-J., Matthews, I., Mangini, M., Spies, J. R., Brick, T. R., Cohn, J. F., and Boker, S. M. Mapping and manipulating facial expression. Language and Speech 52 (2009), 369--386.","paperID":"None"},{"content":"Troseth, G. L., Saylor, M. M., and Archer, A. H. Young children's use of video as a source of socially relevant information. Child Development 77, 3 (2006), 786--799.","paperID":"None"},{"content":"Widen, S. C., and Russell, J. A. Children acquire emotion categories gradually. Cognitive Development 23, 2 (2008), 291--312.","paperID":"None"},{"content":"Zaman, B., Abeele, V. V., and Grooff, D. D. Measuring product liking in preschool children: An evaluation of the Smileyometer and this or that methods. International Journal of Child-Computer Interaction 1, 1 (2013), 61--70.","paperID":"None"}],"abstract":"Interactive animated characters have the potential to engage and educate children, but there is little research on children's interactions with animated characters and real people. We conducted an experiment with 69 children between the ages of 4 and 10 years to investigate how they might engage in conversation differently if their interactive partner appeared as a cartoon character or as a person. A subset of the participants interacted with characters that displayed exaggerated and damped facial motion. The children completed two conversations with an adult confederate who appeared once as herself through video and once as a cartoon character. We measured how much the children spoke and compared their gaze and gesture patterns. We asked them to rate their conversations and indicate their preferred partner. There was no difference in children's conversation behavior with the cartoon character and the person on video, even among those who preferred the person and when the cartoon exhibited altered motion. These results suggest that children will interact with animated characters as they would another person.","video":"http://www.youtube.com/embed/5dcO7po2v18?rel=0","title":"Conversing with children: cartoon and video people elicit similar conversational behaviors","filename":"CHI14/p1787","authors":["Jennifer Hyde","Sara Kiesler","Jessica K. Hodgins","Elizabeth J. Carter"],"conference":"CHI '14"}