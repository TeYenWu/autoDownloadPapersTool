{"paperId":2702443,"abstract":"Crowdsourcing is increasingly being used as a means to tackle problems requiring human intelligence. With the ever-growing worker base that aims to complete microtasks on crowdsourcing platforms in exchange for financial gains, there is a need for stringent mechanisms to prevent exploitation of deployed tasks. Quality control mechanisms need to accommodate a diverse pool of workers, exhibiting a wide range of behavior. A pivotal step towards fraud-proof task design is understanding the behavioral patterns of microtask workers. In this paper, we analyze the prevalent malicious activity on crowdsourcing platforms and study the behavior exhibited by trustworthy and untrustworthy workers, particularly on crowdsourced surveys. Based on our analysis of the typical malicious activity, we define and identify different types of workers in the crowd, propose a method to measure malicious activity, and finally present guidelines for the efficient design of crowdsourced surveys.","citation":[{"content":"Ujwal Gadiraju , Patrick Siehndel , Besnik Fetahu , Ricardo Kawase, Breaking Bad: Understanding Behavior of Crowd Workers in Categorization Microtasks, Proceedings of the 26th ACM Conference on Hypertext & Social Media, September 01-04, 2015, Guzelyurt, Northern Cyprus","paperID":"2791053"},{"content":"Ujwal Gadiraju, Make Hay While the Crowd Shines: Towards Efficient Crowdsourcing on the Web, Proceedings of the 24th International Conference on World Wide Web, May 18-22, 2015, Florence, Italy","paperID":"2741748"},{"content":"Henry Corrigan-Gibbs , Nakull Gupta , Curtis Northcutt , Edward Cutrell , William Thies, Deterring Cheating in Online Environments, ACM Transactions on Computer-Human Interaction (TOCHI), v.22 n.6, p.1-23, December 2015","paperID":"2810239"}],"reference":[{"content":"Baba, Y., Kashima, H., Kinoshita, K., Yamaguchi, G., and Akiyoshi, Y. Leveraging crowdsourcing to detect improper tasks in crowdsourcing marketplaces. In Twenty-Fifth IAAI Conference (2013).","paperID":"None"},{"content":"Behrend, T. S., Sharek, D. J., Meade, A. W., and Wiebe, E. N. The viability of crowdsourcing for survey research. Behavior research methods 43, 3 (2011), 800--813.","paperID":"None"},{"content":"Brabham, D. C. Crowdsourcing as a Model for Problem Solving. Convergence: The International Journal of Research into New Media Technologies 14, 1 (Feb. 2008), 75--90.","paperID":"None"},{"content":"Buchholz, S., and Latorre, J. Crowdsourcing preference tests, and how to detect cheating. In INTERSPEECH (2011), 3053--3056.","paperID":"None"},{"content":"Corbin, J., and Strauss, A. Basics of qualitative research: Techniques and procedures for developing grounded theory. Sage, 2008.","paperID":"None"},{"content":"Difallah, D. E., Demartini, G., and Cudré-Mauroux, P. Mechanical cheat: Spamming schemes and adversarial techniques on crowdsourcing platforms. In CrowdSearch (2012), 26--30.","paperID":"None"},{"content":"Steven Dow , Anand Kulkarni , Brie Bunge , Truc Nguyen , Scott Klemmer , Björn Hartmann, Shepherding the crowd: managing and providing feedback to crowd workers, CHI '11 Extended Abstracts on Human Factors in Computing Systems, May 07-12, 2011, Vancouver, BC, Canada","paperID":"1979826"},{"content":"Steven Dow , Anand Kulkarni , Scott Klemmer , Björn Hartmann, Shepherding the crowd yields better work, Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work, February 11-15, 2012, Seattle, Washington, USA","paperID":"2145355"},{"content":"Eickhoff, C., and de Vries, A. How crowdsourcable is your task. In Proceedings of the workshop on crowdsourcing for search and data mining (CSDM) at the fourth ACM international conference on web search and data mining (WSDM) (2011), 11--14.","paperID":"None"},{"content":"Carsten Eickhoff , Arjen P. Vries, Increasing cheat robustness of crowdsourcing tasks, Information Retrieval, v.16 n.2, p.121-137, April     2013","paperID":"2460572"},{"content":"Enrique Estellés-Arolas , Fernando González-Ladrón-De-Guevara, Towards an integrated crowdsourcing definition, Journal of Information Science, v.38 n.2, p.189-200, April     2012","paperID":"2185503"},{"content":"Ujwal Gadiraju , Ricardo Kawase , Stefan Dietze, A taxonomy of microtasks on the web, Proceedings of the 25th ACM conference on Hypertext and social media, September 01-04, 2014, Santiago, Chile","paperID":"2631819"},{"content":"Rosario Gennaro , Craig Gentry , Bryan Parno, Non-interactive verifiable computing: outsourcing computation to untrusted workers, Proceedings of the 30th annual conference on Advances in cryptology, August 15-19, 2010, Santa Barbara, CA, USA","paperID":"1881445"},{"content":"Robert L. Glass , Iris Vessey, Contemporary Application-Domain Taxonomies, IEEE Software, v.12 n.4, p.63-76, July 1995","paperID":"625489"},{"content":"Panagiotis G. Ipeirotis , Foster Provost , Jing Wang, Quality management on Amazon Mechanical Turk, Proceedings of the ACM SIGKDD Workshop on Human Computation, July 25-25, 2010, Washington DC","paperID":"1837906"},{"content":"Kaufmann, N., Schulze, T., and Veit, D. More than fun and money. worker motivation in crowdsourcing - a study on mechanical turk. In AMCIS (2011).","paperID":"None"},{"content":"Gabriella Kazai , Jaap Kamps , Natasa Milic-Frayling, Worker types and personality traits in crowdsourcing relevance labels, Proceedings of the 20th ACM international conference on Information and knowledge management, October 24-28, 2011, Glasgow, Scotland, UK","paperID":"2063860"},{"content":"Gabriella Kazai , Jaap Kamps , Natasa Milic-Frayling, An analysis of human factors and label accuracy in crowdsourcing relevance judgments, Information Retrieval, v.16 n.2, p.138-178, April     2013","paperID":"2460573"},{"content":"Aniket Kittur , Ed H. Chi , Bongwon Suh, Crowdsourcing user studies with Mechanical Turk, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 05-10, 2008, Florence, Italy","paperID":"1357127"},{"content":"Aniket Kittur , Jeffrey V. Nickerson , Michael Bernstein , Elizabeth Gerber , Aaron Shaw , John Zimmerman , Matt Lease , John Horton, The future of crowd work, Proceedings of the 2013 conference on Computer supported cooperative work, February 23-27, 2013, San Antonio, Texas, USA","paperID":"2441923"},{"content":"Catherine C. Marshall , Frank M. Shipman, Experiences surveying the crowd: reflections on methods, participation, and reliability, Proceedings of the 5th Annual ACM Web Science Conference, p.234-243, May 02-04, 2013, Paris, France","paperID":"2464485"},{"content":"Winter Mason , Duncan J. Watts, Financial incentives and the \"performance of crowds\", ACM SIGKDD Explorations Newsletter, v.11 n.2, December 2009","paperID":"1809422"},{"content":"Klimis Ntalianis , Nicolas Tsapatsoulis , Anastasios Doulamis , Nikolaos Matsatsinis, Automatic annotation of image databases based on implicit crowdsourcing, visual concept modeling and evolution, Multimedia Tools and Applications, v.69 n.2, p.397-421, March     2014","paperID":"2598621"},{"content":"Oleson, D., Sorokin, A., Laughlin, G. P., Hester, V., Le, J., and Biewald, L. Programmatic gold: Targeted and scalable quality assurance in crowdsourcing. Human computation 11 (2011), 11.","paperID":"None"},{"content":"Joel Ross , Lilly Irani , M. Six Silberman , Andrew Zaldivar , Bill Tomlinson, Who are the crowdworkers?: shifting demographics in mechanical turk, CHI '10 Extended Abstracts on Human Factors in Computing Systems, April 10-15, 2010, Atlanta, Georgia, USA","paperID":"1753873"},{"content":"Gang Wang , Christo Wilson , Xiaohan Zhao , Yibo Zhu , Manish Mohanlal , Haitao Zheng , Ben Y. Zhao, Serf and turf: crowdturfing for fun and profit, Proceedings of the 21st international conference on World Wide Web, April 16-20, 2012, Lyon, France","paperID":"2187928"},{"content":"Yuen, M.-C., King, I., and Leung, K.-S. A survey of crowdsourcing systems. In Privacy, security, risk and trust (passat), 2011 ieee third international conference on and 2011 ieee third international conference on social computing (socialcom), IEEE (2011), 766--773.","paperID":"None"}],"title":"Understanding Malicious Behavior in Crowdsourcing Platforms: The Case of Online Surveys","filename":"CHI15/p1631","authors":["Ujwal Gadiraju","Ricardo Kawase","Stefan Dietze","Gianluca Demartini"],"conference":"CHI '15"}