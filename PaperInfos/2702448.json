{"paperId":2702448,"citation":[],"reference":[{"content":"Buxton, W. Mediaspace-meaningspace-meetingspace. In Media Space 20 + Years of Mediated Life, Computer Supported Cooperative Work. Springer, 2009, 217--231.","paperID":"None"},{"content":"Buxton, W. A. S. Telepresence: Integrating shared task and person spaces. In Proc. Graphics Interface, GI'92 (1992), 123--129.","paperID":"None"},{"content":"Isaacs, E. A., and Tang, J. C. What video can and cannot do for collaboration: A case study. Multimedia Systems 2, 2 (1994), 63--73.","paperID":"None"},{"content":"Ishii, H., and Kobayashi, M. Clearboard: A seamless medium for shared drawing and conversation with eye contact. In Proc. Human Factors in Computing Systems, CHI'92, ACM (1992), 525--532.","paperID":"None"},{"content":"Kuechler, M., and Kunz, A. HoloPort - a device for simultaneous video and data conferencing featuring gaze awareness. In Proc. Virtual Reality, VR'06, IEEE (2006), 81--88.","paperID":"None"},{"content":"Mackay, W. E. Media spaces: environments for informal multimedia interaction. In Computer Supported Co-operative Work, M. Beaudouin-Lafon, Ed., John Wiley & Sons (1999), 55--82.","paperID":"None"},{"content":"Nguyen, D., and Canny, J. MultiView: Spatially faithful group video conferencing. In Proc. Human Factors in Computing Systems, CHI'05, ACM (2005), 799--808.","paperID":"None"},{"content":"Tan, K.-H., Robinson, I., Samadani, R., Lee, B., Gelb, D., Vorbau, A., Culbertson, B., and Apostolopoulos, J. Connectboard: A remote collaboration system that supports gaze-aware interaction and sharing. In Workshop on MMSP '2009, IEEE (2009), 1--6.","paperID":"None"},{"content":"Tang, J. C., and Minneman, S. VideoWhiteboard: Video shadows to support remote collaboration. In Proc. Human Factors in Computing Systems, CHI'91, ACM (1991), 315--322.","paperID":"None"},{"content":"Wong, N., and Gutwin, C. Where are you pointing?: The accuracy of deictic pointing in CVEs. In Proc. Human Factors in Computing Systems, CHI'10, ACM (2010), 1029--1038.","paperID":"None"}],"abstract":"This paper presents a controlled experiment assessing the accuracy when interpreting remote users showing a shared object on a large wall-sized display, either by looking at it or by looking and pointing at it. We analyze both distance and angle errors and how they are sensitive to the relative position be- tween the remote viewer and the video feed. We show that the remote user can accurately determine the target, that eye gaze alone is more accurate than combined with the hand, and that the relative position between the viewer and the video feed has little effect on accuracy. These findings can inform the design of future telepresence systems for wall-sized displays.","title":"Accuracy of Deictic Gestures to Support Telepresence on Wall-sized Displays","filename":"CHI15/p2393","authors":["Ignacio Avellino","CÃ©dric Fleury","Michel Beaudouin-Lafon"],"conference":"CHI '15"}